{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"F-o6bXOJ18j4","executionInfo":{"status":"ok","timestamp":1645033501267,"user_tz":0,"elapsed":18198,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"acb3ef21-dae5-4954-e9a2-5d07fb2a9668"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 3.5 MB 14.0 MB/s \n","\u001b[K     |████████████████████████████████| 6.8 MB 74.1 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 71.9 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 76.1 MB/s \n","\u001b[K     |████████████████████████████████| 67 kB 4.9 MB/s \n","\u001b[K     |████████████████████████████████| 1.2 MB 13.6 MB/s \n","\u001b[K     |████████████████████████████████| 311 kB 13.5 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 70.1 MB/s \n","\u001b[K     |████████████████████████████████| 133 kB 72.3 MB/s \n","\u001b[K     |████████████████████████████████| 243 kB 86.2 MB/s \n","\u001b[K     |████████████████████████████████| 94 kB 3.7 MB/s \n","\u001b[K     |████████████████████████████████| 144 kB 86.6 MB/s \n","\u001b[K     |████████████████████████████████| 271 kB 89.9 MB/s \n","\u001b[?25h"]}],"source":["!pip install -qq transformers\n","!pip install -qq sentencepiece\n","!pip install -qq datasets\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Rz6wNlu92ge_","executionInfo":{"status":"ok","timestamp":1645033510537,"user_tz":0,"elapsed":9276,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["import transformers\n","import datasets\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup,Trainer, TrainingArguments\n","from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n","import torch\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from pylab import rcParams\n","import matplotlib.pyplot as plt\n","from matplotlib import rc\n","from sklearn.metrics import confusion_matrix, classification_report\n","from collections import defaultdict\n","import random\n","from textwrap import wrap\n","from datetime import datetime\n","from datasets import load_from_disk\n","from datasets import Dataset\n","from sklearn.metrics import accuracy_score,classification_report, confusion_matrix\n","from sklearn.metrics import precision_recall_fscore_support"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"pOQkqPGp2ZTN","executionInfo":{"status":"ok","timestamp":1645033510538,"user_tz":0,"elapsed":21,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["from torch import nn"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"T7IFr4-3TKaA","executionInfo":{"status":"ok","timestamp":1645033510962,"user_tz":0,"elapsed":10,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["# the model we gonna train, base uncased BERT\n","# check text classification models here: https://huggingface.co/models?filter=text-classification\n","MODEL_NAME = \"distilbert-base-uncased\"\n","# max sequence length for each document/sentence sample\n","BATCH_SIZE = 128\n","EVAL_BATCH_SIZE = 16\n","EPOCHS = 3\n","LEARNING_RATE= 10.58e-5\n","WEIGHT_DECAY =  0.103\n","WARMUP_STEPS = 449\n","RANDOM_SEED=22\n","\n","LEARNING_RATE_DECAY_MULTIPLIER = 0.95\n","REINIT_LAYERS = 2\n","\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"YoKXcvyo_X47","executionInfo":{"status":"ok","timestamp":1645033510965,"user_tz":0,"elapsed":12,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["class LLRDTrainer(Trainer):\n","\n","    def create_optimizer_and_scheduler(self, num_training_steps: int):\n","        \"\"\"\n","        Setup the optimizer and the learning rate scheduler.\n","        We provide a reasonable default that works well. If you want to use something else, you can pass a tuple in the\n","        Trainer's init through `optimizers`, or subclass and override this method (or `create_optimizer` and/or\n","        `create_scheduler`) in a subclass.\n","        \"\"\"\n","        self.create_optimizer()\n","        parameters = get_optimizer_parameters_with_llrd(self.model, LEARNING_RATE, 0.95)\n","        self.optimizer = AdamW(parameters, lr=LEARNING_RATE,weight_decay=WEIGHT_DECAY)\n","        self.create_scheduler(num_training_steps=num_training_steps, optimizer=self.optimizer)\n","\n","\n","def set_seed(seed):\n","    \"\"\"Set all seeds to make results reproducible (deterministic mode).\n","       When seed is None, disables deterministic mode.\n","    :param seed: an integer to your choosing\n","    \"\"\"\n","    if seed is not None:\n","        torch.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","        np.random.seed(seed)\n","        random.seed(seed)\n","\n","def compute_metrics(pred):\n","  labels = pred.label_ids\n","  preds = pred.predictions.argmax(-1)\n","  # calculate accuracy using sklearn's function\n","  acc = accuracy_score(labels, preds)\n","  precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n","  acc = accuracy_score(labels, preds)\n","  confusion_matrix = classification_report(labels, preds, digits=4,output_dict=True)\n","  return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall,\n","        'hate_f1': confusion_matrix[\"0\"][\"f1-score\"],\n","        'hate_recall': confusion_matrix[\"0\"][\"recall\"],\n","        'hate_precision': confusion_matrix[\"0\"][\"precision\"],\n","        'offensive_f1': confusion_matrix[\"1\"][\"f1-score\"],\n","        'offensive_recall': confusion_matrix[\"1\"][\"recall\"],\n","        'offensive_precision': confusion_matrix[\"1\"][\"precision\"],\n","        'normal_f1': confusion_matrix[\"2\"][\"f1-score\"],\n","        'normal_recall': confusion_matrix[\"2\"][\"recall\"],\n","        'normal_precision': confusion_matrix[\"2\"][\"precision\"],    \n","  }\n","\n","\n","\n","def timestamp():\n","    dateTimeObj = datetime.now()\n","    timestampStr = dateTimeObj.strftime(\"%d-%b-%Y (%H:%M:%S.%f)\")\n","    print(timestampStr)\n","\n","\n","def get_optimizer_parameters_with_llrd(model, peak_lr, multiplicative_factor):\n","    num_encoder_layers = len(model.distilbert.transformer.layer)\n","    # Task specific layer gets the peak_lr\n","    tsl_parameters = [\n","        {\n","            \"params\": [param for name, param in model.named_parameters() if 'distilbert' not in name],\n","            \"param_names\": [name for name, param in model.named_parameters() if 'distilbert' not in name],\n","            \"lr\": peak_lr,\n","            \"name\": \"tsl\",\n","        }\n","    ]\n","\n","    # Starting from the last encoder layer each encoder layers get a lr defined by\n","    # current_layer_lr = prev_layer_lr * multiplicative_factor\n","    # the last encoder layer lr = peak_lr * multiplicative_factor\n","    encoder_parameters = [\n","        {\n","            \"params\": [param for name, param in model.named_parameters() if f\"distilbert.transformer.layer.{layer_num}\" in name],\n","            \"param_names\": [name for name, param in model.named_parameters() if f\"distilbert.transformer.layer.{layer_num}\" in name],\n","            \"lr\": peak_lr * (multiplicative_factor ** (num_encoder_layers - layer_num)),\n","            \"name\": f\"layer_{layer_num}\",\n","        }\n","        for layer_num, layer in enumerate(model.distilbert.transformer.layer)\n","    ]\n","\n","    # Embedding layer gets embedding layer lr = first encoder layer lr * multiplicative_factor\n","    embedding_parameters = [\n","        {\n","            \"params\": [param for name, param in model.named_parameters() if 'embeddings' in name],\n","            \"param_names\": [name for name, param in model.named_parameters() if 'embeddings' in name],\n","            \"lr\": peak_lr * (multiplicative_factor ** (num_encoder_layers + 1)),\n","            \"name\": \"embedding\",\n","        }\n","    ]\n","    return tsl_parameters + encoder_parameters + embedding_parameters\n","\n","\n","def reinit_autoencoder_model(model, reinit_num_layers=0):\n","    \"\"\"reinitialize autoencoder model layers\"\"\"\n","\n","    if reinit_num_layers:\n","        for layer in model.distilbert.transformer.layer[-reinit_num_layers:]:\n","            for module in layer.modules():\n","                if isinstance(module, nn.Embedding):\n","                  if module.weight.requires_grad:\n","                    module.weight.data.normal_(mean=0.0, std=model.config.initializer_range)\n","                if isinstance(module, nn.Linear):\n","                  module.weight.data.normal_(mean=0.0, std=model.config.initializer_range)\n","                elif isinstance(module, nn.LayerNorm):\n","                  module.bias.data.zero_()\n","                  module.weight.data.fill_(1.0)\n","                if isinstance(module, nn.Linear) and module.bias is not None:\n","                  module.bias.data.zero_()\n","\n","    return model\n","\n","\n","def model_init():\n","    temp_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME,num_labels=3).to(device)\n","    return temp_model\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"lqKiS7jbkC4x","executionInfo":{"status":"ok","timestamp":1645033510966,"user_tz":0,"elapsed":12,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["set_seed(RANDOM_SEED)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"TlWMqxBs5b5P","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e702f15e576e40cdaeb183cb45bd0cf5","5ee3682e64024d7d94414c3a793de9db","15225c39893949ad80afa54b556889f5","18b1a10681e148749d7786c50695d59e","5063b06045c04b12b4073b9c8fdba0a2","346f8ba1563e46f58886a0d29f2cdd89","ed1ba6a7d6a34fb7bb6398bf12bd160d","802fdb48f26343a4816aa636b9fc21c6","fde6e9b3bd6b42fdae7c481469458fa3","7e3f25edbb8145d691a814001119b2f9","93432cace9684471af4874f0df263500","f3277a5706024e0ba9051c2c8af26793","b27115b0f99c4612bd4f9361c7d077e2","c0a7c19574814e299f9212882507a793","48a7ad42b5a2432cbabe375a8a75859e","96012a167ed54c46a158ebe9d8a95661","9fe5717ce9b24bffb05846d7f12f0581","f8ac26e42d3b4213877e0cfd5d4f283d","08c4e741b6274f29ab6c7eeaedd2def2","a9d741a55632420a91ccefb7c95609e3","3e8f300315a0405f878cf4f1b031d974","172f11a07f60488fbff5c205e125b479"]},"executionInfo":{"status":"ok","timestamp":1645036073702,"user_tz":0,"elapsed":2562747,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"21af36bb-8bab-4821-f2bc-bfd705f8024e"},"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e702f15e576e40cdaeb183cb45bd0cf5","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f3277a5706024e0ba9051c2c8af26793","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 876\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='876' max='876' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [876/876 03:56, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.573734</td>\n","      <td>0.764971</td>\n","      <td>0.718765</td>\n","      <td>0.715898</td>\n","      <td>0.721846</td>\n","      <td>0.695869</td>\n","      <td>0.703219</td>\n","      <td>0.688670</td>\n","      <td>0.846139</td>\n","      <td>0.837838</td>\n","      <td>0.854607</td>\n","      <td>0.614286</td>\n","      <td>0.624481</td>\n","      <td>0.604418</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.647900</td>\n","      <td>0.495317</td>\n","      <td>0.801889</td>\n","      <td>0.750979</td>\n","      <td>0.767162</td>\n","      <td>0.744156</td>\n","      <td>0.762228</td>\n","      <td>0.791751</td>\n","      <td>0.734827</td>\n","      <td>0.872505</td>\n","      <td>0.898186</td>\n","      <td>0.848252</td>\n","      <td>0.618203</td>\n","      <td>0.542531</td>\n","      <td>0.718407</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.647900</td>\n","      <td>0.486810</td>\n","      <td>0.808328</td>\n","      <td>0.765058</td>\n","      <td>0.767075</td>\n","      <td>0.765991</td>\n","      <td>0.784652</td>\n","      <td>0.822938</td>\n","      <td>0.749771</td>\n","      <td>0.875161</td>\n","      <td>0.878563</td>\n","      <td>0.871785</td>\n","      <td>0.635359</td>\n","      <td>0.596473</td>\n","      <td>0.679669</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/1/checkpoint-292\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/1/checkpoint-292/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/1/checkpoint-292/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/1/checkpoint-584\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/1/checkpoint-584/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/1/checkpoint-584/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/1/checkpoint-876\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/1/checkpoint-876/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/1/checkpoint-876/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/1/checkpoint-876 (score: 0.48681026697158813).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_1\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_1/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_1/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"output_type":"stream","name":"stdout","text":["16-Feb-2022 (17:49:44.141733)\n","None\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 876\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='876' max='876' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [876/876 03:59, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.555659</td>\n","      <td>0.774200</td>\n","      <td>0.716252</td>\n","      <td>0.736971</td>\n","      <td>0.704568</td>\n","      <td>0.716734</td>\n","      <td>0.715292</td>\n","      <td>0.718182</td>\n","      <td>0.852639</td>\n","      <td>0.891151</td>\n","      <td>0.817317</td>\n","      <td>0.579384</td>\n","      <td>0.507261</td>\n","      <td>0.675414</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.648400</td>\n","      <td>0.505408</td>\n","      <td>0.793733</td>\n","      <td>0.751717</td>\n","      <td>0.748120</td>\n","      <td>0.763259</td>\n","      <td>0.764257</td>\n","      <td>0.856137</td>\n","      <td>0.690187</td>\n","      <td>0.863206</td>\n","      <td>0.843391</td>\n","      <td>0.883974</td>\n","      <td>0.627689</td>\n","      <td>0.590249</td>\n","      <td>0.670200</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.648400</td>\n","      <td>0.486079</td>\n","      <td>0.810260</td>\n","      <td>0.768713</td>\n","      <td>0.768781</td>\n","      <td>0.769833</td>\n","      <td>0.790652</td>\n","      <td>0.816901</td>\n","      <td>0.766038</td>\n","      <td>0.876479</td>\n","      <td>0.877453</td>\n","      <td>0.875508</td>\n","      <td>0.639009</td>\n","      <td>0.615145</td>\n","      <td>0.664798</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/2/checkpoint-292\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/2/checkpoint-292/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/2/checkpoint-292/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/2/checkpoint-584\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/2/checkpoint-584/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/2/checkpoint-584/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/2/checkpoint-876\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/2/checkpoint-876/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/2/checkpoint-876/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/2/checkpoint-876 (score: 0.48607921600341797).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_2\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_2/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_2/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"output_type":"stream","name":"stdout","text":["16-Feb-2022 (17:53:58.303408)\n","None\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 876\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='876' max='876' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [876/876 03:57, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.588404</td>\n","      <td>0.759820</td>\n","      <td>0.696918</td>\n","      <td>0.717501</td>\n","      <td>0.694941</td>\n","      <td>0.697739</td>\n","      <td>0.760563</td>\n","      <td>0.644501</td>\n","      <td>0.845751</td>\n","      <td>0.867827</td>\n","      <td>0.824771</td>\n","      <td>0.547264</td>\n","      <td>0.456432</td>\n","      <td>0.683230</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.645100</td>\n","      <td>0.521726</td>\n","      <td>0.786649</td>\n","      <td>0.716995</td>\n","      <td>0.773791</td>\n","      <td>0.708997</td>\n","      <td>0.748833</td>\n","      <td>0.806841</td>\n","      <td>0.698606</td>\n","      <td>0.863478</td>\n","      <td>0.915587</td>\n","      <td>0.816981</td>\n","      <td>0.538674</td>\n","      <td>0.404564</td>\n","      <td>0.805785</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.645100</td>\n","      <td>0.500783</td>\n","      <td>0.809401</td>\n","      <td>0.766414</td>\n","      <td>0.769112</td>\n","      <td>0.765017</td>\n","      <td>0.786627</td>\n","      <td>0.804829</td>\n","      <td>0.769231</td>\n","      <td>0.876400</td>\n","      <td>0.883377</td>\n","      <td>0.869534</td>\n","      <td>0.636215</td>\n","      <td>0.606846</td>\n","      <td>0.668571</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/3/checkpoint-292\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/3/checkpoint-292/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/3/checkpoint-292/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/3/checkpoint-584\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/3/checkpoint-584/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/3/checkpoint-584/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/3/checkpoint-876\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/3/checkpoint-876/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/3/checkpoint-876/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/3/checkpoint-876 (score: 0.5007829070091248).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_3\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_3/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_3/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"output_type":"stream","name":"stdout","text":["16-Feb-2022 (17:58:12.805332)\n","None\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 876\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='876' max='876' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [876/876 03:55, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.589084</td>\n","      <td>0.757673</td>\n","      <td>0.685063</td>\n","      <td>0.752645</td>\n","      <td>0.658723</td>\n","      <td>0.685005</td>\n","      <td>0.638833</td>\n","      <td>0.738372</td>\n","      <td>0.835956</td>\n","      <td>0.924472</td>\n","      <td>0.762909</td>\n","      <td>0.534228</td>\n","      <td>0.412863</td>\n","      <td>0.756654</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.644200</td>\n","      <td>0.534049</td>\n","      <td>0.776132</td>\n","      <td>0.738302</td>\n","      <td>0.727877</td>\n","      <td>0.753939</td>\n","      <td>0.747142</td>\n","      <td>0.821932</td>\n","      <td>0.684828</td>\n","      <td>0.846614</td>\n","      <td>0.812292</td>\n","      <td>0.883965</td>\n","      <td>0.621150</td>\n","      <td>0.627593</td>\n","      <td>0.614837</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.644200</td>\n","      <td>0.506913</td>\n","      <td>0.806825</td>\n","      <td>0.764144</td>\n","      <td>0.764368</td>\n","      <td>0.766941</td>\n","      <td>0.796949</td>\n","      <td>0.841046</td>\n","      <td>0.757246</td>\n","      <td>0.872478</td>\n","      <td>0.872640</td>\n","      <td>0.872317</td>\n","      <td>0.623005</td>\n","      <td>0.587137</td>\n","      <td>0.663540</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/4/checkpoint-292\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/4/checkpoint-292/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/4/checkpoint-292/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/4/checkpoint-584\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/4/checkpoint-584/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/4/checkpoint-584/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/4/checkpoint-876\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/4/checkpoint-876/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/4/checkpoint-876/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/4/checkpoint-876 (score: 0.5069133639335632).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_4\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_4/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_4/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"output_type":"stream","name":"stdout","text":["16-Feb-2022 (18:02:26.058064)\n","None\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 876\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='876' max='876' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [876/876 04:04, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.557021</td>\n","      <td>0.777205</td>\n","      <td>0.722621</td>\n","      <td>0.744112</td>\n","      <td>0.707047</td>\n","      <td>0.697218</td>\n","      <td>0.642857</td>\n","      <td>0.761621</td>\n","      <td>0.855175</td>\n","      <td>0.896335</td>\n","      <td>0.817629</td>\n","      <td>0.615469</td>\n","      <td>0.581950</td>\n","      <td>0.653085</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.644600</td>\n","      <td>0.489789</td>\n","      <td>0.803391</td>\n","      <td>0.759394</td>\n","      <td>0.765237</td>\n","      <td>0.755405</td>\n","      <td>0.764356</td>\n","      <td>0.776660</td>\n","      <td>0.752437</td>\n","      <td>0.871009</td>\n","      <td>0.883747</td>\n","      <td>0.858633</td>\n","      <td>0.642818</td>\n","      <td>0.605809</td>\n","      <td>0.684642</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.644600</td>\n","      <td>0.483950</td>\n","      <td>0.818845</td>\n","      <td>0.779080</td>\n","      <td>0.781264</td>\n","      <td>0.778880</td>\n","      <td>0.799029</td>\n","      <td>0.827968</td>\n","      <td>0.772045</td>\n","      <td>0.880663</td>\n","      <td>0.885228</td>\n","      <td>0.876145</td>\n","      <td>0.657549</td>\n","      <td>0.623444</td>\n","      <td>0.695602</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/5/checkpoint-292\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/5/checkpoint-292/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/5/checkpoint-292/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/5/checkpoint-584\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/5/checkpoint-584/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/5/checkpoint-584/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/5/checkpoint-876\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/5/checkpoint-876/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/5/checkpoint-876/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/5/checkpoint-876 (score: 0.4839499592781067).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_5\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_5/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_5/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"output_type":"stream","name":"stdout","text":["16-Feb-2022 (18:06:46.549830)\n","None\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 876\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='876' max='876' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [876/876 03:58, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.558580</td>\n","      <td>0.772483</td>\n","      <td>0.712157</td>\n","      <td>0.734314</td>\n","      <td>0.706669</td>\n","      <td>0.714556</td>\n","      <td>0.760563</td>\n","      <td>0.673797</td>\n","      <td>0.853663</td>\n","      <td>0.882266</td>\n","      <td>0.826856</td>\n","      <td>0.568252</td>\n","      <td>0.477178</td>\n","      <td>0.702290</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.642500</td>\n","      <td>0.509988</td>\n","      <td>0.796094</td>\n","      <td>0.748877</td>\n","      <td>0.755378</td>\n","      <td>0.755107</td>\n","      <td>0.758744</td>\n","      <td>0.851107</td>\n","      <td>0.684466</td>\n","      <td>0.867560</td>\n","      <td>0.863384</td>\n","      <td>0.871776</td>\n","      <td>0.620327</td>\n","      <td>0.550830</td>\n","      <td>0.709893</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.642500</td>\n","      <td>0.501743</td>\n","      <td>0.810689</td>\n","      <td>0.771179</td>\n","      <td>0.768905</td>\n","      <td>0.775569</td>\n","      <td>0.801909</td>\n","      <td>0.845070</td>\n","      <td>0.762943</td>\n","      <td>0.873743</td>\n","      <td>0.868567</td>\n","      <td>0.878981</td>\n","      <td>0.637885</td>\n","      <td>0.613071</td>\n","      <td>0.664792</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/6/checkpoint-292\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/6/checkpoint-292/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/6/checkpoint-292/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/6/checkpoint-584\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/6/checkpoint-584/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/6/checkpoint-584/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/6/checkpoint-876\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/6/checkpoint-876/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/6/checkpoint-876/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/6/checkpoint-876 (score: 0.5017426609992981).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_6\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_6/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_6/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"output_type":"stream","name":"stdout","text":["16-Feb-2022 (18:11:00.075334)\n","None\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 876\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='876' max='876' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [876/876 04:00, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.576684</td>\n","      <td>0.764542</td>\n","      <td>0.720016</td>\n","      <td>0.715439</td>\n","      <td>0.729437</td>\n","      <td>0.713043</td>\n","      <td>0.783702</td>\n","      <td>0.654072</td>\n","      <td>0.841826</td>\n","      <td>0.822658</td>\n","      <td>0.861908</td>\n","      <td>0.605178</td>\n","      <td>0.581950</td>\n","      <td>0.630337</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.643700</td>\n","      <td>0.527057</td>\n","      <td>0.779352</td>\n","      <td>0.722791</td>\n","      <td>0.759177</td>\n","      <td>0.723782</td>\n","      <td>0.736148</td>\n","      <td>0.842052</td>\n","      <td>0.653906</td>\n","      <td>0.852174</td>\n","      <td>0.870789</td>\n","      <td>0.834338</td>\n","      <td>0.580052</td>\n","      <td>0.458506</td>\n","      <td>0.789286</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.643700</td>\n","      <td>0.502730</td>\n","      <td>0.799099</td>\n","      <td>0.755957</td>\n","      <td>0.755067</td>\n","      <td>0.758927</td>\n","      <td>0.782359</td>\n","      <td>0.820926</td>\n","      <td>0.747253</td>\n","      <td>0.867372</td>\n","      <td>0.865605</td>\n","      <td>0.869145</td>\n","      <td>0.618142</td>\n","      <td>0.590249</td>\n","      <td>0.648803</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/7/checkpoint-292\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/7/checkpoint-292/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/7/checkpoint-292/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/7/checkpoint-584\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/7/checkpoint-584/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/7/checkpoint-584/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/7/checkpoint-876\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/7/checkpoint-876/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/7/checkpoint-876/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/7/checkpoint-876 (score: 0.502730131149292).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_7\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_7/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_7/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"output_type":"stream","name":"stdout","text":["16-Feb-2022 (18:15:19.584870)\n","None\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 876\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='876' max='876' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [876/876 03:53, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.573379</td>\n","      <td>0.764756</td>\n","      <td>0.712331</td>\n","      <td>0.721436</td>\n","      <td>0.705278</td>\n","      <td>0.708989</td>\n","      <td>0.702213</td>\n","      <td>0.715897</td>\n","      <td>0.843474</td>\n","      <td>0.864865</td>\n","      <td>0.823115</td>\n","      <td>0.584530</td>\n","      <td>0.548755</td>\n","      <td>0.625296</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.642800</td>\n","      <td>0.515549</td>\n","      <td>0.789654</td>\n","      <td>0.739826</td>\n","      <td>0.752624</td>\n","      <td>0.730187</td>\n","      <td>0.743354</td>\n","      <td>0.731388</td>\n","      <td>0.755717</td>\n","      <td>0.862372</td>\n","      <td>0.889670</td>\n","      <td>0.836699</td>\n","      <td>0.613751</td>\n","      <td>0.569502</td>\n","      <td>0.665455</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.642800</td>\n","      <td>0.514489</td>\n","      <td>0.811977</td>\n","      <td>0.770799</td>\n","      <td>0.771701</td>\n","      <td>0.772273</td>\n","      <td>0.790005</td>\n","      <td>0.826962</td>\n","      <td>0.756210</td>\n","      <td>0.876525</td>\n","      <td>0.877823</td>\n","      <td>0.875231</td>\n","      <td>0.645868</td>\n","      <td>0.612033</td>\n","      <td>0.683662</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/8/checkpoint-292\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/8/checkpoint-292/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/8/checkpoint-292/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/8/checkpoint-584\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/8/checkpoint-584/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/8/checkpoint-584/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/8/checkpoint-876\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/8/checkpoint-876/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/8/checkpoint-876/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/8/checkpoint-876 (score: 0.514488935470581).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_8\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_8/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_8/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"output_type":"stream","name":"stdout","text":["16-Feb-2022 (18:19:27.935093)\n","None\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 876\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='876' max='876' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [876/876 03:55, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.587254</td>\n","      <td>0.751663</td>\n","      <td>0.692881</td>\n","      <td>0.716474</td>\n","      <td>0.677056</td>\n","      <td>0.650768</td>\n","      <td>0.617706</td>\n","      <td>0.687570</td>\n","      <td>0.832719</td>\n","      <td>0.878193</td>\n","      <td>0.791722</td>\n","      <td>0.595156</td>\n","      <td>0.535270</td>\n","      <td>0.670130</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.645000</td>\n","      <td>0.510989</td>\n","      <td>0.790084</td>\n","      <td>0.734677</td>\n","      <td>0.759143</td>\n","      <td>0.726809</td>\n","      <td>0.741519</td>\n","      <td>0.780684</td>\n","      <td>0.706096</td>\n","      <td>0.863620</td>\n","      <td>0.895594</td>\n","      <td>0.833850</td>\n","      <td>0.598891</td>\n","      <td>0.504149</td>\n","      <td>0.737481</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.645000</td>\n","      <td>0.514052</td>\n","      <td>0.799313</td>\n","      <td>0.756921</td>\n","      <td>0.759564</td>\n","      <td>0.755902</td>\n","      <td>0.780822</td>\n","      <td>0.802817</td>\n","      <td>0.760000</td>\n","      <td>0.864805</td>\n","      <td>0.871529</td>\n","      <td>0.858184</td>\n","      <td>0.625137</td>\n","      <td>0.593361</td>\n","      <td>0.660508</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/9/checkpoint-292\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/9/checkpoint-292/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/9/checkpoint-292/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/9/checkpoint-584\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/9/checkpoint-584/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/9/checkpoint-584/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/9/checkpoint-876\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/9/checkpoint-876/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/9/checkpoint-876/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/9/checkpoint-584 (score: 0.5109890103340149).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_9\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_9/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_9/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"output_type":"stream","name":"stdout","text":["16-Feb-2022 (18:23:39.242306)\n","None\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 876\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='876' max='876' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [876/876 03:56, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.567810</td>\n","      <td>0.772269</td>\n","      <td>0.717620</td>\n","      <td>0.727338</td>\n","      <td>0.710539</td>\n","      <td>0.698237</td>\n","      <td>0.697183</td>\n","      <td>0.699294</td>\n","      <td>0.854513</td>\n","      <td>0.876342</td>\n","      <td>0.833744</td>\n","      <td>0.600112</td>\n","      <td>0.558091</td>\n","      <td>0.648975</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.642700</td>\n","      <td>0.508566</td>\n","      <td>0.791372</td>\n","      <td>0.744450</td>\n","      <td>0.748761</td>\n","      <td>0.740663</td>\n","      <td>0.741040</td>\n","      <td>0.738431</td>\n","      <td>0.743668</td>\n","      <td>0.865972</td>\n","      <td>0.876712</td>\n","      <td>0.855491</td>\n","      <td>0.626338</td>\n","      <td>0.606846</td>\n","      <td>0.647124</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.642700</td>\n","      <td>0.501317</td>\n","      <td>0.805538</td>\n","      <td>0.759158</td>\n","      <td>0.761298</td>\n","      <td>0.759047</td>\n","      <td>0.773411</td>\n","      <td>0.801811</td>\n","      <td>0.746954</td>\n","      <td>0.877968</td>\n","      <td>0.883006</td>\n","      <td>0.872987</td>\n","      <td>0.626096</td>\n","      <td>0.592324</td>\n","      <td>0.663953</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/10/checkpoint-292\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/10/checkpoint-292/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/10/checkpoint-292/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/10/checkpoint-584\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/10/checkpoint-584/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/10/checkpoint-584/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/10/checkpoint-876\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/10/checkpoint-876/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/10/checkpoint-876/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/10/checkpoint-876 (score: 0.5013169646263123).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_10\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_10/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_10/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["16-Feb-2022 (18:27:53.269965)\n","None\n"]}],"source":["result_list = []\n","for i in range(1,11):\n","\n","  training_args = TrainingArguments(\n","    output_dir='/content/drive/MyDrive/Dissertation/disbert_hate_optimal/results/'+str(i),          # output directory\n","    num_train_epochs=EPOCHS,              # total number of training epochs\n","    save_strategy =\"epoch\" ,\n","    per_device_train_batch_size=BATCH_SIZE,  # batch size per device during training\n","    per_device_eval_batch_size=EVAL_BATCH_SIZE ,   # batch size for evaluation\n","    weight_decay= WEIGHT_DECAY,               # strength of weight decay\n","    learning_rate= LEARNING_RATE, \n","    warmup_steps = WARMUP_STEPS,\n","    logging_dir='./disbert_hate_optimal/logs',     # directory for storing logs\n","    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n","    evaluation_strategy=\"epoch\",\n","  )\n","\n","  hatetwit_dataset_dfs = load_from_disk('/content/drive/MyDrive/Dissertation/datasets/hatetwit_'+str(i))\n","  train_dataset = hatetwit_dataset_dfs [\"train\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","  eval_dataset = hatetwit_dataset_dfs [\"validation\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","  test_dataset = hatetwit_dataset_dfs [\"test\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","  model = model_init()\n","  parameters = get_optimizer_parameters_with_llrd(model, LEARNING_RATE, 0.95)\n","  trainer = Trainer(\n","      model=model,                         # the instantiated Transformers model to be trained\n","      args=training_args,                  # training arguments, defined above\n","      train_dataset= train_dataset,         # training dataset\n","      eval_dataset=eval_dataset,          # evaluation dataset\n","      compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n","  )\n","  trainer.create_optimizer()\n","  trainer.optimizer = AdamW(parameters, lr=LEARNING_RATE,weight_decay=WEIGHT_DECAY)\n","  trainer.train()\n","  trainer.save_model('/content/drive/MyDrive/Dissertation/disbert_hate_optimal/models/model_'+str(i))\n","  results = trainer.evaluate(test_dataset)\n","  results[\"model_run\"] = i\n","  result_list.append(results)\n","  print(timestamp())"]},{"cell_type":"code","source":["timestamp()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Qoci1RQLlm5","executionInfo":{"status":"ok","timestamp":1645036073703,"user_tz":0,"elapsed":8,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"7aa933b3-c340-4a35-baae-02e66bc3ae31"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["16-Feb-2022 (18:27:53.276665)\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"uGVY-cSu593H","executionInfo":{"status":"ok","timestamp":1645036074920,"user_tz":0,"elapsed":1221,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["results_df = pd.DataFrame(result_list)\n","results_df.to_csv('/content/drive/MyDrive/Dissertation/results/distilbert_optimal.csv')"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"GskO2Y_U6USH","colab":{"base_uri":"https://localhost:8080/","height":145},"executionInfo":{"status":"ok","timestamp":1645036074921,"user_tz":0,"elapsed":28,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"b9420fef-b097-4476-c2b6-4482837ecda5"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-a164b486-abfe-4f76-abfd-46d393630401\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eval_loss</th>\n","      <th>eval_accuracy</th>\n","      <th>eval_f1</th>\n","      <th>eval_precision</th>\n","      <th>eval_recall</th>\n","      <th>eval_hate_f1</th>\n","      <th>eval_hate_recall</th>\n","      <th>eval_hate_precision</th>\n","      <th>eval_offensive_f1</th>\n","      <th>eval_offensive_recall</th>\n","      <th>eval_offensive_precision</th>\n","      <th>eval_normal_f1</th>\n","      <th>eval_normal_recall</th>\n","      <th>eval_normal_precision</th>\n","      <th>eval_runtime</th>\n","      <th>eval_samples_per_second</th>\n","      <th>eval_steps_per_second</th>\n","      <th>epoch</th>\n","      <th>model_run</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>8</th>\n","      <td>0.506524</td>\n","      <td>0.788321</td>\n","      <td>0.734842</td>\n","      <td>0.758074</td>\n","      <td>0.729427</td>\n","      <td>0.75566</td>\n","      <td>0.806647</td>\n","      <td>0.710736</td>\n","      <td>0.858014</td>\n","      <td>0.886296</td>\n","      <td>0.83148</td>\n","      <td>0.590853</td>\n","      <td>0.495337</td>\n","      <td>0.732006</td>\n","      <td>3.8016</td>\n","      <td>1225.283</td>\n","      <td>76.81</td>\n","      <td>3.0</td>\n","      <td>9</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a164b486-abfe-4f76-abfd-46d393630401')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a164b486-abfe-4f76-abfd-46d393630401 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a164b486-abfe-4f76-abfd-46d393630401');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   eval_loss  eval_accuracy   eval_f1  ...  eval_steps_per_second  epoch  model_run\n","8   0.506524       0.788321  0.734842  ...                  76.81    3.0          9\n","\n","[1 rows x 19 columns]"]},"metadata":{},"execution_count":10}],"source":["#Sort rows to determine the mix, max and median \n","results_df = results_df.sort_values(by=['eval_f1'])\n","#Print min values\n","results_df.head(1)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"6ekob4bg6X7y","colab":{"base_uri":"https://localhost:8080/","height":145},"executionInfo":{"status":"ok","timestamp":1645036074922,"user_tz":0,"elapsed":24,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"fdd47aa1-5e9c-4965-b453-fad1c6a36ca2"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-9ed969d7-60bc-49e3-9a1f-916489f82d07\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eval_loss</th>\n","      <th>eval_accuracy</th>\n","      <th>eval_f1</th>\n","      <th>eval_precision</th>\n","      <th>eval_recall</th>\n","      <th>eval_hate_f1</th>\n","      <th>eval_hate_recall</th>\n","      <th>eval_hate_precision</th>\n","      <th>eval_offensive_f1</th>\n","      <th>eval_offensive_recall</th>\n","      <th>eval_offensive_precision</th>\n","      <th>eval_normal_f1</th>\n","      <th>eval_normal_recall</th>\n","      <th>eval_normal_precision</th>\n","      <th>eval_runtime</th>\n","      <th>eval_samples_per_second</th>\n","      <th>eval_steps_per_second</th>\n","      <th>epoch</th>\n","      <th>model_run</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>0.494083</td>\n","      <td>0.816015</td>\n","      <td>0.774754</td>\n","      <td>0.776479</td>\n","      <td>0.776579</td>\n","      <td>0.791429</td>\n","      <td>0.836858</td>\n","      <td>0.750678</td>\n","      <td>0.880178</td>\n","      <td>0.881481</td>\n","      <td>0.878877</td>\n","      <td>0.652655</td>\n","      <td>0.611399</td>\n","      <td>0.699881</td>\n","      <td>3.8453</td>\n","      <td>1211.344</td>\n","      <td>75.937</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ed969d7-60bc-49e3-9a1f-916489f82d07')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9ed969d7-60bc-49e3-9a1f-916489f82d07 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9ed969d7-60bc-49e3-9a1f-916489f82d07');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   eval_loss  eval_accuracy   eval_f1  ...  eval_steps_per_second  epoch  model_run\n","3   0.494083       0.816015  0.774754  ...                 75.937    3.0          4\n","\n","[1 rows x 19 columns]"]},"metadata":{},"execution_count":11}],"source":["#Print max values \n","results_df.tail(1)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"GnlGqulr6jjJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645036074922,"user_tz":0,"elapsed":23,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"993a5a9d-3e89-4265-a02d-b1f6175d17f3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7618399478997824"]},"metadata":{},"execution_count":12}],"source":["#Print median f1\n","results_df[\"eval_f1\"].median()"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"bcF2Dhgf6ldi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645036074923,"user_tz":0,"elapsed":22,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"85ca65dd-2cb2-456d-e45b-4722b2649107"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["eval_loss                      0.504369\n","eval_accuracy                  0.805109\n","eval_f1                        0.761280\n","eval_precision                 0.765112\n","eval_recall                    0.761491\n","eval_hate_f1                   0.785894\n","eval_hate_recall               0.821249\n","eval_hate_precision            0.753686\n","eval_offensive_f1              0.871708\n","eval_offensive_recall          0.877630\n","eval_offensive_precision       0.866014\n","eval_normal_f1                 0.626238\n","eval_normal_recall             0.585596\n","eval_normal_precision          0.675637\n","eval_runtime                   3.781160\n","eval_samples_per_second     1232.009700\n","eval_steps_per_second         77.232000\n","epoch                          3.000000\n","model_run                      5.500000\n","dtype: float64"]},"metadata":{},"execution_count":13}],"source":["#Print average values\n","results_df.mean()"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"wAgbASEh6nsb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645036074923,"user_tz":0,"elapsed":20,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"5fcd5b6b-1dad-40de-adf2-8c03448c6379"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["eval_loss                    0.014501\n","eval_accuracy                0.008251\n","eval_f1                      0.011394\n","eval_precision               0.007555\n","eval_recall                  0.013116\n","eval_hate_f1                 0.012564\n","eval_hate_recall             0.013769\n","eval_hate_precision          0.017806\n","eval_offensive_f1            0.006802\n","eval_offensive_recall        0.007520\n","eval_offensive_precision     0.013224\n","eval_normal_f1               0.016994\n","eval_normal_recall           0.034730\n","eval_normal_precision        0.026468\n","eval_runtime                 0.038644\n","eval_samples_per_second     12.558955\n","eval_steps_per_second        0.787235\n","epoch                        0.000000\n","model_run                    3.027650\n","dtype: float64"]},"metadata":{},"execution_count":14}],"source":["results_df.std()"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"UKVEXp3A6pW1","colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"status":"ok","timestamp":1645036075477,"user_tz":0,"elapsed":571,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"7bcee3c4-32a0-4b76-e047-a2cd6b74e010"},"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deVyVdfr/8dfFjuAuuIAIKriLC2pp7rmkjVqay7Ro1pSO5lLTVPObmRqrmWpMzbJMW+fbYmllpuaaikuWqLhvCO6KigtuKMvn98c5wFEBUTnecM71fDx4yLnPfZ9zocib+/O57+sjxhiUUkqpa3lYXYBSSqniSQNCKaVUnjQglFJK5UkDQimlVJ40IJRSSuXJy+oCikqlSpVMeHi41WUopVSJsn79+pPGmKC8nnOZgAgPDycuLs7qMpRSqkQRkf35PadDTEoppfKkAaGUUipPGhBKKaXy5NSAEJHuIrJLRBJE5MV89ukvIttFZJuIfOWwfbCI7LF/DHZmnUoppa7ntElqEfEEpgBdgEPAOhGZY4zZ7rBPJPAS0MYYc1pEgu3bKwAvAzGAAdbbjz3trHqVUkpdzZlnEC2BBGNMojHmCjAD6H3NPn8CpmT/4DfGHLdv7wYsNsacsj+3GOjuxFqVUkpdw5kBEQIcdHh8yL7NURQQJSKrRWStiHS/iWMRkadEJE5E4k6cOFGEpSullLL6PggvIBLoAIQCsSLSqLAHG2OmAdMAYmJitG+5Usq9nD0MCUvAZELM0CJ/eWcGxGGgusPjUPs2R4eA34wx6UCSiOzGFhiHsYWG47HLnVapUkqVBBmX4cCvtlBIWArH7VO6oS1KXECsAyJFJALbD/yBwB+v2Wc2MAj4VEQqYRtySgT2Av8WkfL2/bpim8xWSin3cirRFgYJSyApFtIvgqcPhN0NXV6F2vdCcD2nvLXTAsIYkyEiI4GFgCfwiTFmm4iMA+KMMXPsz3UVke1AJvC8MSYFQERexRYyAOOMMaecVatSShUbVy7CvlX2s4TFtoAAKB8OTR62BUL4PeAb6PRSxFWWHI2JiTHai0kpVeIYAyd3w57FtlDYvwYyL4OXP0S0tQVC7XuhQk0QKfK3F5H1xpiYvJ6zepJaKaXcT1oqJK3InUs4a79os1IdaPknqN0ZwlqDt5+lZWpAKKWUsxkDxzbnBsLB3yArA3xKQ8320PY5WyiUC7O60qtoQCillDNcPAV7f7EFwt6lcD7Ztr1KI2j9DNTuAtVbgqe3tXUWQANCKaWKQlYmHNloO0vYsxgOrwcM+JeHWp1s8wi1OkHpKlZXWmgaEEopdavOJdvODhKW2M4WLp0GBEKaQ/sXILILVGsKHp5WV3pLNCCUUqqwMtPh4O+2y08TlsCxLbbtAcEQdZ9tHqFWJyhVwdo6i4gGhFJKFeTMQfvk8hJIXAFXzoF4Qthd0PmftqGjyo3Aw/WW19GAUEopR+lpcGBN7t3LJ3batpcJhUZ9bYEQ0Q78ylpb5x2gAaGUUil7c88SklZCxiVbO4sabaDpo7ZQCKrjlBvVijMNCKWU+7lywRYE2aFwOsm2vUJNaPaYvZ1FG/AJsLZOi2lAAJ+sSqJn46pULmPtXYtKKScxxjZUlN3O4sCvkHkFvEvZhovuHmGbXK5Yy+pKixW3D4jE46mcW/Aq/15YnXrRrXioa3sqlnHv3xqUcgmXzlzdziLVvtpAUD1o+ZTtEtSwu8HL19o6izG3D4iaPmcZ5f0DYrJgK6Rt8eZYYC0qRDTBp1pDCK4PlRtAYGW3G39UqkTJynJoZ7HEdjmqyQTfMlCzg+2+hNqdoWyo1ZWWGNrNFSD9EpzYRXLCBrZs/BWfkzuo63mIYE7n7lOqYm5YZP8ZVPeOtNxVSuXjQoq9ncUS2w1rF+xLD1eNtndB7QKhMcW6nYXVCurmqgGRh+1HUpmweDfrd+whxv8oQ2pfpFXAMbxO7IDjOyD9gn1PsfVozwmN+hDcwDbR5en2J2dKFb2sTFsLi+x2Fkc2YmtnUcF2dpDdziIw2OpKSwwNiFsUf/AMby/axco9Jwkq7cvIjrUZ2CIE33MHIXm7bbm/5G22P1MSwGTZDvT0heC6trCoXF+HqZS6HalHHdpZLIO0MyAeEBKTu1ZCtSYltp2F1TQgbtNviSm8vWg3v+87RbWyfozqHEnf5qF4ezrcOWkfproqNJK3w/ljufv4V7AFhQ5TKZW/jCu2dtjZk8vJ9nYWgVXsgdDZNqfgIu0srKYBUQSMMaxKOMn4RbvZdPAMNSqWYsy9kfSKDsHTo4CzggspcHyb/Ywj+0/HYSrsw1QNdZhKua/T+3MDIWkFXDkPHl62q4yyh44qN9QzcCfQgChCxhiW7jjO24t3s+NoKrWDA3m2SxTdG1TBo6CgcJSVBWf2O5xp5DNMFVTH9p9Ch6mUq0m/BPtX57azOLnbtr1smC0QIrtAeFvwK2NtnW5AA8IJsrIMP289xoTFu9h74gL1q5bhua5RdKobjNzqD/D0NDi5yxYYNxqmyg4MHaZSJYEx9nYW9hvV9q2CjDTbL0Lh9+TOJVSK1F+A7jANCCfKzDL8GH+YSUv2cODURZpUL8dfutahTe2Ktx4U17qQ4nCmUcAwVfakeOUGOkylrHf53NXtLM7st22vWDv3EtQarcGnlLV1ujnLAkJEugPvAJ7AR8aYN655fgjwX8B+iyPvGWM+sj+XCdhnpzhgjOlV0HtZFRDZ0jOzmLX+EJOX7uHo2TRaRVTgL93q0CLcSRNp2cNU2cFR4DDVNWccOkylnMEY2/dgTjuLtZCVDt4BtnWXa3eGWp2hQoTVlSoHlgSEiHgCu4EuwCFgHTDIGLPdYZ8hQIwxZmQex583xhR63MTqgMiWlp7JjN8P8N6yvZw8f5l2UUE81yWK6Orl7kwBOcNU2yF5ayGGqerb5jl0mErdikunIXF57gTzuaO27cENcieXw+7SdhbFWEEB4czxh5ZAgjEm0V7EDKA3sL3Ao0o4P29PhrSJYECLMP736z6mrthL7ymr6VK/Ms92iaJeVSdPunn72e4irRp99faLpxzmNbbaQmPjF/kPUwXbg0OHqZSjrCw4Gm+fXF4Mh9bZzlh9y0KtjrmXoZapZnWlqgg48wyiH9DdGPOk/fGjQCvHswX7GcR/gBPYzjbGGmMO2p/LAOKBDOANY8zsPN7jKeApgLCwsOb79+93ytdyO86lpfPp6n1Mj03k3OUM7m9clTH3RlE7uBj8tn7VMJXDGUeBw1T24NBhKvdx/sTV7Swupti2V2uaO7kcEqO/SJRQVg0xFSYgKgLnjTGXReRpYIAxppP9uRBjzGERqQn8AnQ2xuzN7/2KyxBTfs5cvML0lYl8unofaemZPNA0lNGdIwmrWAwn6ByHqY7b5zduNEwV3ACC6+kwlSvIzIDDcbntLI7G27aXqpQ7bFSzIwQGWVunKhJWBcTdwCvGmG72xy8BGGP+k8/+nsApY8x16/iJyGfAXGPMrPzer7gHRLaT5y8zdfle/rd2P1lZhv4tqvNMp9pULetvdWk3dtUwVfbEeAFXU2VPjFeopb9dFndnDzu0s1gOl8/a2lmEtswdNqraxCXXXXZ3VgWEF7Zho87YrlJaB/zRGLPNYZ+qxpij9s8fAF4wxtwlIuWBi/Yzi0rAr0Bvxwnua5WUgMh27GwaU5YlMGPdAUSEh1uF8ecOtQkqXcIm864dpso+47jRMFVwAyhdRYeprJJx2XaVUfbk8nH7f8vSVe1nCV1sVx75l7e2TuV0Vl7m2gOYhO0y10+MMa+LyDggzhgzR0T+A/TCNs9wChhujNkpIq2BD4EswAOYZIz5uKD3KmkBke3gqYu8+8sevttwGB9PDwa3DufpdjUpH+BjdWm357phKvtZhw5TWedUkkM7i1jbmZ+HN9S4O3cuIbi+hrab0RvlSoDEE+d5Z+ke5mw6QoCPF0/cE8ETbSMo4+difex1mOrOuXLR3s7CfqNaSoJte7kw2xlCdjsLDWS3pgFRguw6do6Ji3ezYNsxyvp783T7mgxpHU4pHxf+4ajDVEXDGDi5x6GdxWrIvAxefrYgyD5LqFhL/85UDg2IEmjLobNMWLyLZbtOUCnQh+EdavNwqzD8vN2o532hhqnKX98J152GqdJSbcNF2UNHZw/YtleKyp1crtEGvEvARRDKEhoQJdj6/ad4e9Fu1uxNoUoZP0Z2qk3/mOr4eLnx1STXDlNln3k4DlOVq3F9J1xXGKYyxna/SnYgHPgVsjLAJ9C2RkJ2O4vyNayuVJUQGhAuYM3ek7y9aDfr958mtLw/oztH8kDTELw83TgoHOU5TLUdUvZcM0wVdf0ZR3Efprp4ChKX5bbGPp9s2165Ue59CdVbgVcJv7BBWUIDwkUYY1i++wRvL9rF1sOp1KwUwJguUdzfqGrh16JwN3kNUx3fntszCGzDVNd2wrVymCorE47E288SFtvWYDZZ4FfOtt5y9rrLZapaU59yKRoQLsYYw8JtyUxYvIvdyeepU7k0z3aNomv9ykXXYtzV5TVMdXyHbSWzbOVqXN8J11nDVOeP554h7P0FLp0CBEKaOay73KzkD5GpYkcDwkVlZhnmbj7CpCV7SDp5gcahZXm2SxTto4I0KG5FvsNUCWAybftkD1Nde8Zxs8NUmem2RnfZl6Ae3WTbHhCUGwg1O0JAxaL/OpVyoAHh4jIys/h+42HeWbKHw2cuEVOjPM91rcPdtfSHS5G42WGq7E64wXXBt3TuPmcP5QZC4gq4nAriaZs/yJ5LqNJY21moO0oDwk1cycjim7iDvPfLHpJTL9OmdkWe7VKH5jW0XYJTFHaYKrgenN4PJ3bYtpUJubqdhd917ceUumM0INxMWnomX6zdzwfL95Jy4Qqd6gbzbJcoGoboDyKny8qy3YuQ3QH3+DY4vhMCg213Lte+17Y4kw4BqmJCA8JNXbicwWdr9jEtNpGzl9K5r2EVxnaJIqpy6RsfrJRyCxoQbi41LZ2PVibxyaokLlzJoHd0NUbfG0VEpQCrS1NKWUwDQgFw6sIVPozdy+dr9pGeaejXLJRnOtcmtHwxXLRIKXVHaECoqxw/l8b7y/by1W8HMBgGtQxjRMfaVC7jZ3VpSqk7TANC5enImUu8+0sCM+MO4ukhPHZ3DYa1r0XFwBK2aJFS6pZpQKgCHUi5yKSlu5m98TB+3p4MbRPBn9rWpGwpF1uLQil1HQ0IVSgJx88xccke5m0+Smk/L55qW5PH74kg0FfbOyjlqjQg1E3ZfiSViUt2s3h7MuVLeTO8Qy0evSscfx83WotCKTehAaFuSfzBM0xYvJvY3ScIKu3LyI61GdiyOr5eGhRKuQoNCHVbfk86xfhFu/g96RTVyvoxqnMkfZuH4q1rUShV4mlAqNtmjGF1Qgr/XbSLTQfPUKNiKcbcG0mv6BA8dS0KpUqsggLCqb8Cikh3EdklIgki8mIezw8RkRMiEm//eNLhucEissf+MdiZdaobExHuiazE7D+35uPBMZTy8WLsN5voNimWeZuPkpXlGr9oKKVyOe0MQkQ8gd1AF+AQsA4YZIzZ7rDPECDGGDPymmMrAHFADGCA9UBzY8zp/N5PzyDurKwsw4Jtx5iweDcJx89Tv2oZnusaRae6wboWhVIliFVnEC2BBGNMojHmCjAD6F3IY7sBi40xp+yhsBjo7qQ61S3w8BB6NKrKwjHtmDggmgtXMnji8zgeeH8NK/ecwFWGLpVyZ84MiBDgoMPjQ/Zt1+orIptFZJaIVL+ZY0XkKRGJE5G4EydOFFXd6iZ4eggPNA1lybPteePBRhxPTePRj39nwLS1/J50yurylFK3werLUH4Cwo0xjbGdJXx+MwcbY6YZY2KMMTFBQUFOKVAVjrenBwNbhrHs+Q78q1cDkk5eoP+Hv/LYJ7+z6eAZq8tTSt0CZwbEYaC6w+NQ+7YcxpgUY8xl+8OPgOaFPVYVT75engxuHU7s8x35W4+6bDl0ht5TVvPk53HsOJpqdXlKqZvgzIBYB0SKSISI+AADgTmOO4hIVYeHvQD7mowsBLqKSHkRKQ90tW9TJYS/jydPtavFyhc68VyXKH5LSuG+d1Yy8qsNJBw/f+MXUEpZzmlNdowxGSIyEtsPdk/gE2PMNhEZB8QZY+YAo0SkF5ABnAKG2I89JSKvYgsZgHHGGB3QLoECfb14pnMkj90dzvSViXyyOon5W47Sp2kIYzpHEVZR16JQqrjSG+XUHZVy/jJTV+zlf7/uJzPL8FBMdZ7pVJtq5fytLk0pt6R3UqtiJzk1jSnLEvj69wMIwh9bhfHnjrUILq2LFil1J2lAqGLr0OmLvLs0gVkbDuHj6cFjrWswrF0tygf4WF2aUm5BA0IVe0knL/DOkt38uOkIAT5eDL0ngifbRlDGTxctUsqZNCBUibE7+RwTF+/m563HKOvvzVPtajKkdTgBumiRUk6hAaFKnK2HzzJh8W5+2XmcigE+DO9Qi0fuqoGft65FoVRR0oBQJdb6/aeZsHgXqxNSqFLGjxGdajMgpjo+XlY3AVDKNWhAqBJvzd6TTFi0m7j9pwkt78+ozpE82DQEL120SKnbYtl6EEoVlda1KjFz2N189ngLypfy4a+zNtN1Yiw/xh/WtSiUchINCFViiAgd6gQzZ2QbPny0Od6eHoyeEc9976xkwdZj2mJcqSKmAaFKHBGhW4Mq/Dy6LZMHNSU9M4thX6yn13urWbbruAaFUkVEA0KVWB4eQq/oaiwa247/9mvM6YtXePzTdfSb+itr9p60ujylSjydpFYu40pGFt/GHeTdX/aQnHqZ1rUq8lzXOjSvUd7q0pQqtvQqJuVW0tIz+fK3A3ywPIGT56/QsU4Qz3WtQ8OQslaXplSxowGh3NKFyxl8/us+PlyRyNlL6XRvUIWxXaKoU6W01aUpVWxoQCi3lpqWzscrk/h4VRIXrmTQK7oaY+6NIqJSgNWlKWU5DQilgNMXrvBhbCKfrUkiPdPQt1kIz3SKpHoFXbRIuS8NCKUcHD+XxgfL9/Ll2gMYDANbhDGyU20ql9G1KJT70YBQKg9HzlzivWUJfLvuIJ4ewqN31WBYh1pUCvS1ujSl7hgNCKUKcCDlIu8s3cMPGw/h5+3J423CeaptLcqW0rUolOvTgFCqEBKOn2fSkt3M3XyU0n5e/KltTR5vE05pXbRIuTANCKVuwo6jqUxYvJvF25MpX8qbYe1r8djd4fj76FoUyvVY1s1VRLqLyC4RSRCRFwvYr6+IGBGJsT8OF5FLIhJv/5jqzDqVclSvahmmPxbDjyPa0Ci0HP/5eSdt31rGZ6uTuJyRaXV5St0xTjuDEBFPYDfQBTgErAMGGWO2X7NfaWAe4AOMNMbEiUg4MNcY07Cw76dnEMpZfk86xfhFu/g96RTVyvrxTOdI+jUPxVvXolAuwKoziJZAgjEm0RhzBZgB9M5jv1eBN4E0J9ai1C1rGVGBb566iy+eaEVwGT9e+n4Lnd9ewfcbDpGpa1EoF+bMgAgBDjo8PmTflkNEmgHVjTHz8jg+QkQ2isgKEWnrxDqVuiER4Z7ISvzw59Z8MiSGQF8vnv12E90mxTJv81FdtEi5JC+r3lhEPIAJwJA8nj4KhBljUkSkOTBbRBoYY1KveY2ngKcAwsLCnFyxUrag6FS3Mh2iglmw7RgTF+9mxFcbqFe1DM91iaJzvWBExOoylSoSzjyDOAxUd3gcat+WrTTQEFguIvuAu4A5IhJjjLlsjEkBMMasB/YCUde+gTFmmjEmxhgTExQU5KQvQ6nreXgIPRpVZcGYdkwa0ISLVzJ48n9x9Hl/DSv3nNBFi5RLKFRAiEiA/Td+RCRKRHqJyI0uDl8HRIpIhIj4AAOBOdlPGmPOGmMqGWPCjTHhwFqgl32SOsg+yY2I1AQigcSb/uqUcjJPD6FP0xCWPNueN/s24uS5yzz68e8MmLaW35NOWV2eUrelsGcQsYCfiIQAi4BHgc8KOsAYkwGMBBYCO4BvjTHbRGSciPS6wfu1AzaLSDwwCxhmjNH/barY8vb0YECLMH75S3vG9W5A0skL9P/wVx79+DfiD56xujylbkmhLnMVkQ3GmGYi8gzgb4x5S0TijTFNnF9i4ehlrqo4uXQlky/W7ueDFXs5deEKvZtU41+9GlCulI/VpSl1laK4zFVE5G7gYWz3LADobaVK5cPfx5M/tatJ7F87MqpTbeZtPkq3SbEs33Xc6tKUKrTCBsQY4CXgB/swUU1gmfPKUso1BPp68WzXOswe0YYyft4M+XQdf/thCxcuZ1hdmlI3dNN3UtsnqwOvveTUajrEpIq7tPRMJizezfSViYSW9+fth5rQMqKC1WUpN3fbQ0wi8pWIlBGRAGArsF1Eni/KIpVydX7envytRz2+eepuBGHAtF/59/wdpKVrfydVPBV2iKm+/YyhD/AzEIHtSial1E1qGVGBn0e3ZVDLMKbFJtLrvVVsPXzW6rKUuk5hA8Lbft9DH2COMSYd0DuBlLpFAb5e/PuBRnz2eAvOXkqnz5TVvLNkD+mZWVaXplSOwgbEh8A+IACIFZEaQLGag1CqJOpQJ5iFY9rRo1FVJi7ZTd8P1pBw/JzVZSkF3Ea7bxHxst8MVyzoJLUq6eZtPsrfZ2/h4pVM/tq9Lo+3DsfDQ/s6KecqiknqsiIyQUTi7B9vYzubUEoVkZ6Nq7JwbDvuqV2JV+du548freXgqYtWl6XcWGGHmD4BzgH97R+pwKfOKkopdxVc2o+PBsfwVt/GbD2cyn3vrOSbdQe0+Z+yRGEDopYx5mX74j+Jxph/ATWdWZhS7kpE6N+iOj+PbkvDkDK88N0Wnvg8juOpuqaWurMKGxCXROSe7Aci0ga45JySlFIA1SuU4qsn7+Kf99dndcJJuk6KZe7mI1aXpdxIYQNiGDBFRPbZ1254D3jaaVUppQDbuhND74lg3qi21KhQipFfbeSZrzdy5uIVq0tTbqBQAWGM2WSMiQYaA42NMU2BTk6tTCmVo3ZwIN8Nb81zXaL4ectRuk6MZZk2/lNOdlMryhljUh16MD3rhHqUUvnw8vTgmc6RzB7RhnKlvHn803W89P1mzmvjP+Ukt7PkqF6grZQFGoaUZc7Ie3i6XU1mrDvIfe/E6up1yiluJyD0ujulLOLn7clLPerx7dO5jf9en7ddG/+pIlVgQIjIORFJzePjHFDtDtWolMpHi3Bb478/tgxj+sok/vDuKrYc0sZ/qmgUGBDGmNLGmDJ5fJQ2xnjdqSKVUvkL8PXidXvjv9S0dB54fzWTluzWxn/qtt3OEJNSqhjpUCeYRWPac3/jqkxaskcb/6nbpgGhlAspW8qbSQOb8v7DzTh46iI9Jq/io5WJZGXplKG6eRoQSrmgHo1sjf/aRVbitXk7GDRdG/+pm+fUgBCR7iKyS0QSROTFAvbrKyJGRGIctr1kP26XiHRzZp1KuaLg0n5MfyyGt/o1ZtuRVLpPimXG79r4TxWe0wJCRDyBKcB9QH1gkIjUz2O/0sBo4DeHbfWBgUADoDvwvv31lFI3QUToH1OdBWPa0ji0HC9+r43/VOE58wyiJZBg7/56BZgB9M5jv1eBNwHH79jewAxjzGVjTBKQYH89pdQtCC1fii+fbMXLf9DGf6rwnBkQIcBBh8eH7NtyiEgzoLoxZt7NHms//qnsRYxOnDhRNFUr5aI8PITH29gb/1UM0MZ/6oYsm6QWEQ9gAvDcrb6GMWaaMSbGGBMTFBRUdMUp5cJqBwfy3bC7r278t1Mb/6nrOTMgDgPVHR6H2rdlKw00BJbbW4jfBcyxT1Tf6Fil1G1wbPxXvpQPj3+mjf/U9ZwZEOuASBGJEBEfbJPOc7KfNMacNcZUMsaEG2PCgbVAL2NMnH2/gSLiKyIRQCTwuxNrVcotNQwpy5xn2vB0+9zGf78lplhdliomnBYQxpgMYCSwENgBfGuM2SYi40Sk1w2O3QZ8C2wHFgAjjDHahUwpJ/D18uSl++ox8+m78RBh4PS1vDZXG/8pEFe5JjomJsbExcVZXYZSJdqFyxn85+cdfLH2ALWDA5nQP5rGoeWsLks5kYisN8bE5PWc3kmtlMoR4OvFa30a8b+hLTmflsED769h4mJt/OeuNCCUUtdpFxXEwjHt6BVdjXeW7uHB99ewJ1kb/7kbDQilVJ7KlvJm4oAmfPBwMw6dvkjPd7Xxn7vRgFBKFei+RlVZNLY97SKDeG3eDgZq4z+3oQGhlLqhoNK+TH+sOf/t15gd9sZ/X2vjP5enAaGUKhQR4aGY6iwY247o6uV46fstDP1snTb+c2EaEEqpmxJSzp8vnmjFK3+oz5q9KXSdFMtPm7TxnyvSgFBK3TQPD2FImwjmj25LeMUAnvl6IyO/2sDpC9r4z5VoQCilblmtoEBmDbub57vVYeG2Y3SdpI3/XIkGhFLqtnh5ejCiY21mj2hDBXvjvxe/08Z/rkADQilVJBpUszX+G9a+Ft/GHaT7pFjWauO/Ek0DQilVZHy9PHnxvrrMHHY3nh7CoOlreVUb/5VYGhBKqSLXvEYFfh7dlkda1eDjVUnc/+4qNh86Y3VZ6iZpQCilnKKUjxev9mmojf9KMA0IpZRTaeO/kksDQinldNmN/6Y+0ozDZy7R891VTI9NJFMb/xVrGhBKqTume8OqLBzTjvZRQbw+fweDpq3lQIo2/iuuNCCUUndUUGlfpj3anPEPRbPjaCrd34nlq9+08V9xpAGhlLrjRIR+zUNZMLYdTcPK8bcftvD4Z+tI1sZ/xYoGhFLKMiHl/Pm/oa34V68GrE1MoevEWOZo479iQwNCKWUpDw9hcOtw5o9qS82gAEZ9vZER2vivWHBqQIhIdxHZJSIJIvJiHs8PE5EtIhIvIqtEpL59e7iIXLJvjxeRqc6sUyllvZpBgcx82tb4b5G98d8vO5OtLsutOS0gRMQTmALcB9QHBmUHgIOvjDGNjDFNgLeACQ7P7TXGNLF/DHNWnUqp4iO78d+PI+6hYoAPQz+L44VZmzmXlm51aW7JmWcQLYEEY0yiMeYKMAPo7biDMSbV4WEAoJcxKKWoX60MP45sw0DWKgYAABVrSURBVPAOtZi5/iD3vbNSG/9ZwJkBEQIcdHh8yL7tKiIyQkT2YjuDGOXwVISIbBSRFSLSNq83EJGnRCROROJOnDhRlLUrpSzm6+XJC91tjf+8tPGfJSyfpDbGTDHG1AJeAP5u33wUCDPGNAWeBb4SkTJ5HDvNGBNjjIkJCgq6c0Urpe6Y5jUqMH90Wx69y9b4r+fkldr47w5xZkAcBqo7PA61b8vPDKAPgDHmsjEmxf75emAvEOWkOpVSxVwpHy/G9W7I/z3RkguXM3ng/TVM0MZ/TufMgFgHRIpIhIj4AAOBOY47iEikw8OewB779iD7JDciUhOIBBKdWKtSqgRoGxnEwrHt6B1djclL9/DA+6vZrY3/nMZpAWGMyQBGAguBHcC3xphtIjJORHrZdxspIttEJB7bUNJg+/Z2wGb79lnAMGPMKWfVqpQqOcr6ezNhQBOmPtKco2fSuP/dVUyL3auN/5xAXKX/SUxMjImLi7O6DKXUHXTy/GX+9v0WFm1PpmV4BcY/FE1YxVJWl1WiiMh6Y0xMXs9ZPkmtlFK3qlKgLx8+2py3tfGfU2hAKKVKNBGhb/NQFo5tR7Ow8tr4rwhpQCilXEK1cv78b2hLxvXObfz3Y/xhPZu4DRoQSimX4eEhPHZ3buO/0TPiGfnVRk5p479bogGhlHI5VzX+236MrhNjWbpDG//dLA0IpZRLcmz8VynQhyc+18Z/N0sDQinl0rIb//3Z3viv+6SV/LpXG/8VhgaEUsrl+Xp58tfudZk5rDXenrbGf+N+0sZ/N6IBoZRyG81rlGf+6LYMvrsGn6y2Nf7bdFAb/+VHA0Ip5VZK+Xjxr94N+eKJVly8ksmDH6xhwqJd2vgvDxoQSim3dE9kJRaMaUfvJtWY/EsCfaasZtcxbfznSANCKeW2yvp7M6F/Ez58tDnHzqbxh3dX8eEKbfyXTQNCKeX2ujWowsKx7ehYN4j//LyTgdN+5UDKRavLspwGhFJKYWv8N/WR5kzoH83OY+fo/k4sX/62361bdWhAKKWUnYjwYLNQFo6xNf77fz9sZcin6zh21j0b/7n0ehDp6ekcOnSItDT3/MdVzufn50doaCje3t5Wl6KKWFaW4Yvf9vPv+Tvw8fTg1T4N6RVdDRGxurQiVdB6EC4dEElJSZQuXZqKFSu63D+qsp4xhpSUFM6dO0dERITV5SgnSTp5gee+jWfDgTP0aFSF1/o0okKAj9VlFRm3XTAoLS1Nw0E5jYhQsWJFPUN1cRGVApg5rDV/7V6HxduT3arxn0sHBKDhoJxKv7/cg6eH8OcOtZkzMrfx319nbXL5xn8uHxBKKVVU6lUtw5yR9zCiYy1mrT9E90krWbP3pNVlOY0GhBOlpKTQpEkTmjRpQpUqVQgJCcl5fOVKwQuYxMXFMWrUqBu+R+vWrYuk1uXLl3P//fcXyWsV9B4iwkcffZSzLT4+HhFh/PjxAPzzn/9kyZIlN/WaZcuWpUmTJtStW5e//OUvRV63Uo58vDx4vltdZg1vjY+XB3+c/hv/+mmbSzb+c2pAiEh3EdklIgki8mIezw8TkS0iEi8iq0SkvsNzL9mP2yUi3ZxZp7NUrFiR+Ph44uPjGTZsGGPHjs157OPjQ0ZGRr7HxsTEMHny5Bu+x5o1a4qyZKdr2LAh3377bc7jr7/+mujo6JzH48aN4957772p12zbti3x8fFs3LiRuXPnsnr16iKrV6n8NAsrz/xRbRnSOpxPV++jx+SVxLtY4z8vZ72wiHgCU4AuwCFgnYjMMcZsd9jtK2PMVPv+vYAJQHd7UAwEGgDVgCUiEmWMueWI/tdP29h+JPVWD89T/WplePkPDW7qmCFDhuDn58fGjRtp06YNAwcOZPTo0aSlpeHv78+nn35KnTp1WL58OePHj2fu3Lm88sorHDhwgMTERA4cOMCYMWNyzi4CAwM5f/48y5cv55VXXqFSpUps3bqV5s2b88UXXyAizJ8/n2effZaAgADatGlDYmIic+fOLVS9X3/9Nf/+978xxtCzZ0/efPNNMjMzeeKJJ4iLi0NEGDp0KGPHjmXy5MlMnToVLy8v6tevz4wZM657vRo1apCamkpycjLBwcEsWLCAHj16XPX3c//999OvXz/Cw8MZPHgwP/30E+np6cycOZO6devmW6u/vz9NmjTh8OHDV/3dAMyaNYu5c+fy2WefMWTIEMqUKUNcXBzHjh3jrbfeol+/foX+N1Qqm7+PJ6/0akCX+pV5fuYm+n6whhEdajGyUyQ+XiV/gMZpAQG0BBKMMYkAIjID6A3kBIQxxvEndgCQfc1tb2CGMeYykCQiCfbX+9WJ9d4xhw4dYs2aNXh6epKamsrKlSvx8vJiyZIl/O1vf+O777677pidO3eybNkyzp07R506dRg+fPh1195v3LiRbdu2Ua1aNdq0acPq1auJiYnh6aefJjY2loiICAYNGlToOo8cOcILL7zA+vXrKV++PF27dmX27NlUr16dw4cPs3XrVgDOnLH91vTGG2+QlJSEr69vzra89OvXj5kzZ9K0aVOaNWuGr69vvvtWqlSJDRs28P777zN+/Pirhqeudfr0afbs2UO7du1u+LUdPXqUVatWsXPnTnr16qUBoW5Lm9qVWDC2Hf+as53JvySwdOdxJvRvQp0qpa0u7bY4MyBCgIMOjw8Bra7dSURGAM8CPkAnh2PXXnNsSB7HPgU8BRAWFlZgMTf7m74zPfTQQ3h6egJw9uxZBg8ezJ49exAR0tPzviqiZ8+e+Pr64uvrS3BwMMnJyYSGhl61T8uWLXO2NWnShH379hEYGEjNmjVzrtMfNGgQ06ZNK1Sd69ato0OHDgQFBQHw8MMPExsbyz/+8Q8SExN55pln6NmzJ127dgWgcePGPPzww/Tp04c+ffrk+7r9+/dnwIAB7Ny5k0GDBhU4TPbggw8C0Lx5c77//vs891m5ciXR0dHs2bOHMWPGUKVKlRt+bX369MHDw4P69euTnOwelywq5yrj583b/aPp2qAy/++HLfzh3VU81zWKJ9vWxNOjZF7tZvk5kDFmijGmFvAC8PebPHaaMSbGGBOT/UOsJAgICMj5/B//+AcdO3Zk69at/PTTT/leU+/4W7anp2ee8xeF2acolC9fnk2bNtGhQwemTp3Kk08+CcC8efMYMWIEGzZsoEWLFvm+f5UqVfD29mbx4sV07ty5wPfK/poK+nratm3Lpk2b2LZtGx9//DHx8fHA1ZegXvv36vh35So3i6rioVuDKiwc045OdYNzGv/tT7lgdVm3xJkBcRio7vA41L4tPzOA7F87b/bYEuvs2bOEhNhOjj777LMif/06deqQmJjIvn37APjmm28KfWzLli1ZsWIFJ0+eJDMzk6+//pr27dtz8uRJsrKy6Nu3L6+99hobNmwgKyuLgwcP0rFjR958803Onj2bM/6fl3HjxvHmm2/mnEkVhYiICF588UXefPNNACpXrsyOHTvIysrihx9+KLL3UepGKgb68sEjzZg4wNb47753VvLF2pLX+M+ZQ0zrgEgRicD2w30g8EfHHUQk0hizx/6wJ5D9+RzgKxGZgG2SOhL43Ym1Wuavf/0rgwcP5rXXXqNnz55F/vr+/v68//77dO/enYCAAFq0aJHvvkuXLr1q2GrmzJm88cYbdOzYMWeSunfv3mzatInHH3+crCzbClz/+c9/yMzM5JFHHuHs2bMYYxg1ahTlypXL972K6vLcaw0bNozx48ezb98+3njjDe6//36CgoKIiYkpMLCUKmoiwgNNQ2kVUZEXvtvM32dvZdH2ZN7q25gqZf2sLq9QnNqLSUR6AJMAT+ATY8zrIjIOiDPGzBGRd4B7gXTgNDDSGLPNfuz/A4YCGcAYY8zPBb1XXr2YduzYQb169Yr6yypxzp8/T2BgIMYYRowYQWRkJGPHjrW6LJeh32fqRowxfLF2P/+evxNvT2Fc74b0blI8Gv+5bbM+/Y9rM3HiRD7//HOuXLlC06ZNmT59OqVKlbK6LJeh32eqsPadvMBzMzexfv/pYtP4TwNCKSfS7zN1MzKzDNNiE5m4eDdl/L1548FG3Fu/smX1uG03V6WUKm48PYThHWox55k2BJX25cn/xfH8zOLZ+E8DQimlLFC3Shl+HNGGkR1r892G4tn4TwNCKaUs4uPlwV+61eG74a3xtTf+e2XONi5dKR6N/zQglFLKYk3DyjPP3vjvszX76Plu8Wj8pwHhRB07dmThwoVXbZs0aRLDhw/P95gOHTqQPdneo0ePPHsavfLKKzntsfMze/Zstm/P7Yt4s22086NtwZVyjuzGf18+2Yq0K5n0/WANby/axZWMLMtq0oBwokGDBl3X0XTGjBmFbpg3f/78Am82K8i1AXErbbStpG3BlbvKbvz3QNMQ3v0lgT5TVrPr2DlLanGfgPj5Rfi0Z9F+/HzdEhdX6devH/PmzctZHGjfvn0cOXKEtm3bMnz4cGJiYmjQoAEvv/xynseHh4dz8qRt0ur1118nKiqKe+65h127duXsM336dFq0aEF0dDR9+/bl4sWLrFmzhjlz5vD888/TpEkT9u7dy5AhQ5g1axZgu2O6adOmNGrUiKFDh3L58uWc93v55Zdp1qwZjRo1YufOnYX+6/36669p1KgRDRs25IUXXgAgMzOTIUOG0LBhQxo1asTEiRMBmDx5MvXr16dx48YMHDgwz9erUaMGaWlpJCcnY4xhwYIF3HfffTnPO349N1t3Xm3Bs82aNYshQ4bkvMeoUaNo3bo1NWvWzHk/pZytjJ834x+KZvpjMRw/l8Yf3l3F1BV7ycy6s7cluE9AWKBChQq0bNmSn3+23QQ+Y8YM+vfvj4jw+uuvExcXx+bNm1mxYgWbN2/O93XWr1/PjBkziI+PZ/78+axbty7nuQcffJB169axadMm6tWrx8cff0zr1q3p1asX//3vf4mPj6dWrVo5+6elpTFkyBC++eYbtmzZQkZGBh988EHO89nttYcPH37DYaxs2W3Bf/nlF+Lj41m3bh2zZ88mPj4+py34li1bePzxxwFbW/CNGzeyefNmpk6dmu/rZrcFX7NmTaHbghem7ltpCz537lxefLHgXwiUKmpd6lfOafz3xs87GfDhnW3858xeTMXLfW9Y8rbZw0y9e/dmxowZfPzxxwB8++23TJs2jYyMDI4ePcr27dtp3Lhxnq+xcuVKHnjggZy7n3v16pXz3NatW/n73//OmTNnOH/+PN26Fbz43q5du4iIiCAqKgqAwYMHM2XKFMaMGQMUrr32tbQtuFLOk93478f4I/zzx610n7SSv/WsxyOtwpzeqkPPIJysd+/eLF26lA0bNnDx4kWaN29OUlIS48ePZ+nSpWzevJmePXvm2+b7RoYMGcJ7773Hli1bePnll2/5dbIVpr12YWlbcKWKhojQp2kIC8e2Iya8PP+YvZXHPvmdo2cvOfV9NSCcLDAwkI4dOzJ06NCcyenU1FQCAgIoW7YsycnJOUNQ+WnXrh2zZ8/m0qVLnDt3jp9++innuXPnzlG1alXS09P58ssvc7aXLl2ac+eun9iqU6cO+/btIyEhAYD/+7//o3379rf1NWpbcKXujKpl/fnf0Ja82qchcftO021iLLM3HnbaLy/uM8RkoUGDBvHAAw/kXNEUHR1N06ZNqVu3LtWrV6dNmzYFHt+sWTMGDBhAdHQ0wcHBV7XsfvXVV2nVqhVBQUG0atUqJxQGDhzIn/70JyZPnnzV5Kqfnx+ffvopDz30EBkZGbRo0YJhw4bd1NejbcGVso6I8OhdNWhbuxLPzdzEmG/iWbwjmXcHNsWjiFeu02Z9St0m/T5TVsnMMkxfmcj5tAz+0q3OLb1GQc369AxCKaVKKE8PYVj7Wjfe8RbpHIRSSqk8uXxAuMoQmiqe9PtLuTKXDgg/Pz9SUlL0P7FyCmMMKSkp+PmVjPWFlbpZLj0HERoayqFDhzhx4oTVpSgX5efnd9UVXUq5EpcOCG9vbyIiIqwuQymlSiSXHmJSSil16zQglFJK5UkDQimlVJ5c5k5qETkB7L+Nl6gEFK8Vw5Ur0e8v5Uy38/1VwxgTlNcTLhMQt0tE4vK73Vyp26XfX8qZnPX9pUNMSiml8qQBoZRSKk8aELmmWV2Acmn6/aWcySnfXzoHoZRSKk96BqGUUipPGhBKKaXy5PYBISKfiMhxEdlqdS3KtYhIdRFZJiLbRWSbiIy2uiblWkTET0R+F5FN9u+xfxXp67v7HISItAPOA/8zxjS0uh7lOkSkKlDVGLNBREoD64E+xpjtFpemXISICBBgjDkvIt7AKmC0MWZtUby+259BGGNigVNW16FcjzHmqDFmg/3zc8AOIMTaqpQrMTbn7Q+97R9F9lu/2weEUneCiIQDTYHfrK1EuRoR8RSReOA4sNgYU2TfYxoQSjmZiAQC3wFjjDGpVtejXIsxJtMY0wQIBVqKSJENlWtAKOVE9nHh74AvjTHfW12Pcl3GmDPAMqB7Ub2mBoRSTmKfQPwY2GGMmWB1Pcr1iEiQiJSzf+4PdAF2FtXru31AiMjXwK9AHRE5JCJPWF2TchltgEeBTiISb//oYXVRyqVUBZaJyGZgHbY5iLlF9eJuf5mrUkqpvLn9GYRSSqm8aUAopZTKkwaEUkqpPGlAKKWUypMGhFJKqTxpQCh1AyKS6XCZaryIvFiErx2unYRVceVldQFKlQCX7K0MlHIregah1C0SkX0i8paIbLH35K9t3x4uIr+IyGYRWSoiYfbtlUXkB3vv/k0i0tr+Up4iMt3ez3+R/Y5YRGSUfS2JzSIyw6IvU7kxDQilbsz/miGmAQ7PnTXGNALeAybZt70LfG6MaQx8CUy2b58MrDDGRAPNgG327ZHAFGNMA+AM0Ne+/UWgqf11hjnri1MqP3ontVI3ICLnjTGBeWzfB3QyxiTam/IdM8ZUFJGT2BYKSrdvP2qMqSQiJ4BQY8xlh9cIx9YeIdL++AXA2xjzmogswLaY1WxgtkPff6XuCD2DUOr2mHw+vxmXHT7PJHdusCcwBdvZxjoR0TlDdUdpQCh1ewY4/Pmr/fM1wED75w8DK+2fLwWGQ84iL2Xze1ER8QCqG2OWAS8AZYHrzmKUcib9jUSpG/O3r9iVbYExJvtS1/L2TpqXgUH2bc8An4rI88AJ4HH79tHANHvH4ExsYXE0n/f0BL6wh4gAk+39/pW6Y3QOQqlbZJ+DiDHGnLS6FqWcQYeYlFJK5UnPIJRSSuVJzyCUUkrlSQNCKaVUnjQglFJK5UkDQimlVJ40IJRSSuXp/wOvU2WwVW+nUwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["training_loss_min = [0.5717,0.441300,0.2683]\n","training_loss_max = [0.57460,0.442,0.2661]\n","val_loss_min = [0.570152,0.525531,0.596814]\n","val_loss_max = [0.5456659,0.504951,0.583835]\n","epoch_list=[1,2,3]\n","\n","plt.figure()\n","plt.plot(epoch_list,training_loss_min, label=\"Training Loss Min Run\")\n","plt.plot(epoch_list,val_loss_min, label=\"Validation Loss Min Run\")\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.xticks(epoch_list)\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"4_mveuvX6rdY","colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"status":"ok","timestamp":1645036075478,"user_tz":0,"elapsed":19,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"bbee75b2-6073-4cce-cc4d-766fe200b2b9"},"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["plt.figure()\n","plt.plot(epoch_list,training_loss_max, label=\"Training Loss Max Run\")\n","plt.plot(epoch_list,val_loss_max, label=\"Validation Loss Max Run\")\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.xticks(epoch_list)\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","source":["eval_loss                      0.518135\n","eval_accuracy                  0.800687\n","eval_f1                        0.756091\n","eval_precision                 0.760613\n","eval_recall                    0.757113\n","eval_hate_f1                   0.770281\n","eval_hate_recall               0.806747\n","eval_hate_precision            0.739544\n","eval_offensive_f1              0.870144\n","eval_offensive_recall          0.873296\n","eval_offensive_precision       0.867899\n","eval_normal_f1                 0.627850\n","eval_normal_recall             0.591295\n","eval_normal_precision          0.674396\n","eval_runtime                   3.881660\n","eval_samples_per_second     1200.504000\n","eval_steps_per_second         75.257000\n","epoch                          3.000000\n","model_run                      5.500000\n","dtype: float64"],"metadata":{"id":"WPyYV7Sscb3l"}}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Distilbert Experiment  HateTwit Optimal Results.ipynb","provenance":[{"file_id":"1mIc-wIhR0AZs-81UARd03TJJNrvmHGX4","timestamp":1644839537043},{"file_id":"16nhJIX25usU3-INiry6hlKgeD9v2SqdP","timestamp":1644756721306},{"file_id":"1-rZqxPTOtm21puGsZKK_FiKXeyCg7py7","timestamp":1644163561234},{"file_id":"15wylWRQJ1vxlP58OhBHUnY5fdagThMvJ","timestamp":1643406846637},{"file_id":"1B35hajBJY3fRQV7LSjqoqQ3xjdcyCzE3","timestamp":1642365829686},{"file_id":"1b0lCW2Cj6AULiE-Axh2OeZwURHR6pfcD","timestamp":1642333651961},{"file_id":"1RAjFaq-k9CLJQP5eO668UXLc0q-wjuve","timestamp":1642280213414},{"file_id":"1LzZr7GRN1SwVrNyjVX5t5PpCvio8w_kE","timestamp":1642109182548},{"file_id":"1t-qzEyxZtGn_Cnlfg2WtN-0dlgUmxfzx","timestamp":1641764210714},{"file_id":"14bEU8hCGPF8cVUA_BonJQA6Brv89DKUm","timestamp":1641252935713},{"file_id":"18Il3CpGf89tF1Z10iYX8OdfeHxxAX1Ui","timestamp":1639243141142},{"file_id":"1SHCgoRQVGtl9OiWEJGK3JgKkuxxSPy_5","timestamp":1639231968300},{"file_id":"1D-3yvF0nGnaWEZGxQj21R6fsGnyv5a5g","timestamp":1637526185003},{"file_id":"1glXr2JglKPUpN_3AGyk3GjfCtZSDNfsZ","timestamp":1637408594851},{"file_id":"1rc5hX8PBIv7GKvlxLQ35Vwf2jxLsv9f4","timestamp":1634501666668}],"mount_file_id":"1x1BojsKOAdexjEwpAlgRSijdlbyLc0kJ","authorship_tag":"ABX9TyNMH8S0J2mVzRhzeJg2CDwf"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e702f15e576e40cdaeb183cb45bd0cf5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5ee3682e64024d7d94414c3a793de9db","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_15225c39893949ad80afa54b556889f5","IPY_MODEL_18b1a10681e148749d7786c50695d59e","IPY_MODEL_5063b06045c04b12b4073b9c8fdba0a2"]}},"5ee3682e64024d7d94414c3a793de9db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"15225c39893949ad80afa54b556889f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_346f8ba1563e46f58886a0d29f2cdd89","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ed1ba6a7d6a34fb7bb6398bf12bd160d"}},"18b1a10681e148749d7786c50695d59e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_802fdb48f26343a4816aa636b9fc21c6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":483,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":483,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fde6e9b3bd6b42fdae7c481469458fa3"}},"5063b06045c04b12b4073b9c8fdba0a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7e3f25edbb8145d691a814001119b2f9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 483/483 [00:00&lt;00:00, 18.7kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_93432cace9684471af4874f0df263500"}},"346f8ba1563e46f58886a0d29f2cdd89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ed1ba6a7d6a34fb7bb6398bf12bd160d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"802fdb48f26343a4816aa636b9fc21c6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fde6e9b3bd6b42fdae7c481469458fa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7e3f25edbb8145d691a814001119b2f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"93432cace9684471af4874f0df263500":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f3277a5706024e0ba9051c2c8af26793":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b27115b0f99c4612bd4f9361c7d077e2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c0a7c19574814e299f9212882507a793","IPY_MODEL_48a7ad42b5a2432cbabe375a8a75859e","IPY_MODEL_96012a167ed54c46a158ebe9d8a95661"]}},"b27115b0f99c4612bd4f9361c7d077e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c0a7c19574814e299f9212882507a793":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9fe5717ce9b24bffb05846d7f12f0581","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f8ac26e42d3b4213877e0cfd5d4f283d"}},"48a7ad42b5a2432cbabe375a8a75859e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_08c4e741b6274f29ab6c7eeaedd2def2","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":267967963,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":267967963,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a9d741a55632420a91ccefb7c95609e3"}},"96012a167ed54c46a158ebe9d8a95661":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3e8f300315a0405f878cf4f1b031d974","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 256M/256M [00:05&lt;00:00, 55.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_172f11a07f60488fbff5c205e125b479"}},"9fe5717ce9b24bffb05846d7f12f0581":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f8ac26e42d3b4213877e0cfd5d4f283d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"08c4e741b6274f29ab6c7eeaedd2def2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a9d741a55632420a91ccefb7c95609e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3e8f300315a0405f878cf4f1b031d974":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"172f11a07f60488fbff5c205e125b479":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":0}