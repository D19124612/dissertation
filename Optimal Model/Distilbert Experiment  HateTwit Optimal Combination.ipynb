{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"F-o6bXOJ18j4","executionInfo":{"status":"ok","timestamp":1644780386295,"user_tz":0,"elapsed":18586,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1b466571-6731-4bdd-f307-69579fe50ed1"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 3.5 MB 14.0 MB/s \n","\u001b[K     |████████████████████████████████| 67 kB 4.5 MB/s \n","\u001b[K     |████████████████████████████████| 6.8 MB 81.9 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 90.8 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 58.0 MB/s \n","\u001b[K     |████████████████████████████████| 1.2 MB 14.5 MB/s \n","\u001b[K     |████████████████████████████████| 311 kB 14.3 MB/s \n","\u001b[K     |████████████████████████████████| 243 kB 86.2 MB/s \n","\u001b[K     |████████████████████████████████| 133 kB 74.4 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 84.9 MB/s \n","\u001b[K     |████████████████████████████████| 271 kB 87.5 MB/s \n","\u001b[K     |████████████████████████████████| 94 kB 4.1 MB/s \n","\u001b[K     |████████████████████████████████| 144 kB 63.8 MB/s \n","\u001b[?25h"]}],"source":["!pip install -qq transformers\n","!pip install -qq sentencepiece\n","!pip install -qq datasets\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Rz6wNlu92ge_","executionInfo":{"status":"ok","timestamp":1644780395044,"user_tz":0,"elapsed":8755,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["import transformers\n","import datasets\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup,Trainer, TrainingArguments\n","from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n","import torch\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from pylab import rcParams\n","import matplotlib.pyplot as plt\n","from matplotlib import rc\n","from sklearn.metrics import confusion_matrix, classification_report\n","from collections import defaultdict\n","import random\n","from textwrap import wrap\n","from datetime import datetime\n","from datasets import load_from_disk\n","from datasets import Dataset\n","from sklearn.metrics import accuracy_score,classification_report, confusion_matrix\n","from sklearn.metrics import precision_recall_fscore_support"]},{"cell_type":"code","source":["from torch import nn"],"metadata":{"id":"pOQkqPGp2ZTN","executionInfo":{"status":"ok","timestamp":1644780395045,"user_tz":0,"elapsed":20,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"T7IFr4-3TKaA","executionInfo":{"status":"ok","timestamp":1644780395045,"user_tz":0,"elapsed":19,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["# the model we gonna train, base uncased BERT\n","# check text classification models here: https://huggingface.co/models?filter=text-classification\n","MODEL_NAME = \"distilbert-base-uncased\"\n","# max sequence length for each document/sentence sample\n","MAX_LENGTH = 64\n","BATCH_SIZE = 16\n","EPOCHS = 3\n","LEARNING_RATE= 6.58e-5\n","WEIGHT_DECAY = 0.289\n","WARMUP_STEPS = 464\n","RANDOM_SEED=22\n","LEARNING_RATE_DECAY_MULTIPLIER = 0.95\n","REINIT_LAYERS = 2\n","\n","QA_OUTPUT_PATH= \"/content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad\"\n","\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"]},{"cell_type":"code","source":["\n","\n","def set_seed(seed):\n","    \"\"\"Set all seeds to make results reproducible (deterministic mode).\n","       When seed is None, disables deterministic mode.\n","    :param seed: an integer to your choosing\n","    \"\"\"\n","    if seed is not None:\n","        torch.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","        np.random.seed(seed)\n","        random.seed(seed)\n","\n","def compute_metrics(pred):\n","  labels = pred.label_ids\n","  preds = pred.predictions.argmax(-1)\n","  # calculate accuracy using sklearn's function\n","  acc = accuracy_score(labels, preds)\n","  precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n","  acc = accuracy_score(labels, preds)\n","  confusion_matrix = classification_report(labels, preds, digits=4,output_dict=True)\n","  return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall,\n","        'hate_f1': confusion_matrix[\"0\"][\"f1-score\"],\n","        'hate_recall': confusion_matrix[\"0\"][\"recall\"],\n","        'hate_precision': confusion_matrix[\"0\"][\"precision\"],\n","        'offensive_f1': confusion_matrix[\"1\"][\"f1-score\"],\n","        'offensive_recall': confusion_matrix[\"1\"][\"recall\"],\n","        'offensive_precision': confusion_matrix[\"1\"][\"precision\"],\n","        'normal_f1': confusion_matrix[\"2\"][\"f1-score\"],\n","        'normal_recall': confusion_matrix[\"2\"][\"recall\"],\n","        'normal_precision': confusion_matrix[\"2\"][\"precision\"],    \n","  }\n","\n","\n","def model_init():\n","  temp_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME,num_labels=3).to(device)\n","  return temp_model\n","\n","# Code modified from Stabilizer library to handle DistilBERT architecture\n","#https://github.com/flowerpot-ai/stabilizer\n","\n","\n","def get_optimizer_parameters_with_llrd(model, peak_lr, multiplicative_factor):\n","    num_encoder_layers = len(model.distilbert.transformer.layer)\n","    # Task specific layer gets the peak_lr\n","    tsl_parameters = [\n","        {\n","            \"params\": [param for name, param in model.named_parameters() if 'distilbert' not in name],\n","            \"param_names\": [name for name, param in model.named_parameters() if 'distilbert' not in name],\n","            \"lr\": peak_lr,\n","            \"name\": \"tsl\",\n","        }\n","    ]\n","\n","    # Starting from the last encoder layer each encoder layers get a lr defined by\n","    # current_layer_lr = prev_layer_lr * multiplicative_factor\n","    # the last encoder layer lr = peak_lr * multiplicative_factor\n","    encoder_parameters = [\n","        {\n","            \"params\": [param for name, param in model.named_parameters() if f\"distilbert.transformer.layer.{layer_num}\" in name],\n","            \"param_names\": [name for name, param in model.named_parameters() if f\"distilbert.transformer.layer.{layer_num}\" in name],\n","            \"lr\": peak_lr * (multiplicative_factor ** (num_encoder_layers - layer_num)),\n","            \"name\": f\"layer_{layer_num}\",\n","        }\n","        for layer_num, layer in enumerate(model.distilbert.transformer.layer)\n","    ]\n","\n","    # Embedding layer gets embedding layer lr = first encoder layer lr * multiplicative_factor\n","    embedding_parameters = [\n","        {\n","            \"params\": [param for name, param in model.named_parameters() if 'embeddings' in name],\n","            \"param_names\": [name for name, param in model.named_parameters() if 'embeddings' in name],\n","            \"lr\": peak_lr * (multiplicative_factor ** (num_encoder_layers + 1)),\n","            \"name\": \"embedding\",\n","        }\n","    ]\n","    return tsl_parameters + encoder_parameters + embedding_parameters\n","\n","def reinit_autoencoder_model(model, reinit_num_layers=0):\n","    \"\"\"reinitialize autoencoder model layers\"\"\"\n","\n","    if reinit_num_layers:\n","        for layer in model.distilbert.transformer.layer[-reinit_num_layers:]:\n","            for module in layer.modules():\n","                if isinstance(module, nn.Embedding):\n","                  if module.weight.requires_grad:\n","                    module.weight.data.normal_(mean=0.0, std=model.config.initializer_range)\n","                if isinstance(module, nn.Linear):\n","                  module.weight.data.normal_(mean=0.0, std=model.config.initializer_range)\n","                elif isinstance(module, nn.LayerNorm):\n","                  module.bias.data.zero_()\n","                  module.weight.data.fill_(1.0)\n","                if isinstance(module, nn.Linear) and module.bias is not None:\n","                  module.bias.data.zero_()\n","\n","    return model\n","\n","def seq_model_init():\n","  temp_model =  AutoModelForSequenceClassification.from_pretrained(QA_OUTPUT_PATH,num_labels=3).to(device)\n","  return temp_model\n","\n","def timestamp():\n","    dateTimeObj = datetime.now()\n","    timestampStr = dateTimeObj.strftime(\"%d-%b-%Y (%H:%M:%S.%f)\")\n","    print(timestampStr)"],"metadata":{"id":"YoKXcvyo_X47","executionInfo":{"status":"ok","timestamp":1644780395046,"user_tz":0,"elapsed":20,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["set_seed(RANDOM_SEED)\n"],"metadata":{"id":"lqKiS7jbkC4x","executionInfo":{"status":"ok","timestamp":1644780395046,"user_tz":0,"elapsed":19,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"id":"zRoEfiYqQIEO","executionInfo":{"status":"ok","timestamp":1644780402384,"user_tz":0,"elapsed":7357,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["hatetwit_dataset_dfs = load_from_disk('/content/drive/MyDrive/Dissertation/datasets/hatetwit_'+str(1))\n","train_dataset = hatetwit_dataset_dfs [\"train\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","eval_dataset = hatetwit_dataset_dfs [\"validation\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","test_dataset = hatetwit_dataset_dfs [\"test\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"aum4jWZzXdgX","executionInfo":{"status":"ok","timestamp":1644780402385,"user_tz":0,"elapsed":9,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir='/content/drive/MyDrive/Dissertation/disbert_optimal/results',          # output directory\n","    num_train_epochs=EPOCHS,              # total number of training epochs\n","    save_strategy =\"epoch\" ,\n","    per_device_train_batch_size=BATCH_SIZE,  # batch size per device during training\n","    per_device_eval_batch_size=BATCH_SIZE,   # batch size for evaluation\n","    warmup_steps = WARMUP_STEPS,\n","    weight_decay= WEIGHT_DECAY,               # strength of weight decay\n","    learning_rate= LEARNING_RATE, \n","    logging_dir='./disbert_optimal/logs',     # directory for storing logs\n","    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n","    evaluation_strategy=\"epoch\",\n",")\n","\n","results = []"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"PLMUUequ6kV6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644780420331,"user_tz":0,"elapsed":17954,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"eccb1b20-d8e2-4e6c-cec0-12c49a606189"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad were not used when initializing DistilBertForSequenceClassification: ['qa_outputs.bias', 'qa_outputs.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}],"source":["#Model to test combination of Intermediate Task Transfer,  Weight Reinitialization and LLRD\n","\n","model = seq_model_init()\n","model = reinit_autoencoder_model(model,2)\n","parameters = get_optimizer_parameters_with_llrd(model, LEARNING_RATE, LEARNING_RATE_DECAY_MULTIPLIER)\n","trainer_one = Trainer(\n","    model =model,                         # the instantiated Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=eval_dataset,          # evaluation dataset\n","    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",")\n","trainer_one.create_optimizer()\n","trainer_one.optimizer = AdamW(parameters, lr=LEARNING_RATE,weight_decay=WEIGHT_DECAY)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"UbOulfz660XD","colab":{"base_uri":"https://localhost:8080/","height":832},"executionInfo":{"status":"ok","timestamp":1644780772693,"user_tz":0,"elapsed":352374,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"99f2483e-1e11-42a4-e2de-35ffcd5a6820"},"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:51, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.568000</td>\n","      <td>0.532807</td>\n","      <td>0.780425</td>\n","      <td>0.737912</td>\n","      <td>0.733917</td>\n","      <td>0.745411</td>\n","      <td>0.729302</td>\n","      <td>0.788732</td>\n","      <td>0.678201</td>\n","      <td>0.853590</td>\n","      <td>0.838578</td>\n","      <td>0.869148</td>\n","      <td>0.630844</td>\n","      <td>0.608921</td>\n","      <td>0.654404</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.444100</td>\n","      <td>0.485599</td>\n","      <td>0.806825</td>\n","      <td>0.759553</td>\n","      <td>0.768172</td>\n","      <td>0.757841</td>\n","      <td>0.772447</td>\n","      <td>0.817907</td>\n","      <td>0.731773</td>\n","      <td>0.876027</td>\n","      <td>0.888190</td>\n","      <td>0.864193</td>\n","      <td>0.630184</td>\n","      <td>0.567427</td>\n","      <td>0.708549</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.295300</td>\n","      <td>0.546233</td>\n","      <td>0.805967</td>\n","      <td>0.762902</td>\n","      <td>0.762476</td>\n","      <td>0.765756</td>\n","      <td>0.780698</td>\n","      <td>0.821932</td>\n","      <td>0.743403</td>\n","      <td>0.874420</td>\n","      <td>0.872640</td>\n","      <td>0.876208</td>\n","      <td>0.633588</td>\n","      <td>0.602697</td>\n","      <td>0.667816</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-4660 (score: 0.48559901118278503).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=6990, training_loss=0.47184749052077746, metrics={'train_runtime': 352.4872, 'train_samples_per_second': 317.16, 'train_steps_per_second': 19.831, 'total_flos': 1851182116709760.0, 'train_loss': 0.47184749052077746, 'epoch': 3.0})"]},"metadata":{},"execution_count":10}],"source":["trainer_one.train()\n"]},{"cell_type":"code","source":["timestamp()\n"],"metadata":{"id":"f6VXroG67pHI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644780772694,"user_tz":0,"elapsed":28,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"1a81b6f7-967a-44b6-ff39-892b2e125244"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["13-Feb-2022 (19:32:52.432718)\n"]}]},{"cell_type":"code","execution_count":12,"metadata":{"id":"1G57aLkv7OhH","colab":{"base_uri":"https://localhost:8080/","height":439},"executionInfo":{"status":"ok","timestamp":1644780776420,"user_tz":0,"elapsed":3751,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"2902bce3-8220-4e3f-9618-66e013912de0"},"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 3.0,\n"," 'eval_accuracy': 0.7930442249892657,\n"," 'eval_f1': 0.7444253875529426,\n"," 'eval_hate_f1': 0.7630827783063748,\n"," 'eval_hate_precision': 0.7231740306582507,\n"," 'eval_hate_recall': 0.8076535750251762,\n"," 'eval_loss': 0.5203225612640381,\n"," 'eval_normal_f1': 0.6066897347174163,\n"," 'eval_normal_precision': 0.6840052015604682,\n"," 'eval_normal_recall': 0.5450777202072539,\n"," 'eval_offensive_f1': 0.8635036496350365,\n"," 'eval_offensive_precision': 0.8510791366906475,\n"," 'eval_offensive_recall': 0.8762962962962964,\n"," 'eval_precision': 0.7527527896364554,\n"," 'eval_recall': 0.7430091971762421,\n"," 'eval_runtime': 3.7721,\n"," 'eval_samples_per_second': 1234.863,\n"," 'eval_steps_per_second': 77.411}"]},"metadata":{},"execution_count":12}],"source":["eval_results = trainer_one.evaluate(test_dataset)\n","results.append(eval_results)\n","eval_results"]},{"cell_type":"code","source":["timestamp()"],"metadata":{"id":"f5hWnjoncQKw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644780776421,"user_tz":0,"elapsed":15,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"ef7f6a12-ed94-4994-a5c5-a678411e4205"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["13-Feb-2022 (19:32:56.224873)\n"]}]},{"cell_type":"code","source":["#Model to test combination of Intermediate Task Transfer and LLRD\n","\n","model = seq_model_init()\n","parameters = get_optimizer_parameters_with_llrd(model, LEARNING_RATE, LEARNING_RATE_DECAY_MULTIPLIER)\n","trainer_two = Trainer(\n","    model =model,                         # the instantiated Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=eval_dataset,          # evaluation dataset\n","    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",")\n","trainer_two.create_optimizer()\n","trainer_two.optimizer = AdamW(parameters, lr=LEARNING_RATE,weight_decay=WEIGHT_DECAY)"],"metadata":{"id":"Zkk9DWHntNkD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644780777816,"user_tz":0,"elapsed":1408,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"431a4599-ff62-4741-9065-7e8f39082403"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/config.json\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForQuestionAnswering\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad were not used when initializing DistilBertForSequenceClassification: ['qa_outputs.bias', 'qa_outputs.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["trainer_two.train()"],"metadata":{"id":"uRRdsV6RtQ7b","colab":{"base_uri":"https://localhost:8080/","height":832},"executionInfo":{"status":"ok","timestamp":1644781103820,"user_tz":0,"elapsed":326024,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"038fda8b-a743-4346-e5cb-afa4b61fc4c8"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:26, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.573000</td>\n","      <td>0.544363</td>\n","      <td>0.779996</td>\n","      <td>0.733491</td>\n","      <td>0.735124</td>\n","      <td>0.735217</td>\n","      <td>0.717536</td>\n","      <td>0.761569</td>\n","      <td>0.678315</td>\n","      <td>0.855661</td>\n","      <td>0.854869</td>\n","      <td>0.856454</td>\n","      <td>0.627278</td>\n","      <td>0.589212</td>\n","      <td>0.670602</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.454400</td>\n","      <td>0.492800</td>\n","      <td>0.804035</td>\n","      <td>0.756241</td>\n","      <td>0.765484</td>\n","      <td>0.753694</td>\n","      <td>0.764313</td>\n","      <td>0.805835</td>\n","      <td>0.726860</td>\n","      <td>0.874225</td>\n","      <td>0.887819</td>\n","      <td>0.861041</td>\n","      <td>0.630184</td>\n","      <td>0.567427</td>\n","      <td>0.708549</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.307800</td>\n","      <td>0.535096</td>\n","      <td>0.809830</td>\n","      <td>0.768252</td>\n","      <td>0.768975</td>\n","      <td>0.769236</td>\n","      <td>0.776971</td>\n","      <td>0.807847</td>\n","      <td>0.748369</td>\n","      <td>0.876317</td>\n","      <td>0.877453</td>\n","      <td>0.875185</td>\n","      <td>0.651466</td>\n","      <td>0.622407</td>\n","      <td>0.683371</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-4660 (score: 0.4927995502948761).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=6990, training_loss=0.4787922172928402, metrics={'train_runtime': 326.241, 'train_samples_per_second': 342.676, 'train_steps_per_second': 21.426, 'total_flos': 1851182116709760.0, 'train_loss': 0.4787922172928402, 'epoch': 3.0})"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["eval_results = trainer_two.evaluate(test_dataset)\n","results.append(eval_results)\n","eval_results"],"metadata":{"id":"PLDtxXOutVn6","colab":{"base_uri":"https://localhost:8080/","height":439},"executionInfo":{"status":"ok","timestamp":1644781107585,"user_tz":0,"elapsed":3800,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"a4d8458c-c996-45bf-c805-1ce89ccec959"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 3.0,\n"," 'eval_accuracy': 0.7977672820953199,\n"," 'eval_f1': 0.7523209872543338,\n"," 'eval_hate_f1': 0.7608178792201616,\n"," 'eval_hate_precision': 0.7207207207207207,\n"," 'eval_hate_recall': 0.8056394763343404,\n"," 'eval_loss': 0.5314891338348389,\n"," 'eval_normal_f1': 0.6307956496851744,\n"," 'eval_normal_precision': 0.7046035805626598,\n"," 'eval_normal_recall': 0.5709844559585492,\n"," 'eval_offensive_f1': 0.8653494328576654,\n"," 'eval_offensive_precision': 0.8550253073029646,\n"," 'eval_offensive_recall': 0.8759259259259259,\n"," 'eval_precision': 0.7601165361954484,\n"," 'eval_recall': 0.7508499527396052,\n"," 'eval_runtime': 3.7954,\n"," 'eval_samples_per_second': 1227.291,\n"," 'eval_steps_per_second': 76.936}"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["#Model to test combination of Intermediate Task Transfer and  WR\n","\n","model = seq_model_init()\n","model = reinit_autoencoder_model(model,2)\n","trainer_three = Trainer(\n","    model =model,                         # the instantiated Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=eval_dataset,          # evaluation dataset\n","    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",")"],"metadata":{"id":"yNg68g8QtYf4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644781108352,"user_tz":0,"elapsed":775,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"1f25c681-bfd6-4370-d8a5-499a8257294b"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/config.json\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForQuestionAnswering\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad were not used when initializing DistilBertForSequenceClassification: ['qa_outputs.bias', 'qa_outputs.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["trainer_three.train()"],"metadata":{"id":"l1N3dwMztdXt","colab":{"base_uri":"https://localhost:8080/","height":866},"executionInfo":{"status":"ok","timestamp":1644781436750,"user_tz":0,"elapsed":328408,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"17bedd36-c69a-43e7-83fc-7f42ce0aeb04"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:28, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.572900</td>\n","      <td>0.554150</td>\n","      <td>0.769693</td>\n","      <td>0.724715</td>\n","      <td>0.721087</td>\n","      <td>0.741015</td>\n","      <td>0.712317</td>\n","      <td>0.831992</td>\n","      <td>0.622741</td>\n","      <td>0.851023</td>\n","      <td>0.816364</td>\n","      <td>0.888755</td>\n","      <td>0.610805</td>\n","      <td>0.574689</td>\n","      <td>0.651765</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.435900</td>\n","      <td>0.499295</td>\n","      <td>0.804679</td>\n","      <td>0.759300</td>\n","      <td>0.763546</td>\n","      <td>0.761576</td>\n","      <td>0.772536</td>\n","      <td>0.831992</td>\n","      <td>0.721011</td>\n","      <td>0.873546</td>\n","      <td>0.875972</td>\n","      <td>0.871134</td>\n","      <td>0.631818</td>\n","      <td>0.576763</td>\n","      <td>0.698492</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.268700</td>\n","      <td>0.576627</td>\n","      <td>0.807684</td>\n","      <td>0.765112</td>\n","      <td>0.765898</td>\n","      <td>0.766351</td>\n","      <td>0.783406</td>\n","      <td>0.816901</td>\n","      <td>0.752549</td>\n","      <td>0.874723</td>\n","      <td>0.876342</td>\n","      <td>0.873110</td>\n","      <td>0.637207</td>\n","      <td>0.605809</td>\n","      <td>0.672037</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-4660 (score: 0.49929478764533997).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=6990, training_loss=0.4599053924516888, metrics={'train_runtime': 328.3502, 'train_samples_per_second': 340.475, 'train_steps_per_second': 21.288, 'total_flos': 1851182116709760.0, 'train_loss': 0.4599053924516888, 'epoch': 3.0})"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["eval_results = trainer_three.evaluate(test_dataset)\n","results.append(eval_results)\n","eval_results"],"metadata":{"id":"JR7VmTmNtexn","colab":{"base_uri":"https://localhost:8080/","height":439},"executionInfo":{"status":"ok","timestamp":1644781440583,"user_tz":0,"elapsed":3845,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"cf112bed-a34d-495e-971b-e4b56a402fb8"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 3.0,\n"," 'eval_accuracy': 0.8035637612709318,\n"," 'eval_f1': 0.7583603592175008,\n"," 'eval_hate_f1': 0.7806026365348399,\n"," 'eval_hate_precision': 0.7329796640141468,\n"," 'eval_hate_recall': 0.8348439073514602,\n"," 'eval_loss': 0.5293312668800354,\n"," 'eval_normal_f1': 0.6246418338108882,\n"," 'eval_normal_precision': 0.6987179487179487,\n"," 'eval_normal_recall': 0.5647668393782384,\n"," 'eval_offensive_f1': 0.8698366073067743,\n"," 'eval_offensive_precision': 0.8623953403713142,\n"," 'eval_offensive_recall': 0.8774074074074074,\n"," 'eval_precision': 0.7646976510344698,\n"," 'eval_recall': 0.7590060513790352,\n"," 'eval_runtime': 3.7701,\n"," 'eval_samples_per_second': 1235.499,\n"," 'eval_steps_per_second': 77.451}"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["#Model to test combination of Weight Reinitialization and LLRD\n","\n","model = model_init()\n","model = reinit_autoencoder_model(model,2)\n","parameters = get_optimizer_parameters_with_llrd(model, LEARNING_RATE, LEARNING_RATE_DECAY_MULTIPLIER)\n","trainer_four = Trainer(\n","    model =model,                         # the instantiated Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=eval_dataset,          # evaluation dataset\n","    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",")\n","trainer_four.create_optimizer()\n","trainer_four.optimizer = AdamW(parameters, lr=LEARNING_RATE,weight_decay=WEIGHT_DECAY)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":952,"referenced_widgets":["9542032ada0f496da783a39f68125374","813cc50af3d24d4b8211b8649d83e280","9c29ad4fbe31428299ff1c61b505bf5d","f280c0e6980e485f85aa8928eae338c6","944112d54a114d519c5150e5d1ca19aa","977925ae76ec4ae5a4d4730f29adfa2a","5f1c6333830141128e8ebf1d4a1a1416","89c0a6b1e565440180731ca38b8ccaea","044305d1b2694a6cbde5f7b3c77b1285","052a03b4bad04002b981176c10926288","831b1bdf69564a3c866db0f549e1ce39","be474cbce6f345ccab3f5415474e4b8f","38a70f5e2be844069f83790ca28677df","e9b4598da5a046f09d91741c6534fe87","a2c446ca7e734cbf89dda98ff9b8baad","bfd3d8495f6647b29ab4e371a38d6d3f","9d36d01c93144b3ba0ebcd2c45876e23","2db3d69ce7a841248926d4a5f4136399","4f9284a555b343349eac7e21f71f7372","d02c515c98994b6abdd1ae26e4511e9f","4472e4c81fe04e4aa9c4bb0724f16c51","90d04c63004b4fc8abc23d4292e4d8ba"]},"id":"hpBv9JzUhAju","executionInfo":{"status":"ok","timestamp":1644781448399,"user_tz":0,"elapsed":7821,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"60f836f7-dccf-49dd-8b13-b35ddbe01e54"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["https://huggingface.co/distilbert-base-uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpalumjqtq\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9542032ada0f496da783a39f68125374","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/distilbert-base-uncased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","creating metadata file for /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpjrvu4l4m\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"be474cbce6f345ccab3f5415474e4b8f","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","creating metadata file for /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["trainer_four.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":832},"id":"2siETmFPhd9L","executionInfo":{"status":"ok","timestamp":1644781784358,"user_tz":0,"elapsed":335982,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"7cc3fd21-5afc-4693-d641-d2ea94337368"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:35, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.570900</td>\n","      <td>0.544516</td>\n","      <td>0.775918</td>\n","      <td>0.731199</td>\n","      <td>0.730040</td>\n","      <td>0.740651</td>\n","      <td>0.716204</td>\n","      <td>0.804829</td>\n","      <td>0.645161</td>\n","      <td>0.852602</td>\n","      <td>0.834136</td>\n","      <td>0.871904</td>\n","      <td>0.624792</td>\n","      <td>0.582988</td>\n","      <td>0.673054</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.441300</td>\n","      <td>0.492655</td>\n","      <td>0.804035</td>\n","      <td>0.755705</td>\n","      <td>0.766299</td>\n","      <td>0.749104</td>\n","      <td>0.765114</td>\n","      <td>0.776660</td>\n","      <td>0.753906</td>\n","      <td>0.874593</td>\n","      <td>0.895964</td>\n","      <td>0.854218</td>\n","      <td>0.627407</td>\n","      <td>0.574689</td>\n","      <td>0.690773</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.293800</td>\n","      <td>0.567789</td>\n","      <td>0.804035</td>\n","      <td>0.760210</td>\n","      <td>0.761015</td>\n","      <td>0.761807</td>\n","      <td>0.780019</td>\n","      <td>0.816901</td>\n","      <td>0.746324</td>\n","      <td>0.872667</td>\n","      <td>0.874121</td>\n","      <td>0.871218</td>\n","      <td>0.627945</td>\n","      <td>0.594398</td>\n","      <td>0.665505</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_optimal/results/checkpoint-4660 (score: 0.49265456199645996).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=6990, training_loss=0.46681851235582084, metrics={'train_runtime': 336.0465, 'train_samples_per_second': 332.677, 'train_steps_per_second': 20.801, 'total_flos': 1851182116709760.0, 'train_loss': 0.46681851235582084, 'epoch': 3.0})"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["eval_results = trainer_four.evaluate(test_dataset)\n","results.append(eval_results)\n","eval_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":439},"id":"SXaMwgJphflT","executionInfo":{"status":"ok","timestamp":1644781788194,"user_tz":0,"elapsed":3861,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"054925d5-e9ab-4995-e8ba-f9c2fdfa28ae"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 3.0,\n"," 'eval_accuracy': 0.8037784456848432,\n"," 'eval_f1': 0.7586395609940008,\n"," 'eval_hate_f1': 0.7647637795275591,\n"," 'eval_hate_precision': 0.7478344562078922,\n"," 'eval_hate_recall': 0.7824773413897281,\n"," 'eval_loss': 0.5146265029907227,\n"," 'eval_normal_f1': 0.6422018348623852,\n"," 'eval_normal_precision': 0.7188703465982028,\n"," 'eval_normal_recall': 0.5803108808290155,\n"," 'eval_offensive_f1': 0.8689530685920578,\n"," 'eval_offensive_precision': 0.8475352112676057,\n"," 'eval_offensive_recall': 0.8914814814814814,\n"," 'eval_precision': 0.7714133380245669,\n"," 'eval_recall': 0.7514232345667416,\n"," 'eval_runtime': 3.8288,\n"," 'eval_samples_per_second': 1216.575,\n"," 'eval_steps_per_second': 76.264}"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["results_df = pd.DataFrame(results)\n","results_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":239},"id":"OEqL01PThsqT","executionInfo":{"status":"ok","timestamp":1644781788196,"user_tz":0,"elapsed":20,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"2eb8ccf9-9af5-4670-cfe1-afd8fc154712"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-cdcb9196-e7fe-4396-a61c-e477d0015b0c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eval_loss</th>\n","      <th>eval_accuracy</th>\n","      <th>eval_f1</th>\n","      <th>eval_precision</th>\n","      <th>eval_recall</th>\n","      <th>eval_hate_f1</th>\n","      <th>eval_hate_recall</th>\n","      <th>eval_hate_precision</th>\n","      <th>eval_offensive_f1</th>\n","      <th>eval_offensive_recall</th>\n","      <th>eval_offensive_precision</th>\n","      <th>eval_normal_f1</th>\n","      <th>eval_normal_recall</th>\n","      <th>eval_normal_precision</th>\n","      <th>eval_runtime</th>\n","      <th>eval_samples_per_second</th>\n","      <th>eval_steps_per_second</th>\n","      <th>epoch</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.520323</td>\n","      <td>0.793044</td>\n","      <td>0.744425</td>\n","      <td>0.752753</td>\n","      <td>0.743009</td>\n","      <td>0.763083</td>\n","      <td>0.807654</td>\n","      <td>0.723174</td>\n","      <td>0.863504</td>\n","      <td>0.876296</td>\n","      <td>0.851079</td>\n","      <td>0.606690</td>\n","      <td>0.545078</td>\n","      <td>0.684005</td>\n","      <td>3.7721</td>\n","      <td>1234.863</td>\n","      <td>77.411</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.531489</td>\n","      <td>0.797767</td>\n","      <td>0.752321</td>\n","      <td>0.760117</td>\n","      <td>0.750850</td>\n","      <td>0.760818</td>\n","      <td>0.805639</td>\n","      <td>0.720721</td>\n","      <td>0.865349</td>\n","      <td>0.875926</td>\n","      <td>0.855025</td>\n","      <td>0.630796</td>\n","      <td>0.570984</td>\n","      <td>0.704604</td>\n","      <td>3.7954</td>\n","      <td>1227.291</td>\n","      <td>76.936</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.529331</td>\n","      <td>0.803564</td>\n","      <td>0.758360</td>\n","      <td>0.764698</td>\n","      <td>0.759006</td>\n","      <td>0.780603</td>\n","      <td>0.834844</td>\n","      <td>0.732980</td>\n","      <td>0.869837</td>\n","      <td>0.877407</td>\n","      <td>0.862395</td>\n","      <td>0.624642</td>\n","      <td>0.564767</td>\n","      <td>0.698718</td>\n","      <td>3.7701</td>\n","      <td>1235.499</td>\n","      <td>77.451</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.514627</td>\n","      <td>0.803778</td>\n","      <td>0.758640</td>\n","      <td>0.771413</td>\n","      <td>0.751423</td>\n","      <td>0.764764</td>\n","      <td>0.782477</td>\n","      <td>0.747834</td>\n","      <td>0.868953</td>\n","      <td>0.891481</td>\n","      <td>0.847535</td>\n","      <td>0.642202</td>\n","      <td>0.580311</td>\n","      <td>0.718870</td>\n","      <td>3.8288</td>\n","      <td>1216.575</td>\n","      <td>76.264</td>\n","      <td>3.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdcb9196-e7fe-4396-a61c-e477d0015b0c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cdcb9196-e7fe-4396-a61c-e477d0015b0c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cdcb9196-e7fe-4396-a61c-e477d0015b0c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   eval_loss  eval_accuracy  ...  eval_steps_per_second  epoch\n","0   0.520323       0.793044  ...                 77.411    3.0\n","1   0.531489       0.797767  ...                 76.936    3.0\n","2   0.529331       0.803564  ...                 77.451    3.0\n","3   0.514627       0.803778  ...                 76.264    3.0\n","\n","[4 rows x 18 columns]"]},"metadata":{},"execution_count":23}]}],"metadata":{"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Distilbert Experiment  HateTwit Optimal Combination.ipynb","provenance":[{"file_id":"16nhJIX25usU3-INiry6hlKgeD9v2SqdP","timestamp":1644761945180},{"file_id":"1-rZqxPTOtm21puGsZKK_FiKXeyCg7py7","timestamp":1644163561234},{"file_id":"15wylWRQJ1vxlP58OhBHUnY5fdagThMvJ","timestamp":1643406846637},{"file_id":"1B35hajBJY3fRQV7LSjqoqQ3xjdcyCzE3","timestamp":1642365829686},{"file_id":"1b0lCW2Cj6AULiE-Axh2OeZwURHR6pfcD","timestamp":1642333651961},{"file_id":"1RAjFaq-k9CLJQP5eO668UXLc0q-wjuve","timestamp":1642280213414},{"file_id":"1LzZr7GRN1SwVrNyjVX5t5PpCvio8w_kE","timestamp":1642109182548},{"file_id":"1t-qzEyxZtGn_Cnlfg2WtN-0dlgUmxfzx","timestamp":1641764210714},{"file_id":"14bEU8hCGPF8cVUA_BonJQA6Brv89DKUm","timestamp":1641252935713},{"file_id":"18Il3CpGf89tF1Z10iYX8OdfeHxxAX1Ui","timestamp":1639243141142},{"file_id":"1SHCgoRQVGtl9OiWEJGK3JgKkuxxSPy_5","timestamp":1639231968300},{"file_id":"1D-3yvF0nGnaWEZGxQj21R6fsGnyv5a5g","timestamp":1637526185003},{"file_id":"1glXr2JglKPUpN_3AGyk3GjfCtZSDNfsZ","timestamp":1637408594851},{"file_id":"1rc5hX8PBIv7GKvlxLQ35Vwf2jxLsv9f4","timestamp":1634501666668}],"mount_file_id":"1BVTfhafLbzLIDrms3OllUhS8HhR6Sh-1","authorship_tag":"ABX9TyMeIsKs5aY3/C9ziLH26poP"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9542032ada0f496da783a39f68125374":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_813cc50af3d24d4b8211b8649d83e280","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9c29ad4fbe31428299ff1c61b505bf5d","IPY_MODEL_f280c0e6980e485f85aa8928eae338c6","IPY_MODEL_944112d54a114d519c5150e5d1ca19aa"]}},"813cc50af3d24d4b8211b8649d83e280":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9c29ad4fbe31428299ff1c61b505bf5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_977925ae76ec4ae5a4d4730f29adfa2a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5f1c6333830141128e8ebf1d4a1a1416"}},"f280c0e6980e485f85aa8928eae338c6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_89c0a6b1e565440180731ca38b8ccaea","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":483,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":483,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_044305d1b2694a6cbde5f7b3c77b1285"}},"944112d54a114d519c5150e5d1ca19aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_052a03b4bad04002b981176c10926288","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 483/483 [00:00&lt;00:00, 18.6kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_831b1bdf69564a3c866db0f549e1ce39"}},"977925ae76ec4ae5a4d4730f29adfa2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5f1c6333830141128e8ebf1d4a1a1416":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"89c0a6b1e565440180731ca38b8ccaea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"044305d1b2694a6cbde5f7b3c77b1285":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"052a03b4bad04002b981176c10926288":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"831b1bdf69564a3c866db0f549e1ce39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"be474cbce6f345ccab3f5415474e4b8f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_38a70f5e2be844069f83790ca28677df","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e9b4598da5a046f09d91741c6534fe87","IPY_MODEL_a2c446ca7e734cbf89dda98ff9b8baad","IPY_MODEL_bfd3d8495f6647b29ab4e371a38d6d3f"]}},"38a70f5e2be844069f83790ca28677df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e9b4598da5a046f09d91741c6534fe87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9d36d01c93144b3ba0ebcd2c45876e23","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2db3d69ce7a841248926d4a5f4136399"}},"a2c446ca7e734cbf89dda98ff9b8baad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4f9284a555b343349eac7e21f71f7372","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":267967963,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":267967963,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d02c515c98994b6abdd1ae26e4511e9f"}},"bfd3d8495f6647b29ab4e371a38d6d3f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4472e4c81fe04e4aa9c4bb0724f16c51","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 256M/256M [00:04&lt;00:00, 59.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_90d04c63004b4fc8abc23d4292e4d8ba"}},"9d36d01c93144b3ba0ebcd2c45876e23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2db3d69ce7a841248926d4a5f4136399":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4f9284a555b343349eac7e21f71f7372":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d02c515c98994b6abdd1ae26e4511e9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4472e4c81fe04e4aa9c4bb0724f16c51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"90d04c63004b4fc8abc23d4292e4d8ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":0}