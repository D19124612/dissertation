{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"F-o6bXOJ18j4"},"outputs":[],"source":["!pip install -qq transformers\n","!pip install -qq optuna\n","!pip install -qq sentencepiece\n","!pip install -qq datasets\n","!pip install -qq stabilizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rz6wNlu92ge_"},"outputs":[],"source":["import transformers\n","import datasets\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification,AdamW, get_linear_schedule_with_warmup,Trainer, TrainingArguments\n","from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n","import torch\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from pylab import rcParams\n","import matplotlib.pyplot as plt\n","from matplotlib import rc\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, classification_report\n","from collections import defaultdict\n","import random\n","from textwrap import wrap\n","from datetime import datetime\n","from datasets import load_from_disk\n","from datasets import Dataset\n","from sklearn.metrics import accuracy_score,classification_report, confusion_matrix\n","from sklearn.metrics import precision_recall_fscore_support\n","from stabilizer.reinitialize import reinit_autoencoder_model\n","from stabilizer.llrd import get_optimizer_parameters_with_llrd"]},{"cell_type":"code","source":["from torch import nn"],"metadata":{"id":"pOQkqPGp2ZTN"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T7IFr4-3TKaA"},"outputs":[],"source":["# the model we gonna train, base uncased BERT\n","# check text classification models here: https://huggingface.co/models?filter=text-classification\n","MODEL_NAME = \"distilbert-base-uncased\"\n","BATCH_SIZE = 16\n","EPOCHS = 3\n","LEARNING_RATE= 6.58e-5\n","WEIGHT_DECAY = 0.289\n","WARMUP_STEPS = 464\n","RANDOM_SEED=22\n","\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"]},{"cell_type":"code","source":["def set_seed(seed):\n","    \"\"\"Set all seeds to make results reproducible (deterministic mode).\n","       When seed is None, disables deterministic mode.\n","    :param seed: an integer to your choosing\n","    \"\"\"\n","    if seed is not None:\n","        torch.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","        np.random.seed(seed)\n","        random.seed(seed)\n","\n","def compute_metrics(pred):\n","  labels = pred.label_ids\n","  preds = pred.predictions.argmax(-1)\n","  # calculate accuracy using sklearn's function\n","  acc = accuracy_score(labels, preds)\n","  precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n","  acc = accuracy_score(labels, preds)\n","  confusion_matrix = classification_report(labels, preds, digits=4,output_dict=True)\n","  return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall,\n","        'hate_f1': confusion_matrix[\"0\"][\"f1-score\"],\n","        'hate_recall': confusion_matrix[\"0\"][\"recall\"],\n","        'hate_precision': confusion_matrix[\"0\"][\"precision\"],\n","        'offensive_f1': confusion_matrix[\"1\"][\"f1-score\"],\n","        'offensive_recall': confusion_matrix[\"1\"][\"recall\"],\n","        'offensive_precision': confusion_matrix[\"1\"][\"precision\"],\n","        'normal_f1': confusion_matrix[\"2\"][\"f1-score\"],\n","        'normal_recall': confusion_matrix[\"2\"][\"recall\"],\n","        'normal_precision': confusion_matrix[\"2\"][\"precision\"],    \n","  }\n","\n","\n","\n","def model_init():\n","  return AutoModelForSequenceClassification.from_pretrained(MODEL_NAME,num_labels=3).to(device)\n","\n","\n","# Code extracted from DistilBERT implementation\n","#https://github.com/flowerpot-ai/stabilizer\n","\n","def reinit_autoencoder_model(model, reinit_num_layers=0):\n","    \"\"\"reinitialize autoencoder model layers\"\"\"\n","\n","    if reinit_num_layers:\n","        for layer in model.distilbert.transformer.layer[-reinit_num_layers:]:\n","            for module in layer.modules():\n","                if isinstance(module, nn.Embedding):\n","                  if module.weight.requires_grad:\n","                    module.weight.data.normal_(mean=0.0, std=model.config.initializer_range)\n","                if isinstance(module, nn.Linear):\n","                  module.weight.data.normal_(mean=0.0, std=model.config.initializer_range)\n","                elif isinstance(module, nn.LayerNorm):\n","                  module.bias.data.zero_()\n","                  module.weight.data.fill_(1.0)\n","                if isinstance(module, nn.Linear) and module.bias is not None:\n","                  module.bias.data.zero_()\n","\n","    return model\n","\n","def timestamp():\n","    dateTimeObj = datetime.now()\n","    timestampStr = dateTimeObj.strftime(\"%d-%b-%Y (%H:%M:%S.%f)\")\n","    print(timestampStr)"],"metadata":{"id":"YoKXcvyo_X47"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set_seed(RANDOM_SEED)\n","\n","\n"],"metadata":{"id":"lqKiS7jbkC4x"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3469,"status":"ok","timestamp":1644694159025,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"},"user_tz":0},"id":"AMEUIo294iAd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2aaa4ccf-f098-48e9-e05f-638151916a2d"},"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.10.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading file https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","loading file https://huggingface.co/distilbert-base-uncased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/distilbert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.10.0\",\n","  \"vocab_size\": 30522\n","}\n","\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"]},{"cell_type":"code","source":["  hatetwit_dataset_dfs = load_from_disk('/content/drive/MyDrive/Dissertation/datasets/hatetwit_'+str(1))\n","  train_dataset = hatetwit_dataset_dfs [\"train\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","  eval_dataset = hatetwit_dataset_dfs [\"validation\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","  test_dataset = hatetwit_dataset_dfs [\"test\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n"],"metadata":{"id":"nmPaW82SjXWI"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aum4jWZzXdgX","executionInfo":{"status":"ok","timestamp":1644694159026,"user_tz":0,"elapsed":11,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9a0b93e6-c509-4d15-8b35-1d72bcfb6360"},"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}],"source":["training_args = TrainingArguments(\n","    output_dir='/content/drive/MyDrive/Dissertation/disbert_hate_reinit/results',          # output directory\n","    num_train_epochs=EPOCHS,              # total number of training epochs\n","    save_strategy =\"epoch\" ,\n","    per_device_train_batch_size=BATCH_SIZE,  # batch size per device during training\n","    per_device_eval_batch_size=BATCH_SIZE,   # batch size for evaluation\n","    warmup_steps = WARMUP_STEPS,\n","    weight_decay= WEIGHT_DECAY,               # strength of weight decay\n","    learning_rate= LEARNING_RATE, \n","    logging_dir='./disbert_hate/logs',     # directory for storing logs\n","    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n","    evaluation_strategy=\"epoch\",\n","    #eval_steps = 500     # evaluate each `logging_steps`\n",")"]},{"cell_type":"code","source":["model_l0 = model_init()\n","model_l0 = reinit_autoencoder_model(model_l0,0)\n","trainer_l0 = Trainer(\n","    model =model_l0,                         # the instantiated Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=eval_dataset,          # evaluation dataset\n","    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",")\n","trainer_l0.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"eH6MUAJ0ryj-","executionInfo":{"status":"ok","timestamp":1644699563357,"user_tz":0,"elapsed":311989,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"c81a35fc-425f-4a5c-efca-1157ca87eb86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.10.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:10, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.575200</td>\n","      <td>0.543973</td>\n","      <td>0.786649</td>\n","      <td>0.722384</td>\n","      <td>0.760456</td>\n","      <td>0.705076</td>\n","      <td>0.720895</td>\n","      <td>0.713280</td>\n","      <td>0.728674</td>\n","      <td>0.866019</td>\n","      <td>0.923732</td>\n","      <td>0.815093</td>\n","      <td>0.580239</td>\n","      <td>0.478216</td>\n","      <td>0.737600</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.438200</td>\n","      <td>0.513583</td>\n","      <td>0.806182</td>\n","      <td>0.757252</td>\n","      <td>0.772005</td>\n","      <td>0.745982</td>\n","      <td>0.766133</td>\n","      <td>0.746479</td>\n","      <td>0.786850</td>\n","      <td>0.876923</td>\n","      <td>0.907442</td>\n","      <td>0.848390</td>\n","      <td>0.628699</td>\n","      <td>0.584025</td>\n","      <td>0.680774</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.246900</td>\n","      <td>0.598478</td>\n","      <td>0.812191</td>\n","      <td>0.770503</td>\n","      <td>0.769972</td>\n","      <td>0.771184</td>\n","      <td>0.783515</td>\n","      <td>0.793763</td>\n","      <td>0.773529</td>\n","      <td>0.881274</td>\n","      <td>0.880785</td>\n","      <td>0.881764</td>\n","      <td>0.646719</td>\n","      <td>0.639004</td>\n","      <td>0.654623</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/10/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/10/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/10/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/10/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/10/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/10/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/10/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/10/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/10/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/10/checkpoint-4660 (score: 0.5135825872421265).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=6990, training_loss=0.44640944539562655, metrics={'train_runtime': 310.2819, 'train_samples_per_second': 360.301, 'train_steps_per_second': 22.528, 'total_flos': 1851182116709760.0, 'train_loss': 0.44640944539562655, 'epoch': 3.0})"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["timestamp()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P2JfgDZoKTJA","executionInfo":{"status":"ok","timestamp":1644699563358,"user_tz":0,"elapsed":24,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"2ef377a2-b64b-4214-a027-bdbbcd1b22d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["12-Feb-2022 (20:59:22.739699)\n"]}]},{"cell_type":"code","source":["trainer_l0.evaluate(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"uixoYJUyr26Q","executionInfo":{"status":"ok","timestamp":1644699566781,"user_tz":0,"elapsed":3435,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"12821e27-0c55-4052-d843-d3c36099e5f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 3.0,\n"," 'eval_accuracy': 0.8065693430656934,\n"," 'eval_f1': 0.7600388624161534,\n"," 'eval_hate_f1': 0.7762416794674859,\n"," 'eval_hate_precision': 0.7895833333333333,\n"," 'eval_hate_recall': 0.7633434038267876,\n"," 'eval_loss': 0.5234386324882507,\n"," 'eval_normal_f1': 0.6303982052720135,\n"," 'eval_normal_precision': 0.687041564792176,\n"," 'eval_normal_recall': 0.5823834196891192,\n"," 'eval_offensive_f1': 0.8734767025089605,\n"," 'eval_offensive_precision': 0.8461805555555556,\n"," 'eval_offensive_recall': 0.9025925925925926,\n"," 'eval_precision': 0.774268484560355,\n"," 'eval_recall': 0.7494398053694997,\n"," 'eval_runtime': 3.6877,\n"," 'eval_samples_per_second': 1263.126,\n"," 'eval_steps_per_second': 79.183}"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["timestamp()"],"metadata":{"id":"AM5lYC0nr3l1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PLMUUequ6kV6","executionInfo":{"status":"ok","timestamp":1644694471359,"user_tz":0,"elapsed":312338,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"259b77e4-ac42-4d72-981a-a3b18e5faf2e"},"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.10.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:10, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.567600</td>\n","      <td>0.542159</td>\n","      <td>0.778923</td>\n","      <td>0.737252</td>\n","      <td>0.733916</td>\n","      <td>0.746506</td>\n","      <td>0.715388</td>\n","      <td>0.792757</td>\n","      <td>0.651778</td>\n","      <td>0.852540</td>\n","      <td>0.832655</td>\n","      <td>0.873398</td>\n","      <td>0.643828</td>\n","      <td>0.614108</td>\n","      <td>0.676571</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.428700</td>\n","      <td>0.505512</td>\n","      <td>0.809401</td>\n","      <td>0.767283</td>\n","      <td>0.768604</td>\n","      <td>0.769520</td>\n","      <td>0.773826</td>\n","      <td>0.820926</td>\n","      <td>0.731839</td>\n","      <td>0.876088</td>\n","      <td>0.875602</td>\n","      <td>0.876575</td>\n","      <td>0.651934</td>\n","      <td>0.612033</td>\n","      <td>0.697400</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.261800</td>\n","      <td>0.571578</td>\n","      <td>0.810474</td>\n","      <td>0.768885</td>\n","      <td>0.768240</td>\n","      <td>0.771652</td>\n","      <td>0.785817</td>\n","      <td>0.824950</td>\n","      <td>0.750229</td>\n","      <td>0.876972</td>\n","      <td>0.874861</td>\n","      <td>0.879092</td>\n","      <td>0.643865</td>\n","      <td>0.615145</td>\n","      <td>0.675399</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660 (score: 0.5055122375488281).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=6990, training_loss=0.4498143819609766, metrics={'train_runtime': 310.7695, 'train_samples_per_second': 359.736, 'train_steps_per_second': 22.493, 'total_flos': 1851182116709760.0, 'train_loss': 0.4498143819609766, 'epoch': 3.0})"]},"metadata":{},"execution_count":45}],"source":["model_l1 = model_init()\n","model_l1 = reinit_autoencoder_model(model_l1,1)\n","trainer_l1 = Trainer(\n","    model =model_l1,                         # the instantiated Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=eval_dataset,          # evaluation dataset\n","    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",")\n","trainer_l1.train()"]},{"cell_type":"code","source":["timestamp()\n"],"metadata":{"id":"f6VXroG67pHI","executionInfo":{"status":"ok","timestamp":1644694471359,"user_tz":0,"elapsed":28,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"61f27921-ed93-43b0-f314-d65d7fe39a4e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["12-Feb-2022 (19:34:30.879907)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"1G57aLkv7OhH","executionInfo":{"status":"ok","timestamp":1644694475116,"user_tz":0,"elapsed":3781,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"b94437e8-53a1-466d-fedf-92746b75a7b4"},"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 3.0,\n"," 'eval_accuracy': 0.7930442249892657,\n"," 'eval_f1': 0.7492964771761866,\n"," 'eval_hate_f1': 0.7642585551330798,\n"," 'eval_hate_precision': 0.7236723672367237,\n"," 'eval_hate_recall': 0.8096676737160121,\n"," 'eval_loss': 0.5350803732872009,\n"," 'eval_normal_f1': 0.6218302094818082,\n"," 'eval_normal_precision': 0.6643109540636042,\n"," 'eval_normal_recall': 0.5844559585492228,\n"," 'eval_offensive_f1': 0.8618006669136717,\n"," 'eval_offensive_precision': 0.8621200889547813,\n"," 'eval_offensive_recall': 0.8614814814814815,\n"," 'eval_precision': 0.7500344700850364,\n"," 'eval_recall': 0.7518683712489055,\n"," 'eval_runtime': 3.6964,\n"," 'eval_samples_per_second': 1260.129,\n"," 'eval_steps_per_second': 78.995}"]},"metadata":{},"execution_count":47}],"source":["trainer_l1.evaluate(test_dataset)"]},{"cell_type":"code","source":["timestamp()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s2jEZF1vK-sh","executionInfo":{"status":"ok","timestamp":1644694475117,"user_tz":0,"elapsed":11,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"c8bfe548-25c3-42a7-d3ed-ea3bffa0823e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["12-Feb-2022 (19:34:34.597176)\n"]}]},{"cell_type":"code","source":["model_l2 = model_init()\n","model_l2 = reinit_autoencoder_model(model_l2,2)\n","trainer_l2 = Trainer(\n","    model =model_l2,                         # the instantiated Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=eval_dataset,          # evaluation dataset\n","    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",")\n","trainer_l2.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"NgjTH_zRKiAM","executionInfo":{"status":"ok","timestamp":1644694787087,"user_tz":0,"elapsed":311977,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"3ec5a5bb-0f05-4746-e66d-c3e0f021b520"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.10.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:10, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.569000</td>\n","      <td>0.547982</td>\n","      <td>0.775918</td>\n","      <td>0.731000</td>\n","      <td>0.736677</td>\n","      <td>0.741905</td>\n","      <td>0.713732</td>\n","      <td>0.834004</td>\n","      <td>0.623777</td>\n","      <td>0.851725</td>\n","      <td>0.831544</td>\n","      <td>0.872911</td>\n","      <td>0.627542</td>\n","      <td>0.560166</td>\n","      <td>0.713342</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.430600</td>\n","      <td>0.498001</td>\n","      <td>0.802533</td>\n","      <td>0.755148</td>\n","      <td>0.764668</td>\n","      <td>0.748887</td>\n","      <td>0.769766</td>\n","      <td>0.778672</td>\n","      <td>0.761062</td>\n","      <td>0.872083</td>\n","      <td>0.892262</td>\n","      <td>0.852795</td>\n","      <td>0.623596</td>\n","      <td>0.575726</td>\n","      <td>0.680147</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.265700</td>\n","      <td>0.597122</td>\n","      <td>0.804035</td>\n","      <td>0.761795</td>\n","      <td>0.760826</td>\n","      <td>0.764666</td>\n","      <td>0.782525</td>\n","      <td>0.819920</td>\n","      <td>0.748393</td>\n","      <td>0.871566</td>\n","      <td>0.869308</td>\n","      <td>0.873837</td>\n","      <td>0.631294</td>\n","      <td>0.604772</td>\n","      <td>0.660249</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660 (score: 0.4980005621910095).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=6990, training_loss=0.45234484365569677, metrics={'train_runtime': 310.613, 'train_samples_per_second': 359.917, 'train_steps_per_second': 22.504, 'total_flos': 1851182116709760.0, 'train_loss': 0.45234484365569677, 'epoch': 3.0})"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["timestamp()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S6Y3_RF7K9b2","executionInfo":{"status":"ok","timestamp":1644694787088,"user_tz":0,"elapsed":30,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"a0e85006-4b46-423b-b040-709f2e4e2a0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["12-Feb-2022 (19:39:46.675339)\n"]}]},{"cell_type":"code","source":["trainer_l2.evaluate(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"CDtoMRIcKx-A","executionInfo":{"status":"ok","timestamp":1644694790763,"user_tz":0,"elapsed":3685,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"faf3049b-0b70-43a8-8b29-5b1474a67ade"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 3.0,\n"," 'eval_accuracy': 0.798196650923143,\n"," 'eval_f1': 0.7530348406370205,\n"," 'eval_hate_f1': 0.7754299754299755,\n"," 'eval_hate_precision': 0.7571976967370442,\n"," 'eval_hate_recall': 0.7945619335347432,\n"," 'eval_loss': 0.5186144113540649,\n"," 'eval_normal_f1': 0.6193693693693695,\n"," 'eval_normal_precision': 0.6781750924784217,\n"," 'eval_normal_recall': 0.5699481865284974,\n"," 'eval_offensive_f1': 0.8643051771117165,\n"," 'eval_offensive_precision': 0.8481283422459893,\n"," 'eval_offensive_recall': 0.8811111111111111,\n"," 'eval_precision': 0.7611670438204851,\n"," 'eval_recall': 0.7485404103914505,\n"," 'eval_runtime': 3.6887,\n"," 'eval_samples_per_second': 1262.759,\n"," 'eval_steps_per_second': 79.16}"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["timestamp()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dIFZWcRNLAGQ","executionInfo":{"status":"ok","timestamp":1644694790763,"user_tz":0,"elapsed":11,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"1362d716-d39d-4bb2-ade7-758b1533e654"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["12-Feb-2022 (19:39:50.386979)\n"]}]},{"cell_type":"code","source":["model_l3 = model_init()\n","model_l3 = reinit_autoencoder_model(model_l3,3)\n","trainer_l3 = Trainer(\n","    model =model_l3,                         # the instantiated Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=eval_dataset,          # evaluation dataset\n","    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",")\n","trainer_l3.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"zRg5CaNiLDBV","executionInfo":{"status":"ok","timestamp":1644695104838,"user_tz":0,"elapsed":314082,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"e4282354-b7dc-4e5f-9ddb-58afde4433d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.10.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:12, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.572800</td>\n","      <td>0.539937</td>\n","      <td>0.781713</td>\n","      <td>0.734538</td>\n","      <td>0.738398</td>\n","      <td>0.739737</td>\n","      <td>0.728098</td>\n","      <td>0.806841</td>\n","      <td>0.663358</td>\n","      <td>0.856877</td>\n","      <td>0.851166</td>\n","      <td>0.862664</td>\n","      <td>0.618639</td>\n","      <td>0.561203</td>\n","      <td>0.689172</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.439900</td>\n","      <td>0.501855</td>\n","      <td>0.802962</td>\n","      <td>0.758845</td>\n","      <td>0.763159</td>\n","      <td>0.758223</td>\n","      <td>0.765468</td>\n","      <td>0.802817</td>\n","      <td>0.731439</td>\n","      <td>0.870843</td>\n","      <td>0.877453</td>\n","      <td>0.864333</td>\n","      <td>0.640223</td>\n","      <td>0.594398</td>\n","      <td>0.693705</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.284600</td>\n","      <td>0.584767</td>\n","      <td>0.802747</td>\n","      <td>0.762338</td>\n","      <td>0.760017</td>\n","      <td>0.765778</td>\n","      <td>0.781054</td>\n","      <td>0.812877</td>\n","      <td>0.751628</td>\n","      <td>0.869112</td>\n","      <td>0.864124</td>\n","      <td>0.874157</td>\n","      <td>0.636848</td>\n","      <td>0.620332</td>\n","      <td>0.654267</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660 (score: 0.5018554329872131).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=6990, training_loss=0.4660367013388267, metrics={'train_runtime': 312.5988, 'train_samples_per_second': 357.631, 'train_steps_per_second': 22.361, 'total_flos': 1851182116709760.0, 'train_loss': 0.4660367013388267, 'epoch': 3.0})"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["timestamp()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"52V6r5c9LMQA","executionInfo":{"status":"ok","timestamp":1644695104839,"user_tz":0,"elapsed":26,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"0fb62765-f53a-4083-c08f-6275d2f38269"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["12-Feb-2022 (19:45:04.425282)\n"]}]},{"cell_type":"code","source":["trainer_l3.evaluate(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"Qf71ntzULOyO","executionInfo":{"status":"ok","timestamp":1644695108392,"user_tz":0,"elapsed":3577,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"75d3c369-cd70-415f-c2ab-f18b21b2c0ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 3.0,\n"," 'eval_accuracy': 0.798626019750966,\n"," 'eval_f1': 0.7525014322460969,\n"," 'eval_hate_f1': 0.7672289156626506,\n"," 'eval_hate_precision': 0.7356746765249538,\n"," 'eval_hate_recall': 0.8016112789526687,\n"," 'eval_loss': 0.5245223045349121,\n"," 'eval_normal_f1': 0.6229508196721312,\n"," 'eval_normal_precision': 0.6853233830845771,\n"," 'eval_normal_recall': 0.5709844559585492,\n"," 'eval_offensive_f1': 0.8673245614035089,\n"," 'eval_offensive_precision': 0.8560606060606061,\n"," 'eval_offensive_recall': 0.8788888888888889,\n"," 'eval_precision': 0.759019555223379,\n"," 'eval_recall': 0.7504948746000356,\n"," 'eval_runtime': 3.6872,\n"," 'eval_samples_per_second': 1263.303,\n"," 'eval_steps_per_second': 79.194}"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["timestamp()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BTGng9JVLUxQ","executionInfo":{"status":"ok","timestamp":1644695108392,"user_tz":0,"elapsed":21,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"f30cc75c-ea84-492a-ad81-50519f364b74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["12-Feb-2022 (19:45:08.133371)\n"]}]},{"cell_type":"code","source":["model_l4 = model_init()\n","model_l4 = reinit_autoencoder_model(model_l4,4)\n","trainer_l4 = Trainer(\n","    model =model_l4,                         # the instantiated Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=eval_dataset,          # evaluation dataset\n","    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",")\n","trainer_l4.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ExGfI4UzQJmu","executionInfo":{"status":"ok","timestamp":1644695424621,"user_tz":0,"elapsed":316246,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"eb693e40-c41f-45c8-deb5-eb006a4df4c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.10.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:14, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.576200</td>\n","      <td>0.551037</td>\n","      <td>0.771839</td>\n","      <td>0.721150</td>\n","      <td>0.727027</td>\n","      <td>0.725332</td>\n","      <td>0.713572</td>\n","      <td>0.790744</td>\n","      <td>0.650124</td>\n","      <td>0.851151</td>\n","      <td>0.848945</td>\n","      <td>0.853368</td>\n","      <td>0.598726</td>\n","      <td>0.536307</td>\n","      <td>0.677588</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.447100</td>\n","      <td>0.525794</td>\n","      <td>0.797811</td>\n","      <td>0.749874</td>\n","      <td>0.755132</td>\n","      <td>0.751599</td>\n","      <td>0.753731</td>\n","      <td>0.812877</td>\n","      <td>0.702609</td>\n","      <td>0.871105</td>\n","      <td>0.874491</td>\n","      <td>0.867744</td>\n","      <td>0.624786</td>\n","      <td>0.567427</td>\n","      <td>0.695044</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.305400</td>\n","      <td>0.575829</td>\n","      <td>0.802533</td>\n","      <td>0.757886</td>\n","      <td>0.759921</td>\n","      <td>0.757667</td>\n","      <td>0.762506</td>\n","      <td>0.789738</td>\n","      <td>0.737089</td>\n","      <td>0.873250</td>\n","      <td>0.877453</td>\n","      <td>0.869087</td>\n","      <td>0.637903</td>\n","      <td>0.605809</td>\n","      <td>0.673587</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660 (score: 0.5257939100265503).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=6990, training_loss=0.47607708714039026, metrics={'train_runtime': 314.3891, 'train_samples_per_second': 355.594, 'train_steps_per_second': 22.234, 'total_flos': 1851182116709760.0, 'train_loss': 0.47607708714039026, 'epoch': 3.0})"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["trainer_l4.evaluate(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"36jIg_AEQR2U","executionInfo":{"status":"ok","timestamp":1644695428179,"user_tz":0,"elapsed":3583,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"3df7bbcc-4243-49ba-bc7e-72888b3d9675"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 3.0,\n"," 'eval_accuracy': 0.7958351223701159,\n"," 'eval_f1': 0.7499905905706017,\n"," 'eval_hate_f1': 0.75426944971537,\n"," 'eval_hate_precision': 0.7130044843049327,\n"," 'eval_hate_recall': 0.8006042296072508,\n"," 'eval_loss': 0.5490932464599609,\n"," 'eval_normal_f1': 0.6297343131712833,\n"," 'eval_normal_precision': 0.6927860696517413,\n"," 'eval_normal_recall': 0.5772020725388601,\n"," 'eval_offensive_f1': 0.8659680088251517,\n"," 'eval_offensive_precision': 0.859802847754655,\n"," 'eval_offensive_recall': 0.8722222222222222,\n"," 'eval_precision': 0.7551978005704431,\n"," 'eval_recall': 0.7500095081227777,\n"," 'eval_runtime': 3.6786,\n"," 'eval_samples_per_second': 1266.252,\n"," 'eval_steps_per_second': 79.379}"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["model_l5 = model_init()\n","model_l5 = reinit_autoencoder_model(model_l5,5)\n","trainer_l5 = Trainer(\n","    model =model_l5,                         # the instantiated Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=eval_dataset,          # evaluation dataset\n","    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",")\n","trainer_l5.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"o_wQEB2AWljk","executionInfo":{"status":"ok","timestamp":1644695744393,"user_tz":0,"elapsed":316219,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"17eb31ac-f60c-4d61-e2ab-e9ea3c253bc2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.10.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:14, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.585900</td>\n","      <td>0.562249</td>\n","      <td>0.773986</td>\n","      <td>0.723120</td>\n","      <td>0.729790</td>\n","      <td>0.723905</td>\n","      <td>0.711691</td>\n","      <td>0.768612</td>\n","      <td>0.662619</td>\n","      <td>0.852725</td>\n","      <td>0.857460</td>\n","      <td>0.848041</td>\n","      <td>0.604945</td>\n","      <td>0.545643</td>\n","      <td>0.678710</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.460400</td>\n","      <td>0.535870</td>\n","      <td>0.793518</td>\n","      <td>0.747971</td>\n","      <td>0.751059</td>\n","      <td>0.748672</td>\n","      <td>0.750476</td>\n","      <td>0.792757</td>\n","      <td>0.712477</td>\n","      <td>0.864676</td>\n","      <td>0.868197</td>\n","      <td>0.861183</td>\n","      <td>0.628763</td>\n","      <td>0.585062</td>\n","      <td>0.679518</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.337300</td>\n","      <td>0.570995</td>\n","      <td>0.794162</td>\n","      <td>0.750821</td>\n","      <td>0.751278</td>\n","      <td>0.751996</td>\n","      <td>0.756286</td>\n","      <td>0.786720</td>\n","      <td>0.728119</td>\n","      <td>0.863855</td>\n","      <td>0.864495</td>\n","      <td>0.863216</td>\n","      <td>0.632321</td>\n","      <td>0.604772</td>\n","      <td>0.662500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660 (score: 0.5358704328536987).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=6990, training_loss=0.4937893388609006, metrics={'train_runtime': 314.8008, 'train_samples_per_second': 355.129, 'train_steps_per_second': 22.205, 'total_flos': 1851182116709760.0, 'train_loss': 0.4937893388609006, 'epoch': 3.0})"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["trainer_l5.evaluate(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"t8nrYIYWWtIO","executionInfo":{"status":"ok","timestamp":1644695748051,"user_tz":0,"elapsed":3679,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"3a20ed64-8e7e-4d5c-928b-f517c7529d7e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 3.0,\n"," 'eval_accuracy': 0.787247745813654,\n"," 'eval_f1': 0.7412526746022313,\n"," 'eval_hate_f1': 0.7464114832535885,\n"," 'eval_hate_precision': 0.7110300820419325,\n"," 'eval_hate_recall': 0.7854984894259819,\n"," 'eval_loss': 0.5579251050949097,\n"," 'eval_normal_f1': 0.6182019977802442,\n"," 'eval_normal_precision': 0.6654719235364397,\n"," 'eval_normal_recall': 0.5772020725388601,\n"," 'eval_offensive_f1': 0.8591445427728615,\n"," 'eval_offensive_precision': 0.855359765051395,\n"," 'eval_offensive_recall': 0.8629629629629629,\n"," 'eval_precision': 0.7439539235432558,\n"," 'eval_recall': 0.7418878416426016,\n"," 'eval_runtime': 3.7238,\n"," 'eval_samples_per_second': 1250.858,\n"," 'eval_steps_per_second': 78.414}"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["model_l6 = model_init()\n","model_l6 = reinit_autoencoder_model(model_l6,6)\n","trainer_l6 = Trainer(\n","    model =model_l6,                         # the instantiated Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=eval_dataset,          # evaluation dataset\n","    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",")\n","trainer_l6.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"2cYeiwGqWq2p","executionInfo":{"status":"ok","timestamp":1644694055545,"user_tz":0,"elapsed":311791,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"0ba2d2d4-ef1d-4b3f-ccf2-0629e6c97681"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.10.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:09, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.605900</td>\n","      <td>0.571068</td>\n","      <td>0.764756</td>\n","      <td>0.714698</td>\n","      <td>0.719700</td>\n","      <td>0.718557</td>\n","      <td>0.699772</td>\n","      <td>0.772636</td>\n","      <td>0.639467</td>\n","      <td>0.844667</td>\n","      <td>0.841540</td>\n","      <td>0.847818</td>\n","      <td>0.599655</td>\n","      <td>0.541494</td>\n","      <td>0.671815</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.493900</td>\n","      <td>0.557007</td>\n","      <td>0.777849</td>\n","      <td>0.719782</td>\n","      <td>0.739334</td>\n","      <td>0.712750</td>\n","      <td>0.717653</td>\n","      <td>0.750503</td>\n","      <td>0.687558</td>\n","      <td>0.857654</td>\n","      <td>0.886709</td>\n","      <td>0.830444</td>\n","      <td>0.584039</td>\n","      <td>0.501037</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.374800</td>\n","      <td>0.578897</td>\n","      <td>0.786220</td>\n","      <td>0.740468</td>\n","      <td>0.740428</td>\n","      <td>0.741804</td>\n","      <td>0.743938</td>\n","      <td>0.771630</td>\n","      <td>0.718165</td>\n","      <td>0.860422</td>\n","      <td>0.860422</td>\n","      <td>0.860422</td>\n","      <td>0.617044</td>\n","      <td>0.593361</td>\n","      <td>0.642697</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_reinit/results/checkpoint-4660 (score: 0.5570070743560791).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=6990, training_loss=0.5250469879019414, metrics={'train_runtime': 310.0341, 'train_samples_per_second': 360.589, 'train_steps_per_second': 22.546, 'total_flos': 1851182116709760.0, 'train_loss': 0.5250469879019414, 'epoch': 3.0})"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["trainer_l6.evaluate(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"DxD6DqcnW2VJ","executionInfo":{"status":"ok","timestamp":1644694093980,"user_tz":0,"elapsed":3880,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"df18ef38-15d0-4c90-cfce-e031dcf710f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 3.0,\n"," 'eval_accuracy': 0.7760841562902533,\n"," 'eval_f1': 0.7213222095438064,\n"," 'eval_hate_f1': 0.7204249154997586,\n"," 'eval_hate_precision': 0.6920222634508348,\n"," 'eval_hate_recall': 0.7512588116817724,\n"," 'eval_loss': 0.5702793598175049,\n"," 'eval_normal_f1': 0.5922798552472859,\n"," 'eval_normal_precision': 0.7085137085137085,\n"," 'eval_normal_recall': 0.5088082901554404,\n"," 'eval_offensive_f1': 0.8512618578843745,\n"," 'eval_offensive_precision': 0.8236924142708694,\n"," 'eval_offensive_recall': 0.8807407407407407,\n"," 'eval_precision': 0.7414094620784709,\n"," 'eval_recall': 0.7136026141926511,\n"," 'eval_runtime': 3.6227,\n"," 'eval_samples_per_second': 1285.792,\n"," 'eval_steps_per_second': 80.604}"]},"metadata":{},"execution_count":34}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Distilbert Experiment HateTwit Layer Reinit.ipynb","provenance":[{"file_id":"15wylWRQJ1vxlP58OhBHUnY5fdagThMvJ","timestamp":1643406846637},{"file_id":"1B35hajBJY3fRQV7LSjqoqQ3xjdcyCzE3","timestamp":1642365829686},{"file_id":"1b0lCW2Cj6AULiE-Axh2OeZwURHR6pfcD","timestamp":1642333651961},{"file_id":"1RAjFaq-k9CLJQP5eO668UXLc0q-wjuve","timestamp":1642280213414},{"file_id":"1LzZr7GRN1SwVrNyjVX5t5PpCvio8w_kE","timestamp":1642109182548},{"file_id":"1t-qzEyxZtGn_Cnlfg2WtN-0dlgUmxfzx","timestamp":1641764210714},{"file_id":"14bEU8hCGPF8cVUA_BonJQA6Brv89DKUm","timestamp":1641252935713},{"file_id":"18Il3CpGf89tF1Z10iYX8OdfeHxxAX1Ui","timestamp":1639243141142},{"file_id":"1SHCgoRQVGtl9OiWEJGK3JgKkuxxSPy_5","timestamp":1639231968300},{"file_id":"1D-3yvF0nGnaWEZGxQj21R6fsGnyv5a5g","timestamp":1637526185003},{"file_id":"1glXr2JglKPUpN_3AGyk3GjfCtZSDNfsZ","timestamp":1637408594851},{"file_id":"1rc5hX8PBIv7GKvlxLQ35Vwf2jxLsv9f4","timestamp":1634501666668}],"mount_file_id":"1-rZqxPTOtm21puGsZKK_FiKXeyCg7py7","authorship_tag":"ABX9TyN3VHRmW5vIDbn+hVXg433E"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}