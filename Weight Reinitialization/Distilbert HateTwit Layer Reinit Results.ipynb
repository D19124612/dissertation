{"cells":[{"cell_type":"code","execution_count":21,"metadata":{"id":"F-o6bXOJ18j4","executionInfo":{"status":"ok","timestamp":1644791622322,"user_tz":0,"elapsed":16877,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["!pip install -qq transformers\n","!pip install -qq optuna\n","!pip install -qq sentencepiece\n","!pip install -qq datasets\n","!pip install -qq stabilizer"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"Rz6wNlu92ge_","executionInfo":{"status":"ok","timestamp":1644791622323,"user_tz":0,"elapsed":11,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["import transformers\n","import datasets\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification,AdamW, get_linear_schedule_with_warmup,Trainer, TrainingArguments\n","from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n","import torch\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from pylab import rcParams\n","import matplotlib.pyplot as plt\n","from matplotlib import rc\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, classification_report\n","from collections import defaultdict\n","import random\n","from textwrap import wrap\n","from datetime import datetime\n","from datasets import load_from_disk\n","from datasets import Dataset\n","from sklearn.metrics import accuracy_score,classification_report, confusion_matrix\n","from sklearn.metrics import precision_recall_fscore_support\n","from stabilizer.reinitialize import reinit_autoencoder_model\n","from stabilizer.llrd import get_optimizer_parameters_with_llrd"]},{"cell_type":"code","source":["from torch import nn"],"metadata":{"id":"pOQkqPGp2ZTN","executionInfo":{"status":"ok","timestamp":1644791622323,"user_tz":0,"elapsed":10,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","execution_count":24,"metadata":{"id":"T7IFr4-3TKaA","executionInfo":{"status":"ok","timestamp":1644791622324,"user_tz":0,"elapsed":10,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["# the model we gonna train, base uncased BERT\n","# check text classification models here: https://huggingface.co/models?filter=text-classification\n","MODEL_NAME = \"distilbert-base-uncased\"\n","BATCH_SIZE = 16\n","EPOCHS = 3\n","LEARNING_RATE= 6.779448121064052e-05\n","WEIGHT_DECAY = 0.05951904479543706\n","WARMUP_STEPS = 491\n","RANDOM_SEED=31\n","\n","\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"]},{"cell_type":"code","source":["def set_seed(seed):\n","    \"\"\"Set all seeds to make results reproducible (deterministic mode).\n","       When seed is None, disables deterministic mode.\n","    :param seed: an integer to your choosing\n","    \"\"\"\n","    if seed is not None:\n","        torch.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","        np.random.seed(seed)\n","        random.seed(seed)\n","\n","def compute_metrics(pred):\n","  labels = pred.label_ids\n","  preds = pred.predictions.argmax(-1)\n","  # calculate accuracy using sklearn's function\n","  acc = accuracy_score(labels, preds)\n","  precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n","  acc = accuracy_score(labels, preds)\n","  confusion_matrix = classification_report(labels, preds, digits=4,output_dict=True)\n","  return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall,\n","        'hate_f1': confusion_matrix[\"0\"][\"f1-score\"],\n","        'hate_recall': confusion_matrix[\"0\"][\"recall\"],\n","        'hate_precision': confusion_matrix[\"0\"][\"precision\"],\n","        'offensive_f1': confusion_matrix[\"1\"][\"f1-score\"],\n","        'offensive_recall': confusion_matrix[\"1\"][\"recall\"],\n","        'offensive_precision': confusion_matrix[\"1\"][\"precision\"],\n","        'normal_f1': confusion_matrix[\"2\"][\"f1-score\"],\n","        'normal_recall': confusion_matrix[\"2\"][\"recall\"],\n","        'normal_precision': confusion_matrix[\"2\"][\"precision\"],    \n","  }\n","\n","\n","\n","def model_init():\n","  return AutoModelForSequenceClassification.from_pretrained(MODEL_NAME,num_labels=3).to(device)\n","\n","\n","# Code extracted from DistilBERT implementation\n","#https://github.com/flowerpot-ai/stabilizer\n","\n","def reinit_autoencoder_model(model, reinit_num_layers=0):\n","    \"\"\"reinitialize autoencoder model layers\"\"\"\n","\n","    if reinit_num_layers:\n","        for layer in model.distilbert.transformer.layer[-reinit_num_layers:]:\n","            for module in layer.modules():\n","                if isinstance(module, nn.Embedding):\n","                  if module.weight.requires_grad:\n","                    module.weight.data.normal_(mean=0.0, std=model.config.initializer_range)\n","                if isinstance(module, nn.Linear):\n","                  module.weight.data.normal_(mean=0.0, std=model.config.initializer_range)\n","                elif isinstance(module, nn.LayerNorm):\n","                  module.bias.data.zero_()\n","                  module.weight.data.fill_(1.0)\n","                if isinstance(module, nn.Linear) and module.bias is not None:\n","                  module.bias.data.zero_()\n","\n","    return model\n","\n","def timestamp():\n","    dateTimeObj = datetime.now()\n","    timestampStr = dateTimeObj.strftime(\"%d-%b-%Y (%H:%M:%S.%f)\")\n","    print(timestampStr)"],"metadata":{"id":"YoKXcvyo_X47","executionInfo":{"status":"ok","timestamp":1644791622324,"user_tz":0,"elapsed":10,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["set_seed(RANDOM_SEED)"],"metadata":{"id":"lqKiS7jbkC4x","executionInfo":{"status":"ok","timestamp":1644791622324,"user_tz":0,"elapsed":9,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["num_layers = 2\n","result_list = []\n","for i in range(1,11):\n","\n","  training_args = TrainingArguments(\n","    output_dir='/content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/'+str(i),          # output directory\n","    num_train_epochs=EPOCHS,              # total number of training epochs\n","    save_strategy =\"epoch\" ,\n","    per_device_train_batch_size=BATCH_SIZE,  # batch size per device during training\n","    per_device_eval_batch_size=BATCH_SIZE,   # batch size for evaluation\n","    weight_decay= WEIGHT_DECAY,               # strength of weight decay\n","    learning_rate= LEARNING_RATE, \n","    warmup_steps = WARMUP_STEPS,\n","    logging_dir='./disbert_hate_reinit///logs',     # directory for storing logs\n","    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n","    evaluation_strategy=\"epoch\",\n","  )\n","\n","  hatetwit_dataset_dfs = load_from_disk('/content/drive/MyDrive/Dissertation/datasets/hatetwit_'+str(i))\n","  train_dataset = hatetwit_dataset_dfs [\"train\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","  eval_dataset = hatetwit_dataset_dfs [\"validation\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","  test_dataset = hatetwit_dataset_dfs [\"test\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","  model = model_init()\n","  model = reinit_autoencoder_model(model,num_layers)\n","  trainer = Trainer(\n","      model=model,                         # the instantiated Transformers model to be trained\n","      args=training_args,                  # training arguments, defined above\n","      train_dataset= train_dataset,         # training dataset\n","      eval_dataset=eval_dataset,          # evaluation dataset\n","      compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n","  )\n","  trainer.train()\n","  trainer.save_model('/content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_'+str(i))\n","  results = trainer.evaluate(test_dataset)\n","  results[\"model_run\"] = i\n","  result_list.append(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"e5myJBbEHKUr","executionInfo":{"status":"ok","timestamp":1644795089040,"user_tz":0,"elapsed":3466298,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"04ff7854-dc13-474f-b454-5d3f17baa48c"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.10.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:34, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.572900</td>\n","      <td>0.544395</td>\n","      <td>0.769049</td>\n","      <td>0.727150</td>\n","      <td>0.719960</td>\n","      <td>0.742094</td>\n","      <td>0.726302</td>\n","      <td>0.820926</td>\n","      <td>0.651237</td>\n","      <td>0.844453</td>\n","      <td>0.813032</td>\n","      <td>0.878400</td>\n","      <td>0.610695</td>\n","      <td>0.592324</td>\n","      <td>0.630243</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.432600</td>\n","      <td>0.489772</td>\n","      <td>0.806396</td>\n","      <td>0.762295</td>\n","      <td>0.764880</td>\n","      <td>0.762539</td>\n","      <td>0.777671</td>\n","      <td>0.812877</td>\n","      <td>0.745387</td>\n","      <td>0.874609</td>\n","      <td>0.879304</td>\n","      <td>0.869963</td>\n","      <td>0.634605</td>\n","      <td>0.595436</td>\n","      <td>0.679290</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.260800</td>\n","      <td>0.582599</td>\n","      <td>0.809616</td>\n","      <td>0.769588</td>\n","      <td>0.768462</td>\n","      <td>0.771645</td>\n","      <td>0.794547</td>\n","      <td>0.820926</td>\n","      <td>0.769811</td>\n","      <td>0.874258</td>\n","      <td>0.872640</td>\n","      <td>0.875883</td>\n","      <td>0.639957</td>\n","      <td>0.621369</td>\n","      <td>0.659692</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/1/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/1/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/1/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/1/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/1/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/1/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/1/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/1/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/1/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/1/checkpoint-4660 (score: 0.4897717833518982).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_1\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_1/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_1/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.10.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:32, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.576700</td>\n","      <td>0.534730</td>\n","      <td>0.782571</td>\n","      <td>0.723175</td>\n","      <td>0.747177</td>\n","      <td>0.717299</td>\n","      <td>0.715829</td>\n","      <td>0.766600</td>\n","      <td>0.671366</td>\n","      <td>0.863857</td>\n","      <td>0.891522</td>\n","      <td>0.837857</td>\n","      <td>0.589839</td>\n","      <td>0.493776</td>\n","      <td>0.732308</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.430500</td>\n","      <td>0.508296</td>\n","      <td>0.804250</td>\n","      <td>0.764362</td>\n","      <td>0.757876</td>\n","      <td>0.774546</td>\n","      <td>0.778654</td>\n","      <td>0.844064</td>\n","      <td>0.722653</td>\n","      <td>0.872562</td>\n","      <td>0.853017</td>\n","      <td>0.893023</td>\n","      <td>0.641870</td>\n","      <td>0.626556</td>\n","      <td>0.657952</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.257400</td>\n","      <td>0.596703</td>\n","      <td>0.801889</td>\n","      <td>0.760556</td>\n","      <td>0.758783</td>\n","      <td>0.762422</td>\n","      <td>0.778937</td>\n","      <td>0.788732</td>\n","      <td>0.769382</td>\n","      <td>0.871700</td>\n","      <td>0.867827</td>\n","      <td>0.875607</td>\n","      <td>0.631033</td>\n","      <td>0.630705</td>\n","      <td>0.631360</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/2/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/2/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/2/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/2/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/2/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/2/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/2/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/2/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/2/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/2/checkpoint-4660 (score: 0.5082958936691284).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_2\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_2/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_2/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.10.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:32, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.578000</td>\n","      <td>0.557588</td>\n","      <td>0.769264</td>\n","      <td>0.707687</td>\n","      <td>0.733253</td>\n","      <td>0.691651</td>\n","      <td>0.685535</td>\n","      <td>0.657948</td>\n","      <td>0.715536</td>\n","      <td>0.851988</td>\n","      <td>0.900407</td>\n","      <td>0.808511</td>\n","      <td>0.585538</td>\n","      <td>0.516598</td>\n","      <td>0.675712</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.428400</td>\n","      <td>0.521156</td>\n","      <td>0.792445</td>\n","      <td>0.742128</td>\n","      <td>0.745924</td>\n","      <td>0.745699</td>\n","      <td>0.762523</td>\n","      <td>0.826962</td>\n","      <td>0.707401</td>\n","      <td>0.867750</td>\n","      <td>0.869678</td>\n","      <td>0.865831</td>\n","      <td>0.596110</td>\n","      <td>0.540456</td>\n","      <td>0.664541</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.272900</td>\n","      <td>0.616441</td>\n","      <td>0.806611</td>\n","      <td>0.762919</td>\n","      <td>0.765184</td>\n","      <td>0.760859</td>\n","      <td>0.793763</td>\n","      <td>0.793763</td>\n","      <td>0.793763</td>\n","      <td>0.876677</td>\n","      <td>0.883006</td>\n","      <td>0.870438</td>\n","      <td>0.618317</td>\n","      <td>0.605809</td>\n","      <td>0.631351</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/3/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/3/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/3/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/3/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/3/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/3/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/3/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/3/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/3/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/3/checkpoint-4660 (score: 0.5211563110351562).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_3\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_3/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_3/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.10.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:32, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.578300</td>\n","      <td>0.538110</td>\n","      <td>0.774200</td>\n","      <td>0.725299</td>\n","      <td>0.729370</td>\n","      <td>0.730397</td>\n","      <td>0.719927</td>\n","      <td>0.797787</td>\n","      <td>0.655914</td>\n","      <td>0.851611</td>\n","      <td>0.846723</td>\n","      <td>0.856554</td>\n","      <td>0.604358</td>\n","      <td>0.546680</td>\n","      <td>0.675641</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.417800</td>\n","      <td>0.548766</td>\n","      <td>0.789654</td>\n","      <td>0.753134</td>\n","      <td>0.743322</td>\n","      <td>0.774145</td>\n","      <td>0.768829</td>\n","      <td>0.888330</td>\n","      <td>0.677667</td>\n","      <td>0.855752</td>\n","      <td>0.813773</td>\n","      <td>0.902299</td>\n","      <td>0.634820</td>\n","      <td>0.620332</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.261900</td>\n","      <td>0.612164</td>\n","      <td>0.804894</td>\n","      <td>0.762757</td>\n","      <td>0.762902</td>\n","      <td>0.763794</td>\n","      <td>0.797660</td>\n","      <td>0.822938</td>\n","      <td>0.773888</td>\n","      <td>0.871075</td>\n","      <td>0.873010</td>\n","      <td>0.869149</td>\n","      <td>0.619536</td>\n","      <td>0.595436</td>\n","      <td>0.645669</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/4/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/4/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/4/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/4/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/4/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/4/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/4/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/4/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/4/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/4/checkpoint-2330 (score: 0.5381100177764893).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_4\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_4/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_4/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.10.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:32, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.570300</td>\n","      <td>0.536424</td>\n","      <td>0.783215</td>\n","      <td>0.725929</td>\n","      <td>0.758228</td>\n","      <td>0.710610</td>\n","      <td>0.714357</td>\n","      <td>0.718310</td>\n","      <td>0.710448</td>\n","      <td>0.857744</td>\n","      <td>0.905220</td>\n","      <td>0.815000</td>\n","      <td>0.605686</td>\n","      <td>0.508299</td>\n","      <td>0.749235</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.423400</td>\n","      <td>0.488366</td>\n","      <td>0.806611</td>\n","      <td>0.764323</td>\n","      <td>0.765819</td>\n","      <td>0.763993</td>\n","      <td>0.770059</td>\n","      <td>0.791751</td>\n","      <td>0.749524</td>\n","      <td>0.874263</td>\n","      <td>0.877823</td>\n","      <td>0.870731</td>\n","      <td>0.648649</td>\n","      <td>0.622407</td>\n","      <td>0.677201</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.258400</td>\n","      <td>0.606023</td>\n","      <td>0.811977</td>\n","      <td>0.771290</td>\n","      <td>0.770949</td>\n","      <td>0.772440</td>\n","      <td>0.788264</td>\n","      <td>0.810865</td>\n","      <td>0.766889</td>\n","      <td>0.877823</td>\n","      <td>0.877823</td>\n","      <td>0.877823</td>\n","      <td>0.647782</td>\n","      <td>0.628631</td>\n","      <td>0.668137</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/5/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/5/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/5/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/5/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/5/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/5/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/5/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/5/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/5/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/5/checkpoint-4660 (score: 0.48836562037467957).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_5\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_5/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_5/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.10.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:31, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.584600</td>\n","      <td>0.541674</td>\n","      <td>0.781284</td>\n","      <td>0.733953</td>\n","      <td>0.744991</td>\n","      <td>0.725017</td>\n","      <td>0.720298</td>\n","      <td>0.680080</td>\n","      <td>0.765572</td>\n","      <td>0.855182</td>\n","      <td>0.876712</td>\n","      <td>0.834685</td>\n","      <td>0.626379</td>\n","      <td>0.618257</td>\n","      <td>0.634718</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.431700</td>\n","      <td>0.500074</td>\n","      <td>0.807040</td>\n","      <td>0.765278</td>\n","      <td>0.772089</td>\n","      <td>0.759675</td>\n","      <td>0.784057</td>\n","      <td>0.781690</td>\n","      <td>0.786437</td>\n","      <td>0.870862</td>\n","      <td>0.886338</td>\n","      <td>0.855917</td>\n","      <td>0.640914</td>\n","      <td>0.610996</td>\n","      <td>0.673913</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.266500</td>\n","      <td>0.601847</td>\n","      <td>0.807684</td>\n","      <td>0.769474</td>\n","      <td>0.764901</td>\n","      <td>0.774971</td>\n","      <td>0.789754</td>\n","      <td>0.821932</td>\n","      <td>0.760000</td>\n","      <td>0.872564</td>\n","      <td>0.861903</td>\n","      <td>0.883491</td>\n","      <td>0.646106</td>\n","      <td>0.641079</td>\n","      <td>0.651212</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/6/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/6/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/6/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/6/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/6/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/6/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/6/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/6/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/6/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/6/checkpoint-4660 (score: 0.5000737905502319).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_6\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_6/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_6/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.10.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:31, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.576500</td>\n","      <td>0.547322</td>\n","      <td>0.779352</td>\n","      <td>0.739502</td>\n","      <td>0.734051</td>\n","      <td>0.746486</td>\n","      <td>0.735336</td>\n","      <td>0.775654</td>\n","      <td>0.699003</td>\n","      <td>0.849227</td>\n","      <td>0.834136</td>\n","      <td>0.864875</td>\n","      <td>0.633943</td>\n","      <td>0.629668</td>\n","      <td>0.638275</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.437600</td>\n","      <td>0.519798</td>\n","      <td>0.807040</td>\n","      <td>0.761613</td>\n","      <td>0.775607</td>\n","      <td>0.755199</td>\n","      <td>0.777670</td>\n","      <td>0.805835</td>\n","      <td>0.751407</td>\n","      <td>0.870805</td>\n","      <td>0.893373</td>\n","      <td>0.849349</td>\n","      <td>0.636364</td>\n","      <td>0.566390</td>\n","      <td>0.726064</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.257000</td>\n","      <td>0.609529</td>\n","      <td>0.810904</td>\n","      <td>0.772249</td>\n","      <td>0.768905</td>\n","      <td>0.776631</td>\n","      <td>0.786094</td>\n","      <td>0.818913</td>\n","      <td>0.755803</td>\n","      <td>0.875607</td>\n","      <td>0.867827</td>\n","      <td>0.883528</td>\n","      <td>0.655045</td>\n","      <td>0.643154</td>\n","      <td>0.667384</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/7/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/7/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/7/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/7/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/7/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/7/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/7/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/7/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/7/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/7/checkpoint-4660 (score: 0.5197977423667908).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_7\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_7/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_7/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.10.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:33, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.580900</td>\n","      <td>0.550800</td>\n","      <td>0.778064</td>\n","      <td>0.729405</td>\n","      <td>0.736530</td>\n","      <td>0.727191</td>\n","      <td>0.728407</td>\n","      <td>0.763581</td>\n","      <td>0.696330</td>\n","      <td>0.851507</td>\n","      <td>0.863014</td>\n","      <td>0.840303</td>\n","      <td>0.608300</td>\n","      <td>0.554979</td>\n","      <td>0.672956</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.439200</td>\n","      <td>0.515862</td>\n","      <td>0.801889</td>\n","      <td>0.754323</td>\n","      <td>0.767543</td>\n","      <td>0.743490</td>\n","      <td>0.761453</td>\n","      <td>0.727364</td>\n","      <td>0.798895</td>\n","      <td>0.873406</td>\n","      <td>0.900407</td>\n","      <td>0.847978</td>\n","      <td>0.628108</td>\n","      <td>0.602697</td>\n","      <td>0.655756</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.271100</td>\n","      <td>0.605962</td>\n","      <td>0.807040</td>\n","      <td>0.768064</td>\n","      <td>0.765734</td>\n","      <td>0.770553</td>\n","      <td>0.791687</td>\n","      <td>0.804829</td>\n","      <td>0.778968</td>\n","      <td>0.872836</td>\n","      <td>0.867827</td>\n","      <td>0.877903</td>\n","      <td>0.639668</td>\n","      <td>0.639004</td>\n","      <td>0.640333</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/8/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/8/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/8/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/8/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/8/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/8/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/8/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/8/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/8/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/8/checkpoint-4660 (score: 0.5158617496490479).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_8\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_8/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_8/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.10.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:30, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.578700</td>\n","      <td>0.562046</td>\n","      <td>0.775488</td>\n","      <td>0.722499</td>\n","      <td>0.748750</td>\n","      <td>0.705101</td>\n","      <td>0.703586</td>\n","      <td>0.671026</td>\n","      <td>0.739468</td>\n","      <td>0.847273</td>\n","      <td>0.894484</td>\n","      <td>0.804797</td>\n","      <td>0.616638</td>\n","      <td>0.549793</td>\n","      <td>0.701987</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.445000</td>\n","      <td>0.537687</td>\n","      <td>0.794806</td>\n","      <td>0.740744</td>\n","      <td>0.765282</td>\n","      <td>0.732078</td>\n","      <td>0.758554</td>\n","      <td>0.791751</td>\n","      <td>0.728030</td>\n","      <td>0.865028</td>\n","      <td>0.899297</td>\n","      <td>0.833276</td>\n","      <td>0.598648</td>\n","      <td>0.505187</td>\n","      <td>0.734540</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.268000</td>\n","      <td>0.621006</td>\n","      <td>0.802747</td>\n","      <td>0.762827</td>\n","      <td>0.766439</td>\n","      <td>0.759462</td>\n","      <td>0.785388</td>\n","      <td>0.778672</td>\n","      <td>0.792221</td>\n","      <td>0.866728</td>\n","      <td>0.875231</td>\n","      <td>0.858388</td>\n","      <td>0.636364</td>\n","      <td>0.624481</td>\n","      <td>0.648707</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/9/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/9/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/9/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/9/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/9/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/9/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/9/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/9/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/9/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/9/checkpoint-4660 (score: 0.5376865267753601).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_9\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_9/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_9/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.10.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:32, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.580000</td>\n","      <td>0.541211</td>\n","      <td>0.784718</td>\n","      <td>0.730886</td>\n","      <td>0.746183</td>\n","      <td>0.720855</td>\n","      <td>0.715726</td>\n","      <td>0.714286</td>\n","      <td>0.717172</td>\n","      <td>0.862254</td>\n","      <td>0.892262</td>\n","      <td>0.834199</td>\n","      <td>0.614679</td>\n","      <td>0.556017</td>\n","      <td>0.687179</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.441600</td>\n","      <td>0.496978</td>\n","      <td>0.808543</td>\n","      <td>0.761765</td>\n","      <td>0.769104</td>\n","      <td>0.757161</td>\n","      <td>0.770977</td>\n","      <td>0.785714</td>\n","      <td>0.756783</td>\n","      <td>0.878865</td>\n","      <td>0.894484</td>\n","      <td>0.863783</td>\n","      <td>0.635452</td>\n","      <td>0.591286</td>\n","      <td>0.686747</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.269800</td>\n","      <td>0.591914</td>\n","      <td>0.815196</td>\n","      <td>0.774962</td>\n","      <td>0.776102</td>\n","      <td>0.773992</td>\n","      <td>0.791604</td>\n","      <td>0.796781</td>\n","      <td>0.786495</td>\n","      <td>0.880693</td>\n","      <td>0.884117</td>\n","      <td>0.877296</td>\n","      <td>0.652587</td>\n","      <td>0.641079</td>\n","      <td>0.664516</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/10/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/10/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/10/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/10/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/10/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/10/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/10/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/10/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/10/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_reinit//results/10/checkpoint-4660 (score: 0.49697786569595337).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_10\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_10/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_reinit//models/model_10/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}]},{"cell_type":"code","source":["results_df = pd.DataFrame(result_list)\n","results_df.to_csv('/content/drive/MyDrive/Dissertation/results/distilbert_reinit.csv')"],"metadata":{"id":"o5KikoACuVYQ","executionInfo":{"status":"ok","timestamp":1644795089517,"user_tz":0,"elapsed":482,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["#Sort rows to determine the mix, max and median \n","results_df = results_df.sort_values(by=['eval_f1'])\n","#Print min values\n","results_df.head(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"id":"tAmuZCaLuVrN","executionInfo":{"status":"ok","timestamp":1644795089518,"user_tz":0,"elapsed":21,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"b8c8d1de-3f07-4c70-8770-9297eb9c168f"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-2469a3f7-1b12-4a9e-b843-f5fa7355f259\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eval_loss</th>\n","      <th>eval_accuracy</th>\n","      <th>eval_f1</th>\n","      <th>eval_precision</th>\n","      <th>eval_recall</th>\n","      <th>eval_hate_f1</th>\n","      <th>eval_hate_recall</th>\n","      <th>eval_hate_precision</th>\n","      <th>eval_offensive_f1</th>\n","      <th>eval_offensive_recall</th>\n","      <th>eval_offensive_precision</th>\n","      <th>eval_normal_f1</th>\n","      <th>eval_normal_recall</th>\n","      <th>eval_normal_precision</th>\n","      <th>eval_runtime</th>\n","      <th>eval_samples_per_second</th>\n","      <th>eval_steps_per_second</th>\n","      <th>epoch</th>\n","      <th>model_run</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>0.531342</td>\n","      <td>0.787677</td>\n","      <td>0.738652</td>\n","      <td>0.745633</td>\n","      <td>0.740706</td>\n","      <td>0.72744</td>\n","      <td>0.795569</td>\n","      <td>0.670059</td>\n","      <td>0.864166</td>\n","      <td>0.865926</td>\n","      <td>0.862412</td>\n","      <td>0.624351</td>\n","      <td>0.560622</td>\n","      <td>0.704427</td>\n","      <td>3.7302</td>\n","      <td>1248.74</td>\n","      <td>78.281</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2469a3f7-1b12-4a9e-b843-f5fa7355f259')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2469a3f7-1b12-4a9e-b843-f5fa7355f259 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2469a3f7-1b12-4a9e-b843-f5fa7355f259');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   eval_loss  eval_accuracy   eval_f1  ...  eval_steps_per_second  epoch  model_run\n","3   0.531342       0.787677  0.738652  ...                 78.281    3.0          4\n","\n","[1 rows x 19 columns]"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["#Print max values \n","results_df.tail(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"id":"GiRSHVV1uV3k","executionInfo":{"status":"ok","timestamp":1644795089518,"user_tz":0,"elapsed":19,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"a1aad91c-404a-4e8e-a287-7d740e287f0e"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-78d60fc2-cce4-4a44-80b5-844e9b0af708\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eval_loss</th>\n","      <th>eval_accuracy</th>\n","      <th>eval_f1</th>\n","      <th>eval_precision</th>\n","      <th>eval_recall</th>\n","      <th>eval_hate_f1</th>\n","      <th>eval_hate_recall</th>\n","      <th>eval_hate_precision</th>\n","      <th>eval_offensive_f1</th>\n","      <th>eval_offensive_recall</th>\n","      <th>eval_offensive_precision</th>\n","      <th>eval_normal_f1</th>\n","      <th>eval_normal_recall</th>\n","      <th>eval_normal_precision</th>\n","      <th>eval_runtime</th>\n","      <th>eval_samples_per_second</th>\n","      <th>eval_steps_per_second</th>\n","      <th>epoch</th>\n","      <th>model_run</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.496077</td>\n","      <td>0.806784</td>\n","      <td>0.768004</td>\n","      <td>0.760762</td>\n","      <td>0.777852</td>\n","      <td>0.789647</td>\n","      <td>0.844914</td>\n","      <td>0.741166</td>\n","      <td>0.873864</td>\n","      <td>0.854444</td>\n","      <td>0.894186</td>\n","      <td>0.640502</td>\n","      <td>0.634197</td>\n","      <td>0.646934</td>\n","      <td>3.7606</td>\n","      <td>1238.621</td>\n","      <td>77.646</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78d60fc2-cce4-4a44-80b5-844e9b0af708')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-78d60fc2-cce4-4a44-80b5-844e9b0af708 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-78d60fc2-cce4-4a44-80b5-844e9b0af708');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   eval_loss  eval_accuracy   eval_f1  ...  eval_steps_per_second  epoch  model_run\n","1   0.496077       0.806784  0.768004  ...                 77.646    3.0          2\n","\n","[1 rows x 19 columns]"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["#Print median f1\n","results_df[\"eval_f1\"].median()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uSyRqJSyuWBY","executionInfo":{"status":"ok","timestamp":1644795089519,"user_tz":0,"elapsed":18,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"06e9f47e-06f7-4241-8504-d0ead787576c"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7535629447301149"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["#Print average values\n","results_df.mean()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3DSjhx1cuWIp","executionInfo":{"status":"ok","timestamp":1644795089520,"user_tz":0,"elapsed":14,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"7248696c-8c44-4c59-deb4-1e0cb9d2308d"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["eval_loss                      0.512189\n","eval_accuracy                  0.800451\n","eval_f1                        0.754041\n","eval_precision                 0.761405\n","eval_recall                    0.752522\n","eval_hate_f1                   0.767212\n","eval_hate_recall               0.799194\n","eval_hate_precision            0.739833\n","eval_offensive_f1              0.870401\n","eval_offensive_recall          0.880444\n","eval_offensive_precision       0.861182\n","eval_normal_f1                 0.624511\n","eval_normal_recall             0.577927\n","eval_normal_precision          0.683202\n","eval_runtime                   3.758570\n","eval_samples_per_second     1240.070400\n","eval_steps_per_second         77.737400\n","epoch                          3.000000\n","model_run                      5.500000\n","dtype: float64"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["results_df.std()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NVXvrEsQuWOL","executionInfo":{"status":"ok","timestamp":1644795089520,"user_tz":0,"elapsed":12,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"94c2bcf7-87b5-47e3-a805-21489b7c45ef"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["eval_loss                    0.010762\n","eval_accuracy                0.006596\n","eval_f1                      0.009888\n","eval_precision               0.008954\n","eval_recall                  0.013808\n","eval_hate_f1                 0.017254\n","eval_hate_recall             0.035497\n","eval_hate_precision          0.035162\n","eval_offensive_f1            0.003763\n","eval_offensive_recall        0.018021\n","eval_offensive_precision     0.017242\n","eval_normal_f1               0.014798\n","eval_normal_recall           0.038309\n","eval_normal_precision        0.031556\n","eval_runtime                 0.101684\n","eval_samples_per_second     31.615415\n","eval_steps_per_second        1.982021\n","epoch                        0.000000\n","model_run                    3.027650\n","dtype: float64"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["training_loss_min = [0.5717,0.441300,0.2683]\n","training_loss_max = [0.57460,0.442,0.2661]\n","val_loss_min = [0.570152,0.525531,0.596814]\n","val_loss_max = [0.5456659,0.504951,0.583835]\n","epoch_list=[1,2,3]\n","\n","plt.figure()\n","plt.plot(epoch_list,training_loss_min, label=\"Training Loss Min Run\")\n","plt.plot(epoch_list,val_loss_min, label=\"Validation Loss Min Run\")\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.xticks(epoch_list)\n","plt.legend()\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"7OsRZYTeuwwB","executionInfo":{"status":"ok","timestamp":1644795090030,"user_tz":0,"elapsed":519,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"309fe0fb-851d-40b1-e62d-e9829bce5f2e"},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["\n","plt.figure()\n","plt.plot(epoch_list,training_loss_max, label=\"Training Loss Max Run\")\n","plt.plot(epoch_list,val_loss_max, label=\"Validation Loss Max Run\")\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.xticks(epoch_list)\n","plt.legend()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"gkVOwCEAuxd_","executionInfo":{"status":"ok","timestamp":1644795090031,"user_tz":0,"elapsed":17,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"16c54a98-a406-4641-ea2a-c1d644163eaf"},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Distilbert HateTwit Layer Reinit Results.ipynb","provenance":[{"file_id":"1-rZqxPTOtm21puGsZKK_FiKXeyCg7py7","timestamp":1644757737493},{"file_id":"15wylWRQJ1vxlP58OhBHUnY5fdagThMvJ","timestamp":1643406846637},{"file_id":"1B35hajBJY3fRQV7LSjqoqQ3xjdcyCzE3","timestamp":1642365829686},{"file_id":"1b0lCW2Cj6AULiE-Axh2OeZwURHR6pfcD","timestamp":1642333651961},{"file_id":"1RAjFaq-k9CLJQP5eO668UXLc0q-wjuve","timestamp":1642280213414},{"file_id":"1LzZr7GRN1SwVrNyjVX5t5PpCvio8w_kE","timestamp":1642109182548},{"file_id":"1t-qzEyxZtGn_Cnlfg2WtN-0dlgUmxfzx","timestamp":1641764210714},{"file_id":"14bEU8hCGPF8cVUA_BonJQA6Brv89DKUm","timestamp":1641252935713},{"file_id":"18Il3CpGf89tF1Z10iYX8OdfeHxxAX1Ui","timestamp":1639243141142},{"file_id":"1SHCgoRQVGtl9OiWEJGK3JgKkuxxSPy_5","timestamp":1639231968300},{"file_id":"1D-3yvF0nGnaWEZGxQj21R6fsGnyv5a5g","timestamp":1637526185003},{"file_id":"1glXr2JglKPUpN_3AGyk3GjfCtZSDNfsZ","timestamp":1637408594851},{"file_id":"1rc5hX8PBIv7GKvlxLQ35Vwf2jxLsv9f4","timestamp":1634501666668}],"mount_file_id":"12ss-KSYiGYDJavkcCym60e-RxEKzcROm","authorship_tag":"ABX9TyNaQK12vGlNCwUPrz9sscoz"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}