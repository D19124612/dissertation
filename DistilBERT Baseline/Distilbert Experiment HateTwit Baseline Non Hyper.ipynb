{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14310,"status":"ok","timestamp":1645612383999,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"},"user_tz":0},"id":"F-o6bXOJ18j4","outputId":"195f69d2-1afe-48b1-9af2-ece99926192c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |████████████████████████████████| 3.5 MB 13.3 MB/s \n","\u001b[K     |████████████████████████████████| 6.8 MB 62.8 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 66.4 MB/s \n","\u001b[K     |████████████████████████████████| 67 kB 6.2 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 83.5 MB/s \n","\u001b[K     |████████████████████████████████| 311 kB 12.9 MB/s \n","\u001b[K     |████████████████████████████████| 134 kB 74.7 MB/s \n","\u001b[K     |████████████████████████████████| 243 kB 85.2 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 74.6 MB/s \n","\u001b[K     |████████████████████████████████| 144 kB 75.1 MB/s \n","\u001b[K     |████████████████████████████████| 271 kB 65.2 MB/s \n","\u001b[K     |████████████████████████████████| 94 kB 3.3 MB/s \n","\u001b[?25h"]}],"source":["!pip install -qq transformers\n","!pip install -qq datasets\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rz6wNlu92ge_"},"outputs":[],"source":["import transformers\n","import datasets\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification,AdamW, get_linear_schedule_with_warmup,Trainer, TrainingArguments\n","from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n","import torch\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from matplotlib import rc\n","import random\n","from datetime import datetime\n","from datasets import load_from_disk\n","from datasets import Dataset\n","from sklearn.metrics import accuracy_score,classification_report, confusion_matrix\n","from sklearn.metrics import precision_recall_fscore_support"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T7IFr4-3TKaA"},"outputs":[],"source":["# the model we gonna train, base uncased BERT\n","# check text classification models here: https://huggingface.co/models?filter=text-classification\n","MODEL_NAME = \"distilbert-base-uncased\"\n","# max sequence length for each document/sentence sample\n","MAX_LENGTH = 64\n","BATCH_SIZE = 32\n","EPOCHS = 3\n","LEARNING_RATE= 1e-5\n","RANDOM_SEED=2\n","\n","\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YoKXcvyo_X47"},"outputs":[],"source":["def set_seed(seed):\n","    \"\"\"Set all seeds to make results reproducible (deterministic mode).\n","       When seed is None, disables deterministic mode.\n","    :param seed: an integer to your choosing\n","    \"\"\"\n","    if seed is not None:\n","        torch.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","        np.random.seed(seed)\n","        random.seed(seed)\n","\n","def compute_metrics(pred):\n","  labels = pred.label_ids\n","  preds = pred.predictions.argmax(-1)\n","  # calculate accuracy using sklearn's function\n","  acc = accuracy_score(labels, preds)\n","  precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n","  acc = accuracy_score(labels, preds)\n","  confusion_matrix = classification_report(labels, preds, digits=4,output_dict=True)\n","  return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall,\n","        'hate_f1': confusion_matrix[\"0\"][\"f1-score\"],\n","        'hate_recall': confusion_matrix[\"0\"][\"recall\"],\n","        'hate_precision': confusion_matrix[\"0\"][\"precision\"],\n","        'offensive_f1': confusion_matrix[\"1\"][\"f1-score\"],\n","        'offensive_recall': confusion_matrix[\"1\"][\"recall\"],\n","        'offensive_precision': confusion_matrix[\"1\"][\"precision\"],\n","        'normal_f1': confusion_matrix[\"2\"][\"f1-score\"],\n","        'normal_recall': confusion_matrix[\"2\"][\"recall\"],\n","        'normal_precision': confusion_matrix[\"2\"][\"precision\"],    \n","  }\n","\n","def model_init():\n","  temp_model =  AutoModelForSequenceClassification.from_pretrained(MODEL_NAME,num_labels=3).to(device)\n","  return temp_model\n","\n","def timestamp():\n","    dateTimeObj = datetime.now()\n","    timestampStr = dateTimeObj.strftime(\"%d-%b-%Y (%H:%M:%S.%f)\")\n","    print(timestampStr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lqKiS7jbkC4x"},"outputs":[],"source":["set_seed(RANDOM_SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["f1bdff56afee4109b501214df212c559","24ce3f986e904a6d94a368b1e599e1a4","df21f15e093845b4af9adcb667665f12","77308e371b6641dc9274b2a147adcd80","6594f432bb234f948003a2eceace47fb","7c203097c9a14431b0f063cc28663a3d","e93d8b577da94ac4a57524b51bb7c038","85b4bf44e1e44f038d21c1b1dab24e68","edf6e95e128344ab9beb4b1d0397f492","1ff585973a3044ea900bce575dcfa713","d1166243516a4b418bcd7aae8d07ceab","275f3106f7054aa1a1182c5621b105f4","fd0f0859fdf84cd387f74e3943316635","cf1cb1d96fec452aa26b3480a93b231d","b35abc2d16fb428083b84bcf0ae46722","8ce92f93ab904b26b661e0ed845dbad6","d1e91c7d737c483c81957832751c15bc","f539c84378c0423ca4decd668096a604","a98ca39d33b24294a3c5b168b78e097c","57c64bd6db0d4a338cd3c114bdd9613d","8e18aade616e4758aad742a1b8e766d6","6f1dca92367e4bb1a3c22a6889e3ca32","6e781f09e5bf462aaaa80f31a1dbdf60","905571a80cc145d09e84535ea652851c","e298a34baabf451d8d90208c6eb03cee","cb62781ebd094515b07c5a5d952f0aed","d32c44771deb4207991dcb40432438dc","655f5613563642ebb67d3a1b38b9faea","380f76be13154e71adbd14d60aeca9a4","35bbe29a68df448bad6a1bfac94eab13","d62ccb37095b4db99fa45f5b16a0bdfb","57ac3abf4a4e46d8948d2c5a7bc7c5ee","7b084d3aeadd40d8bfb871ac5c3802c6","610db12da17b496a9e96338d0da52d09","cb568ee03aba4d8b81648294484da130","c8e8e6a6bd234b07bc573d6519991fed","d389227d26a14921838c48b69bbf440c","e8b1fb6d741c4633b467382094a38361","0b6cbceda29040128178f3adced0789d","8885ca08b7c044519a272376c9fb5967","137e61e583e04e2ab8300f5cd319e744","84515947b60f43f6aa43060608e484a5","7d7b4b4f694147c7965b450aeb13a2f8","32d3eb083a744e32bbdc3283e239ef55"]},"executionInfo":{"elapsed":6054,"status":"ok","timestamp":1645612398898,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"},"user_tz":0},"id":"AMEUIo294iAd","outputId":"9f9db242-b109-48a1-90c2-c5ff15cbf416"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f1bdff56afee4109b501214df212c559","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"275f3106f7054aa1a1182c5621b105f4","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6e781f09e5bf462aaaa80f31a1dbdf60","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"610db12da17b496a9e96338d0da52d09","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["cac3a524c47f44f482db573a6d485e84","b54f1f0a17e9438b9242c70dc39c5e4b","3bf7fd32ec724eaf823dc2eaa13b490d","13a42522f379454d82900e6465b096fb","7a1f63ca96a84f73ad16ada30967c8a3","3bb7711f7ec247829cf9bccb32e874ab","e9dad320b0b44787b64c8f01ccf6f35a","f2e584763e8d4f63a1ddb0f8f47b7aae","3d7107e4766f4280b2152c33f06dee84","77fedfa616d04d829e16792b4b4f204a","6944c83c54614e8caa38debe94633a20"]},"id":"aum4jWZzXdgX","outputId":"60fba361-3007-4570-fa88-4c01e255da2c"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cac3a524c47f44f482db573a6d485e84","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3495\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3495/3495 04:16, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.609200</td>\n","      <td>0.566570</td>\n","      <td>0.770337</td>\n","      <td>0.721660</td>\n","      <td>0.724208</td>\n","      <td>0.719893</td>\n","      <td>0.705941</td>\n","      <td>0.717304</td>\n","      <td>0.694932</td>\n","      <td>0.848797</td>\n","      <td>0.855239</td>\n","      <td>0.842451</td>\n","      <td>0.610243</td>\n","      <td>0.587137</td>\n","      <td>0.635241</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.530300</td>\n","      <td>0.530467</td>\n","      <td>0.782357</td>\n","      <td>0.730347</td>\n","      <td>0.741188</td>\n","      <td>0.724521</td>\n","      <td>0.725490</td>\n","      <td>0.744467</td>\n","      <td>0.707457</td>\n","      <td>0.858796</td>\n","      <td>0.879304</td>\n","      <td>0.839223</td>\n","      <td>0.606754</td>\n","      <td>0.549793</td>\n","      <td>0.676884</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.487500</td>\n","      <td>0.525276</td>\n","      <td>0.785362</td>\n","      <td>0.733947</td>\n","      <td>0.741674</td>\n","      <td>0.731971</td>\n","      <td>0.732569</td>\n","      <td>0.771630</td>\n","      <td>0.697273</td>\n","      <td>0.862516</td>\n","      <td>0.874491</td>\n","      <td>0.850865</td>\n","      <td>0.606754</td>\n","      <td>0.549793</td>\n","      <td>0.676884</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/1/checkpoint-1165\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/1/checkpoint-1165/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/1/checkpoint-1165/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/1/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/1/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/1/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/1/checkpoint-3495\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/1/checkpoint-3495/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/1/checkpoint-3495/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/1/checkpoint-3495 (score: 0.5252763628959656).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_1\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_1/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_1/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 32\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [146/146 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3495\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3495/3495 04:16, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.601300</td>\n","      <td>0.560955</td>\n","      <td>0.775703</td>\n","      <td>0.716191</td>\n","      <td>0.744228</td>\n","      <td>0.701079</td>\n","      <td>0.716692</td>\n","      <td>0.706237</td>\n","      <td>0.727461</td>\n","      <td>0.852838</td>\n","      <td>0.901148</td>\n","      <td>0.809445</td>\n","      <td>0.579043</td>\n","      <td>0.495851</td>\n","      <td>0.695779</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.536300</td>\n","      <td>0.530066</td>\n","      <td>0.785362</td>\n","      <td>0.734105</td>\n","      <td>0.744068</td>\n","      <td>0.731950</td>\n","      <td>0.727187</td>\n","      <td>0.773642</td>\n","      <td>0.685995</td>\n","      <td>0.861887</td>\n","      <td>0.874491</td>\n","      <td>0.849640</td>\n","      <td>0.613240</td>\n","      <td>0.547718</td>\n","      <td>0.696570</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.480500</td>\n","      <td>0.520064</td>\n","      <td>0.787293</td>\n","      <td>0.740086</td>\n","      <td>0.745799</td>\n","      <td>0.737654</td>\n","      <td>0.731589</td>\n","      <td>0.759557</td>\n","      <td>0.705607</td>\n","      <td>0.860384</td>\n","      <td>0.870418</td>\n","      <td>0.850579</td>\n","      <td>0.628284</td>\n","      <td>0.582988</td>\n","      <td>0.681212</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/2/checkpoint-1165\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/2/checkpoint-1165/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/2/checkpoint-1165/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/2/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/2/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/2/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/2/checkpoint-3495\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/2/checkpoint-3495/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/2/checkpoint-3495/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/2/checkpoint-3495 (score: 0.5200636386871338).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_2\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_2/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_2/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 32\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [146/146 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3495\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3495/3495 04:21, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.597700</td>\n","      <td>0.570481</td>\n","      <td>0.766259</td>\n","      <td>0.710510</td>\n","      <td>0.722105</td>\n","      <td>0.703539</td>\n","      <td>0.709100</td>\n","      <td>0.717304</td>\n","      <td>0.701082</td>\n","      <td>0.846915</td>\n","      <td>0.871529</td>\n","      <td>0.823653</td>\n","      <td>0.575515</td>\n","      <td>0.521784</td>\n","      <td>0.641582</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.523700</td>\n","      <td>0.547137</td>\n","      <td>0.779781</td>\n","      <td>0.719515</td>\n","      <td>0.744641</td>\n","      <td>0.711428</td>\n","      <td>0.739026</td>\n","      <td>0.770624</td>\n","      <td>0.709917</td>\n","      <td>0.856788</td>\n","      <td>0.893743</td>\n","      <td>0.822768</td>\n","      <td>0.562733</td>\n","      <td>0.469917</td>\n","      <td>0.701238</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.479000</td>\n","      <td>0.541061</td>\n","      <td>0.781927</td>\n","      <td>0.728824</td>\n","      <td>0.740292</td>\n","      <td>0.722433</td>\n","      <td>0.736063</td>\n","      <td>0.750503</td>\n","      <td>0.722168</td>\n","      <td>0.858327</td>\n","      <td>0.881525</td>\n","      <td>0.836319</td>\n","      <td>0.592083</td>\n","      <td>0.535270</td>\n","      <td>0.662388</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/3/checkpoint-1165\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/3/checkpoint-1165/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/3/checkpoint-1165/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/3/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/3/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/3/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/3/checkpoint-3495\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/3/checkpoint-3495/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/3/checkpoint-3495/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/3/checkpoint-3495 (score: 0.5410612225532532).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_3\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_3/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_3/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 32\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [146/146 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3495\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3495/3495 04:15, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.614400</td>\n","      <td>0.581375</td>\n","      <td>0.763469</td>\n","      <td>0.703961</td>\n","      <td>0.732537</td>\n","      <td>0.687474</td>\n","      <td>0.696781</td>\n","      <td>0.675050</td>\n","      <td>0.719957</td>\n","      <td>0.840929</td>\n","      <td>0.891522</td>\n","      <td>0.795770</td>\n","      <td>0.574174</td>\n","      <td>0.495851</td>\n","      <td>0.681883</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.534700</td>\n","      <td>0.559762</td>\n","      <td>0.771196</td>\n","      <td>0.724205</td>\n","      <td>0.725529</td>\n","      <td>0.731094</td>\n","      <td>0.719457</td>\n","      <td>0.799799</td>\n","      <td>0.653783</td>\n","      <td>0.847508</td>\n","      <td>0.837468</td>\n","      <td>0.857793</td>\n","      <td>0.605650</td>\n","      <td>0.556017</td>\n","      <td>0.665012</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.479100</td>\n","      <td>0.546558</td>\n","      <td>0.780425</td>\n","      <td>0.729420</td>\n","      <td>0.738018</td>\n","      <td>0.726134</td>\n","      <td>0.729026</td>\n","      <td>0.760563</td>\n","      <td>0.700000</td>\n","      <td>0.856259</td>\n","      <td>0.871159</td>\n","      <td>0.841860</td>\n","      <td>0.602975</td>\n","      <td>0.546680</td>\n","      <td>0.672194</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/4/checkpoint-1165\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/4/checkpoint-1165/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/4/checkpoint-1165/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/4/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/4/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/4/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/4/checkpoint-3495\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/4/checkpoint-3495/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/4/checkpoint-3495/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/4/checkpoint-3495 (score: 0.5465583801269531).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_4\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_4/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_4/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 32\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [146/146 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3495\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3495/3495 04:14, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.601500</td>\n","      <td>0.557297</td>\n","      <td>0.773986</td>\n","      <td>0.713619</td>\n","      <td>0.736605</td>\n","      <td>0.702360</td>\n","      <td>0.716849</td>\n","      <td>0.723340</td>\n","      <td>0.710474</td>\n","      <td>0.853960</td>\n","      <td>0.894113</td>\n","      <td>0.817259</td>\n","      <td>0.570048</td>\n","      <td>0.489627</td>\n","      <td>0.682081</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.528900</td>\n","      <td>0.528806</td>\n","      <td>0.784718</td>\n","      <td>0.735536</td>\n","      <td>0.743128</td>\n","      <td>0.730972</td>\n","      <td>0.730315</td>\n","      <td>0.746479</td>\n","      <td>0.714836</td>\n","      <td>0.859273</td>\n","      <td>0.874861</td>\n","      <td>0.844230</td>\n","      <td>0.617021</td>\n","      <td>0.571577</td>\n","      <td>0.670316</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.488500</td>\n","      <td>0.523649</td>\n","      <td>0.786864</td>\n","      <td>0.734740</td>\n","      <td>0.746198</td>\n","      <td>0.730219</td>\n","      <td>0.734458</td>\n","      <td>0.766600</td>\n","      <td>0.704903</td>\n","      <td>0.862681</td>\n","      <td>0.881525</td>\n","      <td>0.844626</td>\n","      <td>0.607081</td>\n","      <td>0.542531</td>\n","      <td>0.689065</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/5/checkpoint-1165\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/5/checkpoint-1165/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/5/checkpoint-1165/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/5/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/5/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/5/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/5/checkpoint-3495\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/5/checkpoint-3495/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/5/checkpoint-3495/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/5/checkpoint-3495 (score: 0.523648738861084).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_5\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_5/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_5/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 32\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [146/146 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3495\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3495/3495 04:18, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.612700</td>\n","      <td>0.568590</td>\n","      <td>0.768405</td>\n","      <td>0.711350</td>\n","      <td>0.729320</td>\n","      <td>0.702709</td>\n","      <td>0.706634</td>\n","      <td>0.723340</td>\n","      <td>0.690682</td>\n","      <td>0.847500</td>\n","      <td>0.878563</td>\n","      <td>0.818558</td>\n","      <td>0.579917</td>\n","      <td>0.506224</td>\n","      <td>0.678720</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.535100</td>\n","      <td>0.536096</td>\n","      <td>0.778923</td>\n","      <td>0.731908</td>\n","      <td>0.734638</td>\n","      <td>0.731062</td>\n","      <td>0.735151</td>\n","      <td>0.759557</td>\n","      <td>0.712264</td>\n","      <td>0.852784</td>\n","      <td>0.858941</td>\n","      <td>0.846715</td>\n","      <td>0.607789</td>\n","      <td>0.574689</td>\n","      <td>0.644936</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.478400</td>\n","      <td>0.529038</td>\n","      <td>0.783430</td>\n","      <td>0.736211</td>\n","      <td>0.740118</td>\n","      <td>0.735902</td>\n","      <td>0.742090</td>\n","      <td>0.778672</td>\n","      <td>0.708791</td>\n","      <td>0.856146</td>\n","      <td>0.862643</td>\n","      <td>0.849745</td>\n","      <td>0.610397</td>\n","      <td>0.566390</td>\n","      <td>0.661818</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/6/checkpoint-1165\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/6/checkpoint-1165/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/6/checkpoint-1165/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/6/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/6/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/6/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/6/checkpoint-3495\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/6/checkpoint-3495/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/6/checkpoint-3495/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/6/checkpoint-3495 (score: 0.5290379524230957).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_6\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_6/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_6/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 32\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [146/146 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3495\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3495/3495 04:17, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.608800</td>\n","      <td>0.570800</td>\n","      <td>0.770122</td>\n","      <td>0.720456</td>\n","      <td>0.724157</td>\n","      <td>0.720475</td>\n","      <td>0.718586</td>\n","      <td>0.756539</td>\n","      <td>0.684258</td>\n","      <td>0.847370</td>\n","      <td>0.853017</td>\n","      <td>0.841798</td>\n","      <td>0.595411</td>\n","      <td>0.551867</td>\n","      <td>0.646416</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.528300</td>\n","      <td>0.542565</td>\n","      <td>0.778923</td>\n","      <td>0.725218</td>\n","      <td>0.738683</td>\n","      <td>0.724460</td>\n","      <td>0.733766</td>\n","      <td>0.795775</td>\n","      <td>0.680723</td>\n","      <td>0.855062</td>\n","      <td>0.869308</td>\n","      <td>0.841276</td>\n","      <td>0.586826</td>\n","      <td>0.508299</td>\n","      <td>0.694051</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.493600</td>\n","      <td>0.533371</td>\n","      <td>0.783430</td>\n","      <td>0.733795</td>\n","      <td>0.739433</td>\n","      <td>0.731812</td>\n","      <td>0.735621</td>\n","      <td>0.765594</td>\n","      <td>0.707907</td>\n","      <td>0.859024</td>\n","      <td>0.869678</td>\n","      <td>0.848627</td>\n","      <td>0.606742</td>\n","      <td>0.560166</td>\n","      <td>0.661765</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/7/checkpoint-1165\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/7/checkpoint-1165/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/7/checkpoint-1165/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/7/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/7/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/7/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/7/checkpoint-3495\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/7/checkpoint-3495/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/7/checkpoint-3495/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/7/checkpoint-3495 (score: 0.5333713889122009).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_7\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_7/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_7/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 32\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [146/146 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3495\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3495/3495 04:19, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.603400</td>\n","      <td>0.581258</td>\n","      <td>0.761751</td>\n","      <td>0.711924</td>\n","      <td>0.712762</td>\n","      <td>0.712809</td>\n","      <td>0.702076</td>\n","      <td>0.731388</td>\n","      <td>0.675023</td>\n","      <td>0.842514</td>\n","      <td>0.843762</td>\n","      <td>0.841270</td>\n","      <td>0.591181</td>\n","      <td>0.563278</td>\n","      <td>0.621993</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.531600</td>\n","      <td>0.547291</td>\n","      <td>0.777849</td>\n","      <td>0.720906</td>\n","      <td>0.736195</td>\n","      <td>0.710711</td>\n","      <td>0.718861</td>\n","      <td>0.711268</td>\n","      <td>0.726619</td>\n","      <td>0.858519</td>\n","      <td>0.890781</td>\n","      <td>0.828512</td>\n","      <td>0.585338</td>\n","      <td>0.530083</td>\n","      <td>0.653453</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.480900</td>\n","      <td>0.543907</td>\n","      <td>0.780425</td>\n","      <td>0.727121</td>\n","      <td>0.736573</td>\n","      <td>0.721642</td>\n","      <td>0.729156</td>\n","      <td>0.743461</td>\n","      <td>0.715392</td>\n","      <td>0.858900</td>\n","      <td>0.878934</td>\n","      <td>0.839759</td>\n","      <td>0.593307</td>\n","      <td>0.542531</td>\n","      <td>0.654568</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/8/checkpoint-1165\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/8/checkpoint-1165/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/8/checkpoint-1165/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/8/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/8/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/8/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/8/checkpoint-3495\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/8/checkpoint-3495/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/8/checkpoint-3495/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/8/checkpoint-3495 (score: 0.543907105922699).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_8\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_8/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_8/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 32\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [146/146 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3495\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3495/3495 04:20, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.604700</td>\n","      <td>0.583537</td>\n","      <td>0.758317</td>\n","      <td>0.703865</td>\n","      <td>0.721325</td>\n","      <td>0.690743</td>\n","      <td>0.668441</td>\n","      <td>0.631791</td>\n","      <td>0.709605</td>\n","      <td>0.837061</td>\n","      <td>0.873010</td>\n","      <td>0.803955</td>\n","      <td>0.606094</td>\n","      <td>0.567427</td>\n","      <td>0.650416</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.533200</td>\n","      <td>0.553154</td>\n","      <td>0.773771</td>\n","      <td>0.720732</td>\n","      <td>0.734512</td>\n","      <td>0.711521</td>\n","      <td>0.708312</td>\n","      <td>0.707243</td>\n","      <td>0.709384</td>\n","      <td>0.850690</td>\n","      <td>0.878563</td>\n","      <td>0.824531</td>\n","      <td>0.603193</td>\n","      <td>0.548755</td>\n","      <td>0.669620</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.477700</td>\n","      <td>0.546683</td>\n","      <td>0.777635</td>\n","      <td>0.726536</td>\n","      <td>0.737515</td>\n","      <td>0.719114</td>\n","      <td>0.721722</td>\n","      <td>0.725352</td>\n","      <td>0.718127</td>\n","      <td>0.852920</td>\n","      <td>0.875972</td>\n","      <td>0.831050</td>\n","      <td>0.604966</td>\n","      <td>0.556017</td>\n","      <td>0.663366</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/9/checkpoint-1165\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/9/checkpoint-1165/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/9/checkpoint-1165/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/9/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/9/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/9/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/9/checkpoint-3495\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/9/checkpoint-3495/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/9/checkpoint-3495/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/9/checkpoint-3495 (score: 0.5466830134391785).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_9\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_9/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_9/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 32\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [146/146 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3495\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3495/3495 04:13, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.608100</td>\n","      <td>0.567444</td>\n","      <td>0.772269</td>\n","      <td>0.719522</td>\n","      <td>0.726743</td>\n","      <td>0.716039</td>\n","      <td>0.699708</td>\n","      <td>0.724346</td>\n","      <td>0.676692</td>\n","      <td>0.853445</td>\n","      <td>0.866716</td>\n","      <td>0.840575</td>\n","      <td>0.605411</td>\n","      <td>0.557054</td>\n","      <td>0.662963</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.531300</td>\n","      <td>0.537458</td>\n","      <td>0.782786</td>\n","      <td>0.733736</td>\n","      <td>0.737859</td>\n","      <td>0.731269</td>\n","      <td>0.722714</td>\n","      <td>0.739437</td>\n","      <td>0.706731</td>\n","      <td>0.860073</td>\n","      <td>0.869308</td>\n","      <td>0.851033</td>\n","      <td>0.618421</td>\n","      <td>0.585062</td>\n","      <td>0.655814</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.489500</td>\n","      <td>0.535090</td>\n","      <td>0.784503</td>\n","      <td>0.732842</td>\n","      <td>0.743352</td>\n","      <td>0.727260</td>\n","      <td>0.729677</td>\n","      <td>0.749497</td>\n","      <td>0.710878</td>\n","      <td>0.860503</td>\n","      <td>0.880415</td>\n","      <td>0.841472</td>\n","      <td>0.608348</td>\n","      <td>0.551867</td>\n","      <td>0.677707</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/10/checkpoint-1165\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/10/checkpoint-1165/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/10/checkpoint-1165/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/10/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/10/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/10/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/10/checkpoint-3495\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/10/checkpoint-3495/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/10/checkpoint-3495/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/10/checkpoint-3495 (score: 0.535089910030365).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_10\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_10/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_10/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 32\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [146/146 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["result_list = []\n","for i in range(1,11):\n","\n","  training_args = TrainingArguments(\n","    output_dir='/content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/results/'+str(i),          # output directory\n","    num_train_epochs=EPOCHS,              # total number of training epochs\n","    save_strategy =\"epoch\" ,\n","    per_device_train_batch_size=BATCH_SIZE,  # batch size per device during training\n","    per_device_eval_batch_size=BATCH_SIZE,   # batch size for evaluation\n","    learning_rate= LEARNING_RATE, \n","    logging_dir='./disbert_hate_baseline_no_hyper//logs',     # directory for storing logs\n","    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n","    evaluation_strategy=\"epoch\",\n","  )\n","\n","  hatetwit_dataset_dfs = load_from_disk('/content/drive/MyDrive/Dissertation/datasets/hatetwit_'+str(i))\n","  train_dataset = hatetwit_dataset_dfs [\"train\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","  eval_dataset = hatetwit_dataset_dfs [\"validation\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","  test_dataset = hatetwit_dataset_dfs [\"test\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","  model = model_init()\n","  trainer = Trainer(\n","      model=model,                         # the instantiated Transformers model to be trained\n","      args=training_args,                  # training arguments, defined above\n","      train_dataset= train_dataset,         # training dataset\n","      eval_dataset=eval_dataset,          # evaluation dataset\n","      compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n","  )\n","  trainer.train()\n","  trainer.save_model('/content/drive/MyDrive/Dissertation/disbert_hate_baseline_no_hyper/models/model_'+str(i))\n","  results = trainer.evaluate(test_dataset)\n","  results[\"model_run\"] = i\n","  result_list.append(results)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"xr7fZYm4Yp8_"},"outputs":[],"source":["results_df = pd.DataFrame(result_list)\n","results_df.to_csv('/content/drive/MyDrive/Dissertation/results/distilbert_baselines_no_hyper.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"V5Y8SojS_LB3","outputId":"324fa938-cb33-4bd5-a36d-3199d1cc571d"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-f2382b8c-0eb5-4a64-8cea-2b97c0a1a0c8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eval_loss</th>\n","      <th>eval_accuracy</th>\n","      <th>eval_f1</th>\n","      <th>eval_precision</th>\n","      <th>eval_recall</th>\n","      <th>eval_hate_f1</th>\n","      <th>eval_hate_recall</th>\n","      <th>eval_hate_precision</th>\n","      <th>eval_offensive_f1</th>\n","      <th>eval_offensive_recall</th>\n","      <th>eval_offensive_precision</th>\n","      <th>eval_normal_f1</th>\n","      <th>eval_normal_recall</th>\n","      <th>eval_normal_precision</th>\n","      <th>eval_runtime</th>\n","      <th>eval_samples_per_second</th>\n","      <th>eval_steps_per_second</th>\n","      <th>epoch</th>\n","      <th>model_run</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4</th>\n","      <td>0.557117</td>\n","      <td>0.773723</td>\n","      <td>0.720469</td>\n","      <td>0.730017</td>\n","      <td>0.716694</td>\n","      <td>0.720503</td>\n","      <td>0.750252</td>\n","      <td>0.693023</td>\n","      <td>0.85206</td>\n","      <td>0.869259</td>\n","      <td>0.835529</td>\n","      <td>0.588844</td>\n","      <td>0.53057</td>\n","      <td>0.661499</td>\n","      <td>3.2957</td>\n","      <td>1413.355</td>\n","      <td>44.3</td>\n","      <td>3.0</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2382b8c-0eb5-4a64-8cea-2b97c0a1a0c8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f2382b8c-0eb5-4a64-8cea-2b97c0a1a0c8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f2382b8c-0eb5-4a64-8cea-2b97c0a1a0c8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   eval_loss  eval_accuracy   eval_f1  ...  eval_steps_per_second  epoch  model_run\n","4   0.557117       0.773723  0.720469  ...                   44.3    3.0          5\n","\n","[1 rows x 19 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["#Sort rows to determine the mix, max and median \n","results_df = results_df.sort_values(by=['eval_f1'])\n","#Print min values\n","results_df.head(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rh5O2OL6_Qkd","outputId":"cf2dc6fe-a526-4f31-b73e-fd3a3aa07851"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-f955550e-8608-4365-8958-9e95b4d0fe61\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eval_loss</th>\n","      <th>eval_accuracy</th>\n","      <th>eval_f1</th>\n","      <th>eval_precision</th>\n","      <th>eval_recall</th>\n","      <th>eval_hate_f1</th>\n","      <th>eval_hate_recall</th>\n","      <th>eval_hate_precision</th>\n","      <th>eval_offensive_f1</th>\n","      <th>eval_offensive_recall</th>\n","      <th>eval_offensive_precision</th>\n","      <th>eval_normal_f1</th>\n","      <th>eval_normal_recall</th>\n","      <th>eval_normal_precision</th>\n","      <th>eval_runtime</th>\n","      <th>eval_samples_per_second</th>\n","      <th>eval_steps_per_second</th>\n","      <th>epoch</th>\n","      <th>model_run</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>0.53339</td>\n","      <td>0.791756</td>\n","      <td>0.741504</td>\n","      <td>0.753716</td>\n","      <td>0.73678</td>\n","      <td>0.744701</td>\n","      <td>0.778449</td>\n","      <td>0.713758</td>\n","      <td>0.864336</td>\n","      <td>0.883704</td>\n","      <td>0.845799</td>\n","      <td>0.615474</td>\n","      <td>0.548187</td>\n","      <td>0.701592</td>\n","      <td>3.8188</td>\n","      <td>1219.746</td>\n","      <td>38.232</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f955550e-8608-4365-8958-9e95b4d0fe61')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f955550e-8608-4365-8958-9e95b4d0fe61 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f955550e-8608-4365-8958-9e95b4d0fe61');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   eval_loss  eval_accuracy   eval_f1  ...  eval_steps_per_second  epoch  model_run\n","3    0.53339       0.791756  0.741504  ...                 38.232    3.0          4\n","\n","[1 rows x 19 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["#Print max values \n","results_df.tail(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"sdV3f6bE_blb","outputId":"41097c74-471e-4346-9548-44adc8b740f0"},"outputs":[{"data":{"text/plain":["0.7314957611022004"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["#Print median f1\n","results_df[\"eval_f1\"].median()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1XwImR50_dcZ","outputId":"2f98daf7-e6aa-40ec-c5a7-1407a25aafc8"},"outputs":[{"data":{"text/plain":["eval_loss                      0.537542\n","eval_accuracy                  0.782696\n","eval_f1                        0.731730\n","eval_precision                 0.741024\n","eval_recall                    0.727591\n","eval_hate_f1                   0.734793\n","eval_hate_recall               0.760725\n","eval_hate_precision            0.710688\n","eval_offensive_f1              0.857949\n","eval_offensive_recall          0.875000\n","eval_offensive_precision       0.841601\n","eval_normal_f1                 0.602448\n","eval_normal_recall             0.547047\n","eval_normal_precision          0.670783\n","eval_runtime                   3.363220\n","eval_samples_per_second     1387.583100\n","eval_steps_per_second         43.492500\n","epoch                          3.000000\n","model_run                      5.500000\n","dtype: float64"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["#Print average values\n","results_df.mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"cu8sEyeh_fWL","outputId":"cff3a928-97c2-42be-b012-602b7fa70a73"},"outputs":[{"data":{"text/plain":["eval_loss                    0.010383\n","eval_accuracy                0.005189\n","eval_f1                      0.005454\n","eval_precision               0.007121\n","eval_recall                  0.005209\n","eval_hate_f1                 0.006442\n","eval_hate_recall             0.009869\n","eval_hate_precision          0.009434\n","eval_offensive_f1            0.004838\n","eval_offensive_recall        0.007601\n","eval_offensive_precision     0.006385\n","eval_normal_f1               0.007400\n","eval_normal_recall           0.009812\n","eval_normal_precision        0.017554\n","eval_runtime                 0.162086\n","eval_samples_per_second     59.944719\n","eval_steps_per_second        1.878851\n","epoch                        0.000000\n","model_run                    3.027650\n","dtype: float64"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["results_df.std()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ETVYeOfB_iG8","outputId":"fb456dd3-e139-45d7-fda5-f0e4f75e5116"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["training_loss_min = [0.5717,0.441300,0.2683]\n","training_loss_max = [0.5689,0.42830,0.2549]\n","val_loss_min = [0.570152,0.525531,0.596814]\n","val_loss_max = [0.548766,0.5161,0.6011]\n","epoch_list=[1,2,3]\n","\n","plt.figure()\n","plt.plot(epoch_list,training_loss_min, label=\"Training Loss Min Run\")\n","plt.plot(epoch_list,val_loss_min, label=\"Validation Loss Min Run\")\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.xticks(epoch_list)\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3fH_e7Wt_kNP","outputId":"f678f780-8fbb-4bf8-83f2-da8c83ddaa3c"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["\n","plt.figure()\n","plt.plot(epoch_list,training_loss_max, label=\"Training Loss Max Run\")\n","plt.plot(epoch_list,val_loss_max, label=\"Validation Loss Max Run\")\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.xticks(epoch_list)\n","plt.legend()\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"Distilbert Experiment HateTwit Baseline Non Hyper.ipynb","provenance":[{"file_id":"1STrl8D_SltHJ1NdJG0TjnfyyiceDn_Gi","timestamp":1645610447274},{"file_id":"1A8y-Rv0ooUg6fzJ2bnYBJxBSaOEr3z9z","timestamp":1643754143701},{"file_id":"1-rZqxPTOtm21puGsZKK_FiKXeyCg7py7","timestamp":1643745856080},{"file_id":"15wylWRQJ1vxlP58OhBHUnY5fdagThMvJ","timestamp":1643406846637},{"file_id":"1B35hajBJY3fRQV7LSjqoqQ3xjdcyCzE3","timestamp":1642365829686},{"file_id":"1b0lCW2Cj6AULiE-Axh2OeZwURHR6pfcD","timestamp":1642333651961},{"file_id":"1RAjFaq-k9CLJQP5eO668UXLc0q-wjuve","timestamp":1642280213414},{"file_id":"1LzZr7GRN1SwVrNyjVX5t5PpCvio8w_kE","timestamp":1642109182548},{"file_id":"1t-qzEyxZtGn_Cnlfg2WtN-0dlgUmxfzx","timestamp":1641764210714},{"file_id":"14bEU8hCGPF8cVUA_BonJQA6Brv89DKUm","timestamp":1641252935713},{"file_id":"18Il3CpGf89tF1Z10iYX8OdfeHxxAX1Ui","timestamp":1639243141142},{"file_id":"1SHCgoRQVGtl9OiWEJGK3JgKkuxxSPy_5","timestamp":1639231968300},{"file_id":"1D-3yvF0nGnaWEZGxQj21R6fsGnyv5a5g","timestamp":1637526185003},{"file_id":"1glXr2JglKPUpN_3AGyk3GjfCtZSDNfsZ","timestamp":1637408594851},{"file_id":"1rc5hX8PBIv7GKvlxLQ35Vwf2jxLsv9f4","timestamp":1634501666668}],"mount_file_id":"1Tosci2v933SSabdS3wJ46J0Zf-0lL-bj","authorship_tag":"ABX9TyPtm5+McAXt4xpOWykdXfbq"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0b6cbceda29040128178f3adced0789d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"137e61e583e04e2ab8300f5cd319e744":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13a42522f379454d82900e6465b096fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77fedfa616d04d829e16792b4b4f204a","placeholder":"​","style":"IPY_MODEL_6944c83c54614e8caa38debe94633a20","value":" 256M/256M [00:04&lt;00:00, 62.5MB/s]"}},"1ff585973a3044ea900bce575dcfa713":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24ce3f986e904a6d94a368b1e599e1a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c203097c9a14431b0f063cc28663a3d","placeholder":"​","style":"IPY_MODEL_e93d8b577da94ac4a57524b51bb7c038","value":"Downloading: 100%"}},"275f3106f7054aa1a1182c5621b105f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fd0f0859fdf84cd387f74e3943316635","IPY_MODEL_cf1cb1d96fec452aa26b3480a93b231d","IPY_MODEL_b35abc2d16fb428083b84bcf0ae46722"],"layout":"IPY_MODEL_8ce92f93ab904b26b661e0ed845dbad6"}},"32d3eb083a744e32bbdc3283e239ef55":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35bbe29a68df448bad6a1bfac94eab13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"380f76be13154e71adbd14d60aeca9a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3bb7711f7ec247829cf9bccb32e874ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bf7fd32ec724eaf823dc2eaa13b490d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2e584763e8d4f63a1ddb0f8f47b7aae","max":267967963,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3d7107e4766f4280b2152c33f06dee84","value":267967963}},"3d7107e4766f4280b2152c33f06dee84":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"57ac3abf4a4e46d8948d2c5a7bc7c5ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57c64bd6db0d4a338cd3c114bdd9613d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"610db12da17b496a9e96338d0da52d09":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb568ee03aba4d8b81648294484da130","IPY_MODEL_c8e8e6a6bd234b07bc573d6519991fed","IPY_MODEL_d389227d26a14921838c48b69bbf440c"],"layout":"IPY_MODEL_e8b1fb6d741c4633b467382094a38361"}},"655f5613563642ebb67d3a1b38b9faea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6594f432bb234f948003a2eceace47fb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6944c83c54614e8caa38debe94633a20":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e781f09e5bf462aaaa80f31a1dbdf60":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_905571a80cc145d09e84535ea652851c","IPY_MODEL_e298a34baabf451d8d90208c6eb03cee","IPY_MODEL_cb62781ebd094515b07c5a5d952f0aed"],"layout":"IPY_MODEL_d32c44771deb4207991dcb40432438dc"}},"6f1dca92367e4bb1a3c22a6889e3ca32":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77308e371b6641dc9274b2a147adcd80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ff585973a3044ea900bce575dcfa713","placeholder":"​","style":"IPY_MODEL_d1166243516a4b418bcd7aae8d07ceab","value":" 28.0/28.0 [00:00&lt;00:00, 966B/s]"}},"77fedfa616d04d829e16792b4b4f204a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a1f63ca96a84f73ad16ada30967c8a3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b084d3aeadd40d8bfb871ac5c3802c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c203097c9a14431b0f063cc28663a3d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d7b4b4f694147c7965b450aeb13a2f8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84515947b60f43f6aa43060608e484a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85b4bf44e1e44f038d21c1b1dab24e68":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8885ca08b7c044519a272376c9fb5967":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ce92f93ab904b26b661e0ed845dbad6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e18aade616e4758aad742a1b8e766d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"905571a80cc145d09e84535ea652851c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_655f5613563642ebb67d3a1b38b9faea","placeholder":"​","style":"IPY_MODEL_380f76be13154e71adbd14d60aeca9a4","value":"Downloading: 100%"}},"a98ca39d33b24294a3c5b168b78e097c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b35abc2d16fb428083b84bcf0ae46722":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e18aade616e4758aad742a1b8e766d6","placeholder":"​","style":"IPY_MODEL_6f1dca92367e4bb1a3c22a6889e3ca32","value":" 483/483 [00:00&lt;00:00, 18.5kB/s]"}},"b54f1f0a17e9438b9242c70dc39c5e4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bb7711f7ec247829cf9bccb32e874ab","placeholder":"​","style":"IPY_MODEL_e9dad320b0b44787b64c8f01ccf6f35a","value":"Downloading: 100%"}},"c8e8e6a6bd234b07bc573d6519991fed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_137e61e583e04e2ab8300f5cd319e744","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_84515947b60f43f6aa43060608e484a5","value":466062}},"cac3a524c47f44f482db573a6d485e84":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b54f1f0a17e9438b9242c70dc39c5e4b","IPY_MODEL_3bf7fd32ec724eaf823dc2eaa13b490d","IPY_MODEL_13a42522f379454d82900e6465b096fb"],"layout":"IPY_MODEL_7a1f63ca96a84f73ad16ada30967c8a3"}},"cb568ee03aba4d8b81648294484da130":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b6cbceda29040128178f3adced0789d","placeholder":"​","style":"IPY_MODEL_8885ca08b7c044519a272376c9fb5967","value":"Downloading: 100%"}},"cb62781ebd094515b07c5a5d952f0aed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57ac3abf4a4e46d8948d2c5a7bc7c5ee","placeholder":"​","style":"IPY_MODEL_7b084d3aeadd40d8bfb871ac5c3802c6","value":" 226k/226k [00:00&lt;00:00, 646kB/s]"}},"cf1cb1d96fec452aa26b3480a93b231d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a98ca39d33b24294a3c5b168b78e097c","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_57c64bd6db0d4a338cd3c114bdd9613d","value":483}},"d1166243516a4b418bcd7aae8d07ceab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1e91c7d737c483c81957832751c15bc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d32c44771deb4207991dcb40432438dc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d389227d26a14921838c48b69bbf440c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d7b4b4f694147c7965b450aeb13a2f8","placeholder":"​","style":"IPY_MODEL_32d3eb083a744e32bbdc3283e239ef55","value":" 455k/455k [00:00&lt;00:00, 621kB/s]"}},"d62ccb37095b4db99fa45f5b16a0bdfb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df21f15e093845b4af9adcb667665f12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_85b4bf44e1e44f038d21c1b1dab24e68","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_edf6e95e128344ab9beb4b1d0397f492","value":28}},"e298a34baabf451d8d90208c6eb03cee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_35bbe29a68df448bad6a1bfac94eab13","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d62ccb37095b4db99fa45f5b16a0bdfb","value":231508}},"e8b1fb6d741c4633b467382094a38361":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e93d8b577da94ac4a57524b51bb7c038":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9dad320b0b44787b64c8f01ccf6f35a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"edf6e95e128344ab9beb4b1d0397f492":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f1bdff56afee4109b501214df212c559":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_24ce3f986e904a6d94a368b1e599e1a4","IPY_MODEL_df21f15e093845b4af9adcb667665f12","IPY_MODEL_77308e371b6641dc9274b2a147adcd80"],"layout":"IPY_MODEL_6594f432bb234f948003a2eceace47fb"}},"f2e584763e8d4f63a1ddb0f8f47b7aae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f539c84378c0423ca4decd668096a604":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd0f0859fdf84cd387f74e3943316635":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1e91c7d737c483c81957832751c15bc","placeholder":"​","style":"IPY_MODEL_f539c84378c0423ca4decd668096a604","value":"Downloading: 100%"}}}}},"nbformat":4,"nbformat_minor":0}