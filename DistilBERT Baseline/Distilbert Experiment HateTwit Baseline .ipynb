{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":14833,"status":"ok","timestamp":1644697848488,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"},"user_tz":0},"id":"F-o6bXOJ18j4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"384cd1f6-ba96-4692-bbcb-7915d4910b37"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 3.5 MB 14.6 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 81.8 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 81.5 MB/s \n","\u001b[K     |████████████████████████████████| 67 kB 6.2 MB/s \n","\u001b[K     |████████████████████████████████| 6.8 MB 89.8 MB/s \n","\u001b[K     |████████████████████████████████| 311 kB 13.5 MB/s \n","\u001b[K     |████████████████████████████████| 133 kB 81.4 MB/s \n","\u001b[K     |████████████████████████████████| 243 kB 89.3 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 81.5 MB/s \n","\u001b[K     |████████████████████████████████| 144 kB 80.3 MB/s \n","\u001b[K     |████████████████████████████████| 94 kB 3.8 MB/s \n","\u001b[K     |████████████████████████████████| 271 kB 88.4 MB/s \n","\u001b[?25h"]}],"source":["!pip install -qq transformers\n","!pip install -qq datasets\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Rz6wNlu92ge_","executionInfo":{"status":"ok","timestamp":1644697857327,"user_tz":0,"elapsed":8846,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["import transformers\n","import datasets\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification,AdamW, get_linear_schedule_with_warmup,Trainer, TrainingArguments\n","from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n","import torch\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from matplotlib import rc\n","import random\n","from datetime import datetime\n","from datasets import load_from_disk\n","from datasets import Dataset\n","from sklearn.metrics import accuracy_score,classification_report, confusion_matrix\n","from sklearn.metrics import precision_recall_fscore_support"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"T7IFr4-3TKaA","executionInfo":{"status":"ok","timestamp":1644688884766,"user_tz":0,"elapsed":8,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["# the model we gonna train, base uncased BERT\n","# check text classification models here: https://huggingface.co/models?filter=text-classification\n","MODEL_NAME = \"distilbert-base-uncased\"\n","# max sequence length for each document/sentence sample\n","BATCH_SIZE = 16\n","EPOCHS = 3\n","LEARNING_RATE= 6.58e-05\n","WEIGHT_DECAY = 0.289\n","WARMUP_STEPS = 464\n","RANDOM_SEED=22\n","\n","\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"]},{"cell_type":"code","source":["def set_seed(seed):\n","    \"\"\"Set all seeds to make results reproducible (deterministic mode).\n","       When seed is None, disables deterministic mode.\n","    :param seed: an integer to your choosing\n","    \"\"\"\n","    if seed is not None:\n","        torch.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","        np.random.seed(seed)\n","        random.seed(seed)\n","\n","def compute_metrics(pred):\n","  labels = pred.label_ids\n","  preds = pred.predictions.argmax(-1)\n","  # calculate accuracy using sklearn's function\n","  acc = accuracy_score(labels, preds)\n","  precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n","  acc = accuracy_score(labels, preds)\n","  confusion_matrix = classification_report(labels, preds, digits=4,output_dict=True)\n","  return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall,\n","        'hate_f1': confusion_matrix[\"0\"][\"f1-score\"],\n","        'hate_recall': confusion_matrix[\"0\"][\"recall\"],\n","        'hate_precision': confusion_matrix[\"0\"][\"precision\"],\n","        'offensive_f1': confusion_matrix[\"1\"][\"f1-score\"],\n","        'offensive_recall': confusion_matrix[\"1\"][\"recall\"],\n","        'offensive_precision': confusion_matrix[\"1\"][\"precision\"],\n","        'normal_f1': confusion_matrix[\"2\"][\"f1-score\"],\n","        'normal_recall': confusion_matrix[\"2\"][\"recall\"],\n","        'normal_precision': confusion_matrix[\"2\"][\"precision\"],    \n","  }\n","\n","def model_init():\n","  temp_model =  AutoModelForSequenceClassification.from_pretrained(MODEL_NAME,num_labels=3).to(device)\n","  return temp_model\n","\n","def timestamp():\n","    dateTimeObj = datetime.now()\n","    timestampStr = dateTimeObj.strftime(\"%d-%b-%Y (%H:%M:%S.%f)\")\n","    print(timestampStr)"],"metadata":{"id":"YoKXcvyo_X47","executionInfo":{"status":"ok","timestamp":1644688884767,"user_tz":0,"elapsed":7,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["set_seed(RANDOM_SEED)"],"metadata":{"id":"lqKiS7jbkC4x","executionInfo":{"status":"ok","timestamp":1644688884767,"user_tz":0,"elapsed":7,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3465,"status":"ok","timestamp":1644688888226,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"},"user_tz":0},"id":"AMEUIo294iAd"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"aum4jWZzXdgX","executionInfo":{"status":"ok","timestamp":1644692382927,"user_tz":0,"elapsed":3494706,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"13805888-8261-49e1-aa1a-45f353df87bb"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:38, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.566800</td>\n","      <td>0.535197</td>\n","      <td>0.783215</td>\n","      <td>0.741828</td>\n","      <td>0.734362</td>\n","      <td>0.751258</td>\n","      <td>0.723384</td>\n","      <td>0.765594</td>\n","      <td>0.685586</td>\n","      <td>0.859316</td>\n","      <td>0.836727</td>\n","      <td>0.883157</td>\n","      <td>0.642784</td>\n","      <td>0.651452</td>\n","      <td>0.634343</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.427600</td>\n","      <td>0.488667</td>\n","      <td>0.810904</td>\n","      <td>0.765317</td>\n","      <td>0.774795</td>\n","      <td>0.760947</td>\n","      <td>0.780962</td>\n","      <td>0.808853</td>\n","      <td>0.754930</td>\n","      <td>0.877225</td>\n","      <td>0.894113</td>\n","      <td>0.860963</td>\n","      <td>0.637764</td>\n","      <td>0.579876</td>\n","      <td>0.708492</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.270900</td>\n","      <td>0.554953</td>\n","      <td>0.812406</td>\n","      <td>0.771700</td>\n","      <td>0.770010</td>\n","      <td>0.775198</td>\n","      <td>0.787152</td>\n","      <td>0.825956</td>\n","      <td>0.751832</td>\n","      <td>0.878512</td>\n","      <td>0.874121</td>\n","      <td>0.882947</td>\n","      <td>0.649435</td>\n","      <td>0.625519</td>\n","      <td>0.675252</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/1/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/1/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/1/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/1/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/1/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/1/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/1/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/1/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/1/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/1/checkpoint-4660 (score: 0.48866745829582214).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_1\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_1/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_1/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:36, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.571700</td>\n","      <td>0.542782</td>\n","      <td>0.777849</td>\n","      <td>0.715615</td>\n","      <td>0.746474</td>\n","      <td>0.700767</td>\n","      <td>0.706653</td>\n","      <td>0.705231</td>\n","      <td>0.708081</td>\n","      <td>0.858193</td>\n","      <td>0.907442</td>\n","      <td>0.814015</td>\n","      <td>0.581998</td>\n","      <td>0.489627</td>\n","      <td>0.717325</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.437200</td>\n","      <td>0.514808</td>\n","      <td>0.800386</td>\n","      <td>0.761000</td>\n","      <td>0.755515</td>\n","      <td>0.769528</td>\n","      <td>0.776790</td>\n","      <td>0.835010</td>\n","      <td>0.726159</td>\n","      <td>0.866893</td>\n","      <td>0.851166</td>\n","      <td>0.883212</td>\n","      <td>0.639318</td>\n","      <td>0.622407</td>\n","      <td>0.657174</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.258800</td>\n","      <td>0.579757</td>\n","      <td>0.809187</td>\n","      <td>0.769425</td>\n","      <td>0.766781</td>\n","      <td>0.772604</td>\n","      <td>0.788471</td>\n","      <td>0.811871</td>\n","      <td>0.766382</td>\n","      <td>0.875559</td>\n","      <td>0.870048</td>\n","      <td>0.881140</td>\n","      <td>0.644246</td>\n","      <td>0.635892</td>\n","      <td>0.652822</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/2/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/2/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/2/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/2/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/2/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/2/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/2/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/2/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/2/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/2/checkpoint-4660 (score: 0.5148082375526428).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_2\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_2/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_2/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:36, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.571700</td>\n","      <td>0.570152</td>\n","      <td>0.771196</td>\n","      <td>0.714580</td>\n","      <td>0.727324</td>\n","      <td>0.709355</td>\n","      <td>0.700772</td>\n","      <td>0.730382</td>\n","      <td>0.673469</td>\n","      <td>0.853839</td>\n","      <td>0.874861</td>\n","      <td>0.833804</td>\n","      <td>0.589129</td>\n","      <td>0.522822</td>\n","      <td>0.674699</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.441300</td>\n","      <td>0.525531</td>\n","      <td>0.793518</td>\n","      <td>0.739883</td>\n","      <td>0.756935</td>\n","      <td>0.738575</td>\n","      <td>0.756707</td>\n","      <td>0.822938</td>\n","      <td>0.700342</td>\n","      <td>0.866836</td>\n","      <td>0.884487</td>\n","      <td>0.849875</td>\n","      <td>0.596107</td>\n","      <td>0.508299</td>\n","      <td>0.720588</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.268300</td>\n","      <td>0.596814</td>\n","      <td>0.805538</td>\n","      <td>0.765152</td>\n","      <td>0.765978</td>\n","      <td>0.764690</td>\n","      <td>0.782738</td>\n","      <td>0.793763</td>\n","      <td>0.772016</td>\n","      <td>0.870849</td>\n","      <td>0.873750</td>\n","      <td>0.867966</td>\n","      <td>0.641870</td>\n","      <td>0.626556</td>\n","      <td>0.657952</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/3/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/3/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/3/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/3/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/3/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/3/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/3/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/3/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/3/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/3/checkpoint-4660 (score: 0.5255313515663147).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_3\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_3/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_3/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:36, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.574000</td>\n","      <td>0.541478</td>\n","      <td>0.777420</td>\n","      <td>0.722352</td>\n","      <td>0.742363</td>\n","      <td>0.714959</td>\n","      <td>0.715314</td>\n","      <td>0.749497</td>\n","      <td>0.684114</td>\n","      <td>0.853916</td>\n","      <td>0.881896</td>\n","      <td>0.827658</td>\n","      <td>0.597826</td>\n","      <td>0.513485</td>\n","      <td>0.715318</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.429700</td>\n","      <td>0.533275</td>\n","      <td>0.786435</td>\n","      <td>0.752430</td>\n","      <td>0.740029</td>\n","      <td>0.775320</td>\n","      <td>0.763828</td>\n","      <td>0.875252</td>\n","      <td>0.677570</td>\n","      <td>0.851816</td>\n","      <td>0.803406</td>\n","      <td>0.906433</td>\n","      <td>0.641645</td>\n","      <td>0.647303</td>\n","      <td>0.636086</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.261700</td>\n","      <td>0.602442</td>\n","      <td>0.804679</td>\n","      <td>0.761973</td>\n","      <td>0.762074</td>\n","      <td>0.764689</td>\n","      <td>0.789122</td>\n","      <td>0.831992</td>\n","      <td>0.750454</td>\n","      <td>0.871111</td>\n","      <td>0.870789</td>\n","      <td>0.871434</td>\n","      <td>0.625686</td>\n","      <td>0.591286</td>\n","      <td>0.664336</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/4/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/4/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/4/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/4/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/4/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/4/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/4/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/4/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/4/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/4/checkpoint-4660 (score: 0.533275306224823).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_4\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_4/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_4/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:39, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.560600</td>\n","      <td>0.543548</td>\n","      <td>0.783645</td>\n","      <td>0.728409</td>\n","      <td>0.750430</td>\n","      <td>0.717031</td>\n","      <td>0.712234</td>\n","      <td>0.723340</td>\n","      <td>0.701463</td>\n","      <td>0.860089</td>\n","      <td>0.895594</td>\n","      <td>0.827291</td>\n","      <td>0.612903</td>\n","      <td>0.532158</td>\n","      <td>0.722535</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.420600</td>\n","      <td>0.492091</td>\n","      <td>0.811977</td>\n","      <td>0.770262</td>\n","      <td>0.771494</td>\n","      <td>0.771658</td>\n","      <td>0.783317</td>\n","      <td>0.821932</td>\n","      <td>0.748168</td>\n","      <td>0.877634</td>\n","      <td>0.878934</td>\n","      <td>0.876338</td>\n","      <td>0.649835</td>\n","      <td>0.614108</td>\n","      <td>0.689977</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.249700</td>\n","      <td>0.600655</td>\n","      <td>0.808328</td>\n","      <td>0.766070</td>\n","      <td>0.766433</td>\n","      <td>0.766412</td>\n","      <td>0.785258</td>\n","      <td>0.803823</td>\n","      <td>0.767531</td>\n","      <td>0.876247</td>\n","      <td>0.878193</td>\n","      <td>0.874309</td>\n","      <td>0.636704</td>\n","      <td>0.617220</td>\n","      <td>0.657459</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/5/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/5/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/5/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/5/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/5/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/5/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/5/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/5/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/5/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/5/checkpoint-4660 (score: 0.49209123849868774).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_5\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_5/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_5/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:42, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.576400</td>\n","      <td>0.547402</td>\n","      <td>0.777420</td>\n","      <td>0.733990</td>\n","      <td>0.734101</td>\n","      <td>0.733878</td>\n","      <td>0.726358</td>\n","      <td>0.726358</td>\n","      <td>0.726358</td>\n","      <td>0.850481</td>\n","      <td>0.850796</td>\n","      <td>0.850166</td>\n","      <td>0.625130</td>\n","      <td>0.624481</td>\n","      <td>0.625780</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.436800</td>\n","      <td>0.493523</td>\n","      <td>0.805752</td>\n","      <td>0.768154</td>\n","      <td>0.767369</td>\n","      <td>0.769240</td>\n","      <td>0.780849</td>\n","      <td>0.795775</td>\n","      <td>0.766473</td>\n","      <td>0.867841</td>\n","      <td>0.866716</td>\n","      <td>0.868968</td>\n","      <td>0.655772</td>\n","      <td>0.645228</td>\n","      <td>0.666667</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.261000</td>\n","      <td>0.598802</td>\n","      <td>0.806611</td>\n","      <td>0.770173</td>\n","      <td>0.764772</td>\n","      <td>0.776345</td>\n","      <td>0.794560</td>\n","      <td>0.822938</td>\n","      <td>0.768075</td>\n","      <td>0.869598</td>\n","      <td>0.856720</td>\n","      <td>0.882869</td>\n","      <td>0.646360</td>\n","      <td>0.649378</td>\n","      <td>0.643371</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/6/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/6/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/6/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/6/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/6/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/6/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/6/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/6/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/6/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/6/checkpoint-4660 (score: 0.49352332949638367).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_6\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_6/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_6/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:38, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.568900</td>\n","      <td>0.548766</td>\n","      <td>0.776991</td>\n","      <td>0.735845</td>\n","      <td>0.729500</td>\n","      <td>0.744642</td>\n","      <td>0.728383</td>\n","      <td>0.779678</td>\n","      <td>0.683422</td>\n","      <td>0.850161</td>\n","      <td>0.830803</td>\n","      <td>0.870442</td>\n","      <td>0.628990</td>\n","      <td>0.623444</td>\n","      <td>0.634636</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.428300</td>\n","      <td>0.516198</td>\n","      <td>0.796737</td>\n","      <td>0.750777</td>\n","      <td>0.760176</td>\n","      <td>0.744888</td>\n","      <td>0.766337</td>\n","      <td>0.778672</td>\n","      <td>0.754386</td>\n","      <td>0.864023</td>\n","      <td>0.883377</td>\n","      <td>0.845500</td>\n","      <td>0.621972</td>\n","      <td>0.572614</td>\n","      <td>0.680641</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.254900</td>\n","      <td>0.601103</td>\n","      <td>0.803606</td>\n","      <td>0.763740</td>\n","      <td>0.762155</td>\n","      <td>0.765698</td>\n","      <td>0.785644</td>\n","      <td>0.803823</td>\n","      <td>0.768269</td>\n","      <td>0.869452</td>\n","      <td>0.866716</td>\n","      <td>0.872206</td>\n","      <td>0.636124</td>\n","      <td>0.626556</td>\n","      <td>0.645989</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/7/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/7/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/7/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/7/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/7/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/7/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/7/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/7/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/7/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/7/checkpoint-4660 (score: 0.5161980986595154).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_7\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_7/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_7/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:34, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.569600</td>\n","      <td>0.549209</td>\n","      <td>0.780210</td>\n","      <td>0.727418</td>\n","      <td>0.738965</td>\n","      <td>0.720883</td>\n","      <td>0.725838</td>\n","      <td>0.740443</td>\n","      <td>0.711799</td>\n","      <td>0.856988</td>\n","      <td>0.879674</td>\n","      <td>0.835443</td>\n","      <td>0.599427</td>\n","      <td>0.542531</td>\n","      <td>0.669654</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.430400</td>\n","      <td>0.506972</td>\n","      <td>0.800601</td>\n","      <td>0.754456</td>\n","      <td>0.765238</td>\n","      <td>0.745334</td>\n","      <td>0.763845</td>\n","      <td>0.735412</td>\n","      <td>0.794565</td>\n","      <td>0.871166</td>\n","      <td>0.893743</td>\n","      <td>0.849701</td>\n","      <td>0.628357</td>\n","      <td>0.606846</td>\n","      <td>0.651448</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.259700</td>\n","      <td>0.589525</td>\n","      <td>0.813479</td>\n","      <td>0.773480</td>\n","      <td>0.773976</td>\n","      <td>0.773474</td>\n","      <td>0.801383</td>\n","      <td>0.815895</td>\n","      <td>0.787379</td>\n","      <td>0.877608</td>\n","      <td>0.880044</td>\n","      <td>0.875184</td>\n","      <td>0.641449</td>\n","      <td>0.624481</td>\n","      <td>0.659365</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/8/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/8/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/8/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/8/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/8/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/8/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/8/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/8/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/8/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/8/checkpoint-4660 (score: 0.5069718956947327).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_8\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_8/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_8/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:34, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.574800</td>\n","      <td>0.546071</td>\n","      <td>0.778708</td>\n","      <td>0.727018</td>\n","      <td>0.740043</td>\n","      <td>0.717313</td>\n","      <td>0.712315</td>\n","      <td>0.701207</td>\n","      <td>0.723780</td>\n","      <td>0.854735</td>\n","      <td>0.882266</td>\n","      <td>0.828870</td>\n","      <td>0.614006</td>\n","      <td>0.568465</td>\n","      <td>0.667479</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.437800</td>\n","      <td>0.510202</td>\n","      <td>0.798884</td>\n","      <td>0.751382</td>\n","      <td>0.762841</td>\n","      <td>0.745201</td>\n","      <td>0.762138</td>\n","      <td>0.781690</td>\n","      <td>0.743541</td>\n","      <td>0.867365</td>\n","      <td>0.888560</td>\n","      <td>0.847158</td>\n","      <td>0.624642</td>\n","      <td>0.565353</td>\n","      <td>0.697823</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.263400</td>\n","      <td>0.613632</td>\n","      <td>0.802103</td>\n","      <td>0.761353</td>\n","      <td>0.763571</td>\n","      <td>0.759314</td>\n","      <td>0.778672</td>\n","      <td>0.778672</td>\n","      <td>0.778672</td>\n","      <td>0.867966</td>\n","      <td>0.873750</td>\n","      <td>0.862258</td>\n","      <td>0.637421</td>\n","      <td>0.625519</td>\n","      <td>0.649784</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/9/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/9/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/9/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/9/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/9/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/9/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/9/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/9/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/9/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/9/checkpoint-4660 (score: 0.5102016925811768).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_9\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_9/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_9/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:36, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.576000</td>\n","      <td>0.539398</td>\n","      <td>0.778493</td>\n","      <td>0.711052</td>\n","      <td>0.750693</td>\n","      <td>0.694605</td>\n","      <td>0.718338</td>\n","      <td>0.713280</td>\n","      <td>0.723469</td>\n","      <td>0.859616</td>\n","      <td>0.919289</td>\n","      <td>0.807217</td>\n","      <td>0.555201</td>\n","      <td>0.451245</td>\n","      <td>0.721393</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.432300</td>\n","      <td>0.507200</td>\n","      <td>0.811977</td>\n","      <td>0.768351</td>\n","      <td>0.779717</td>\n","      <td>0.759164</td>\n","      <td>0.775615</td>\n","      <td>0.761569</td>\n","      <td>0.790188</td>\n","      <td>0.877073</td>\n","      <td>0.900777</td>\n","      <td>0.854584</td>\n","      <td>0.652365</td>\n","      <td>0.615145</td>\n","      <td>0.694379</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.247000</td>\n","      <td>0.575591</td>\n","      <td>0.816270</td>\n","      <td>0.775313</td>\n","      <td>0.776013</td>\n","      <td>0.775023</td>\n","      <td>0.787129</td>\n","      <td>0.799799</td>\n","      <td>0.774854</td>\n","      <td>0.882776</td>\n","      <td>0.885228</td>\n","      <td>0.880339</td>\n","      <td>0.656034</td>\n","      <td>0.640041</td>\n","      <td>0.672846</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/10/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/10/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/10/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/10/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/10/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/10/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/10/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/10/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/10/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/10/checkpoint-4660 (score: 0.5072002410888672).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_10\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_10/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_10/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}],"source":["result_list = []\n","for i in range(1,11):\n","\n","  training_args = TrainingArguments(\n","    output_dir='/content/drive/MyDrive/Dissertation/disbert_hate_baseline/results/'+str(i),          # output directory\n","    num_train_epochs=EPOCHS,              # total number of training epochs\n","    save_strategy =\"epoch\" ,\n","    per_device_train_batch_size=BATCH_SIZE,  # batch size per device during training\n","    per_device_eval_batch_size=BATCH_SIZE,   # batch size for evaluation\n","    weight_decay= WEIGHT_DECAY,               # strength of weight decay\n","    learning_rate= LEARNING_RATE, \n","    warmup_steps = WARMUP_STEPS,\n","    logging_dir='./disbert_hate_baseline//logs',     # directory for storing logs\n","    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n","    evaluation_strategy=\"epoch\",\n","  )\n","\n","  hatetwit_dataset_dfs = load_from_disk('/content/drive/MyDrive/Dissertation/datasets/hatetwit_'+str(i))\n","  train_dataset = hatetwit_dataset_dfs [\"train\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","  eval_dataset = hatetwit_dataset_dfs [\"validation\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","  test_dataset = hatetwit_dataset_dfs [\"test\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","  model = model_init()\n","  trainer = Trainer(\n","      model=model,                         # the instantiated Transformers model to be trained\n","      args=training_args,                  # training arguments, defined above\n","      train_dataset= train_dataset,         # training dataset\n","      eval_dataset=eval_dataset,          # evaluation dataset\n","      compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n","  )\n","  trainer.train()\n","  trainer.save_model('/content/drive/MyDrive/Dissertation/disbert_hate_baseline/models/model_'+str(i))\n","  results = trainer.evaluate(test_dataset)\n","  results[\"model_run\"] = i\n","  result_list.append(results)\n","\n","\n"]},{"cell_type":"code","source":["results_df = pd.DataFrame(result_list)\n","results_df.to_csv('/content/drive/MyDrive/Dissertation/results/distilbert_baselines.csv')"],"metadata":{"id":"xr7fZYm4Yp8_","executionInfo":{"status":"ok","timestamp":1644692383702,"user_tz":0,"elapsed":797,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#Sort rows to determine the mix, max and median \n","results_df = results_df.sort_values(by=['eval_f1'])\n","#Print min values\n","results_df.head(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"id":"V5Y8SojS_LB3","executionInfo":{"status":"ok","timestamp":1644692383703,"user_tz":0,"elapsed":36,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"0894399d-bd80-45b5-ec90-32506017600c"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-3aff7217-2eef-40dd-a202-531bc5d445a7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eval_loss</th>\n","      <th>eval_accuracy</th>\n","      <th>eval_f1</th>\n","      <th>eval_precision</th>\n","      <th>eval_recall</th>\n","      <th>eval_hate_f1</th>\n","      <th>eval_hate_recall</th>\n","      <th>eval_hate_precision</th>\n","      <th>eval_offensive_f1</th>\n","      <th>eval_offensive_recall</th>\n","      <th>eval_offensive_precision</th>\n","      <th>eval_normal_f1</th>\n","      <th>eval_normal_recall</th>\n","      <th>eval_normal_precision</th>\n","      <th>eval_runtime</th>\n","      <th>eval_samples_per_second</th>\n","      <th>eval_steps_per_second</th>\n","      <th>epoch</th>\n","      <th>model_run</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>0.524914</td>\n","      <td>0.798411</td>\n","      <td>0.749282</td>\n","      <td>0.761003</td>\n","      <td>0.749298</td>\n","      <td>0.753932</td>\n","      <td>0.820745</td>\n","      <td>0.697177</td>\n","      <td>0.87017</td>\n","      <td>0.88</td>\n","      <td>0.860558</td>\n","      <td>0.623745</td>\n","      <td>0.54715</td>\n","      <td>0.725275</td>\n","      <td>3.9153</td>\n","      <td>1189.691</td>\n","      <td>74.579</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3aff7217-2eef-40dd-a202-531bc5d445a7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3aff7217-2eef-40dd-a202-531bc5d445a7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3aff7217-2eef-40dd-a202-531bc5d445a7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   eval_loss  eval_accuracy   eval_f1  ...  eval_steps_per_second  epoch  model_run\n","2   0.524914       0.798411  0.749282  ...                 74.579    3.0          3\n","\n","[1 rows x 19 columns]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["#Print max values \n","results_df.tail(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"id":"rh5O2OL6_Qkd","executionInfo":{"status":"ok","timestamp":1644692383704,"user_tz":0,"elapsed":33,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"415bb5f5-4dde-4737-8d45-da47a778ef44"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-3a5edb3c-943b-42cd-a25e-5fcd4dfadaa3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eval_loss</th>\n","      <th>eval_accuracy</th>\n","      <th>eval_f1</th>\n","      <th>eval_precision</th>\n","      <th>eval_recall</th>\n","      <th>eval_hate_f1</th>\n","      <th>eval_hate_recall</th>\n","      <th>eval_hate_precision</th>\n","      <th>eval_offensive_f1</th>\n","      <th>eval_offensive_recall</th>\n","      <th>eval_offensive_precision</th>\n","      <th>eval_normal_f1</th>\n","      <th>eval_normal_recall</th>\n","      <th>eval_normal_precision</th>\n","      <th>eval_runtime</th>\n","      <th>eval_samples_per_second</th>\n","      <th>eval_steps_per_second</th>\n","      <th>epoch</th>\n","      <th>model_run</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6</th>\n","      <td>0.511171</td>\n","      <td>0.815157</td>\n","      <td>0.769912</td>\n","      <td>0.783891</td>\n","      <td>0.760764</td>\n","      <td>0.787575</td>\n","      <td>0.791541</td>\n","      <td>0.783649</td>\n","      <td>0.879425</td>\n","      <td>0.906296</td>\n","      <td>0.854101</td>\n","      <td>0.642735</td>\n","      <td>0.584456</td>\n","      <td>0.713924</td>\n","      <td>3.8754</td>\n","      <td>1201.952</td>\n","      <td>75.348</td>\n","      <td>3.0</td>\n","      <td>7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a5edb3c-943b-42cd-a25e-5fcd4dfadaa3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3a5edb3c-943b-42cd-a25e-5fcd4dfadaa3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3a5edb3c-943b-42cd-a25e-5fcd4dfadaa3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   eval_loss  eval_accuracy   eval_f1  ...  eval_steps_per_second  epoch  model_run\n","6   0.511171       0.815157  0.769912  ...                 75.348    3.0          7\n","\n","[1 rows x 19 columns]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["#Print median f1\n","results_df[\"eval_f1\"].median()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sdV3f6bE_blb","executionInfo":{"status":"ok","timestamp":1644692383705,"user_tz":0,"elapsed":33,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"b3fdc4e6-3f7e-4e95-9d62-ab63de31a15b"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7577267614857477"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["#Print average values\n","results_df.mean()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1XwImR50_dcZ","executionInfo":{"status":"ok","timestamp":1644692383706,"user_tz":0,"elapsed":29,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"c2d68dae-9691-4320-f129-87cf6e677852"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["eval_loss                      0.514836\n","eval_accuracy                  0.803049\n","eval_f1                        0.758755\n","eval_precision                 0.764466\n","eval_recall                    0.757894\n","eval_hate_f1                   0.771782\n","eval_hate_recall               0.802115\n","eval_hate_precision            0.746817\n","eval_offensive_f1              0.871258\n","eval_offensive_recall          0.878407\n","eval_offensive_precision       0.865375\n","eval_normal_f1                 0.633224\n","eval_normal_recall             0.593161\n","eval_normal_precision          0.681205\n","eval_runtime                   3.924650\n","eval_samples_per_second     1187.001100\n","eval_steps_per_second         74.410500\n","epoch                          3.000000\n","model_run                      5.500000\n","dtype: float64"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["results_df.std()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cu8sEyeh_fWL","executionInfo":{"status":"ok","timestamp":1644692383706,"user_tz":0,"elapsed":27,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"527065ac-2334-4a5b-c3c0-4eb2ceb62281"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["eval_loss                    0.013752\n","eval_accuracy                0.007213\n","eval_f1                      0.006414\n","eval_precision               0.011832\n","eval_recall                  0.009454\n","eval_hate_f1                 0.011321\n","eval_hate_recall             0.034178\n","eval_hate_precision          0.043059\n","eval_offensive_f1            0.006159\n","eval_offensive_recall        0.028199\n","eval_offensive_precision     0.019999\n","eval_normal_f1               0.011193\n","eval_normal_recall           0.029526\n","eval_normal_precision        0.025304\n","eval_runtime                 0.044901\n","eval_samples_per_second     13.500682\n","eval_steps_per_second        0.846298\n","epoch                        0.000000\n","model_run                    3.027650\n","dtype: float64"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["training_loss_min = [0.5717,0.441300,0.2683]\n","training_loss_max = [0.5689,0.42830,0.2549]\n","val_loss_min = [0.570152,0.525531,0.596814]\n","val_loss_max = [0.548766,0.5161,0.6011]\n","epoch_list=[1,2,3]\n","\n","plt.figure()\n","plt.plot(epoch_list,training_loss_min, label=\"Training Loss Min Run\")\n","plt.plot(epoch_list,val_loss_min, label=\"Validation Loss Min Run\")\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.xticks(epoch_list)\n","plt.legend()\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"ETVYeOfB_iG8","executionInfo":{"status":"ok","timestamp":1644697857924,"user_tz":0,"elapsed":618,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"a6639301-801d-49ee-812e-910f2274eeda"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deVyVdfr/8dfFjuAuuIAIKriLC2pp7rmkjVqay7Ro1pSO5lLTVPObmRqrmWpMzbJMW+fbYmllpuaaikuWqLhvCO6KigtuKMvn98c5wFEBUTnecM71fDx4yLnPfZ9zocib+/O57+sjxhiUUkqpa3lYXYBSSqniSQNCKaVUnjQglFJK5UkDQimlVJ40IJRSSuXJy+oCikqlSpVMeHi41WUopVSJsn79+pPGmKC8nnOZgAgPDycuLs7qMpRSqkQRkf35PadDTEoppfKkAaGUUipPGhBKKaXy5NSAEJHuIrJLRBJE5MV89ukvIttFZJuIfOWwfbCI7LF/DHZmnUoppa7ntElqEfEEpgBdgEPAOhGZY4zZ7rBPJPAS0MYYc1pEgu3bKwAvAzGAAdbbjz3trHqVUkpdzZlnEC2BBGNMojHmCjAD6H3NPn8CpmT/4DfGHLdv7wYsNsacsj+3GOjuxFqVUkpdw5kBEQIcdHh8yL7NURQQJSKrRWStiHS/iWMRkadEJE5E4k6cOFGEpSullLL6PggvIBLoAIQCsSLSqLAHG2OmAdMAYmJitG+5Usq9nD0MCUvAZELM0CJ/eWcGxGGgusPjUPs2R4eA34wx6UCSiOzGFhiHsYWG47HLnVapUkqVBBmX4cCvtlBIWArH7VO6oS1KXECsAyJFJALbD/yBwB+v2Wc2MAj4VEQqYRtySgT2Av8WkfL2/bpim8xWSin3cirRFgYJSyApFtIvgqcPhN0NXV6F2vdCcD2nvLXTAsIYkyEiI4GFgCfwiTFmm4iMA+KMMXPsz3UVke1AJvC8MSYFQERexRYyAOOMMaecVatSShUbVy7CvlX2s4TFtoAAKB8OTR62BUL4PeAb6PRSxFWWHI2JiTHai0kpVeIYAyd3w57FtlDYvwYyL4OXP0S0tQVC7XuhQk0QKfK3F5H1xpiYvJ6zepJaKaXcT1oqJK3InUs4a79os1IdaPknqN0ZwlqDt5+lZWpAKKWUsxkDxzbnBsLB3yArA3xKQ8320PY5WyiUC7O60qtoQCillDNcPAV7f7EFwt6lcD7Ztr1KI2j9DNTuAtVbgqe3tXUWQANCKaWKQlYmHNloO0vYsxgOrwcM+JeHWp1s8wi1OkHpKlZXWmgaEEopdavOJdvODhKW2M4WLp0GBEKaQ/sXILILVGsKHp5WV3pLNCCUUqqwMtPh4O+2y08TlsCxLbbtAcEQdZ9tHqFWJyhVwdo6i4gGhFJKFeTMQfvk8hJIXAFXzoF4Qthd0PmftqGjyo3Aw/WW19GAUEopR+lpcGBN7t3LJ3batpcJhUZ9bYEQ0Q78ylpb5x2gAaGUUil7c88SklZCxiVbO4sabaDpo7ZQCKrjlBvVijMNCKWU+7lywRYE2aFwOsm2vUJNaPaYvZ1FG/AJsLZOi2lAAJ+sSqJn46pULmPtXYtKKScxxjZUlN3O4sCvkHkFvEvZhovuHmGbXK5Yy+pKixW3D4jE46mcW/Aq/15YnXrRrXioa3sqlnHv3xqUcgmXzlzdziLVvtpAUD1o+ZTtEtSwu8HL19o6izG3D4iaPmcZ5f0DYrJgK6Rt8eZYYC0qRDTBp1pDCK4PlRtAYGW3G39UqkTJynJoZ7HEdjmqyQTfMlCzg+2+hNqdoWyo1ZWWGNrNFSD9EpzYRXLCBrZs/BWfkzuo63mIYE7n7lOqYm5YZP8ZVPeOtNxVSuXjQoq9ncUS2w1rF+xLD1eNtndB7QKhMcW6nYXVCurmqgGRh+1HUpmweDfrd+whxv8oQ2pfpFXAMbxO7IDjOyD9gn1PsfVozwmN+hDcwDbR5en2J2dKFb2sTFsLi+x2Fkc2YmtnUcF2dpDdziIw2OpKSwwNiFsUf/AMby/axco9Jwkq7cvIjrUZ2CIE33MHIXm7bbm/5G22P1MSwGTZDvT0heC6trCoXF+HqZS6HalHHdpZLIO0MyAeEBKTu1ZCtSYltp2F1TQgbtNviSm8vWg3v+87RbWyfozqHEnf5qF4ezrcOWkfproqNJK3w/ljufv4V7AFhQ5TKZW/jCu2dtjZk8vJ9nYWgVXsgdDZNqfgIu0srKYBUQSMMaxKOMn4RbvZdPAMNSqWYsy9kfSKDsHTo4CzggspcHyb/Ywj+0/HYSrsw1QNdZhKua/T+3MDIWkFXDkPHl62q4yyh44qN9QzcCfQgChCxhiW7jjO24t3s+NoKrWDA3m2SxTdG1TBo6CgcJSVBWf2O5xp5DNMFVTH9p9Ch6mUq0m/BPtX57azOLnbtr1smC0QIrtAeFvwK2NtnW5AA8IJsrIMP289xoTFu9h74gL1q5bhua5RdKobjNzqD/D0NDi5yxYYNxqmyg4MHaZSJYEx9nYW9hvV9q2CjDTbL0Lh9+TOJVSK1F+A7jANCCfKzDL8GH+YSUv2cODURZpUL8dfutahTe2Ktx4U17qQ4nCmUcAwVfakeOUGOkylrHf53NXtLM7st22vWDv3EtQarcGnlLV1ujnLAkJEugPvAJ7AR8aYN655fgjwX8B+iyPvGWM+sj+XCdhnpzhgjOlV0HtZFRDZ0jOzmLX+EJOX7uHo2TRaRVTgL93q0CLcSRNp2cNU2cFR4DDVNWccOkylnMEY2/dgTjuLtZCVDt4BtnWXa3eGWp2hQoTVlSoHlgSEiHgCu4EuwCFgHTDIGLPdYZ8hQIwxZmQex583xhR63MTqgMiWlp7JjN8P8N6yvZw8f5l2UUE81yWK6Orl7kwBOcNU2yF5ayGGqerb5jl0mErdikunIXF57gTzuaO27cENcieXw+7SdhbFWEEB4czxh5ZAgjEm0V7EDKA3sL3Ao0o4P29PhrSJYECLMP736z6mrthL7ymr6VK/Ms92iaJeVSdPunn72e4irRp99faLpxzmNbbaQmPjF/kPUwXbg0OHqZSjrCw4Gm+fXF4Mh9bZzlh9y0KtjrmXoZapZnWlqgg48wyiH9DdGPOk/fGjQCvHswX7GcR/gBPYzjbGGmMO2p/LAOKBDOANY8zsPN7jKeApgLCwsOb79+93ytdyO86lpfPp6n1Mj03k3OUM7m9clTH3RlE7uBj8tn7VMJXDGUeBw1T24NBhKvdx/sTV7Swupti2V2uaO7kcEqO/SJRQVg0xFSYgKgLnjTGXReRpYIAxppP9uRBjzGERqQn8AnQ2xuzN7/2KyxBTfs5cvML0lYl8unofaemZPNA0lNGdIwmrWAwn6ByHqY7b5zduNEwV3ACC6+kwlSvIzIDDcbntLI7G27aXqpQ7bFSzIwQGWVunKhJWBcTdwCvGmG72xy8BGGP+k8/+nsApY8x16/iJyGfAXGPMrPzer7gHRLaT5y8zdfle/rd2P1lZhv4tqvNMp9pULetvdWk3dtUwVfbEeAFXU2VPjFeopb9dFndnDzu0s1gOl8/a2lmEtswdNqraxCXXXXZ3VgWEF7Zho87YrlJaB/zRGLPNYZ+qxpij9s8fAF4wxtwlIuWBi/Yzi0rAr0Bvxwnua5WUgMh27GwaU5YlMGPdAUSEh1uF8ecOtQkqXcIm864dpso+47jRMFVwAyhdRYeprJJx2XaVUfbk8nH7f8vSVe1nCV1sVx75l7e2TuV0Vl7m2gOYhO0y10+MMa+LyDggzhgzR0T+A/TCNs9wChhujNkpIq2BD4EswAOYZIz5uKD3KmkBke3gqYu8+8sevttwGB9PDwa3DufpdjUpH+BjdWm357phKvtZhw5TWedUkkM7i1jbmZ+HN9S4O3cuIbi+hrab0RvlSoDEE+d5Z+ke5mw6QoCPF0/cE8ETbSMo4+difex1mOrOuXLR3s7CfqNaSoJte7kw2xlCdjsLDWS3pgFRguw6do6Ji3ezYNsxyvp783T7mgxpHU4pHxf+4ajDVEXDGDi5x6GdxWrIvAxefrYgyD5LqFhL/85UDg2IEmjLobNMWLyLZbtOUCnQh+EdavNwqzD8vN2o532hhqnKX98J152GqdJSbcNF2UNHZw/YtleKyp1crtEGvEvARRDKEhoQJdj6/ad4e9Fu1uxNoUoZP0Z2qk3/mOr4eLnx1STXDlNln3k4DlOVq3F9J1xXGKYyxna/SnYgHPgVsjLAJ9C2RkJ2O4vyNayuVJUQGhAuYM3ek7y9aDfr958mtLw/oztH8kDTELw83TgoHOU5TLUdUvZcM0wVdf0ZR3Efprp4ChKX5bbGPp9s2165Ue59CdVbgVcJv7BBWUIDwkUYY1i++wRvL9rF1sOp1KwUwJguUdzfqGrh16JwN3kNUx3fntszCGzDVNd2wrVymCorE47E288SFtvWYDZZ4FfOtt5y9rrLZapaU59yKRoQLsYYw8JtyUxYvIvdyeepU7k0z3aNomv9ykXXYtzV5TVMdXyHbSWzbOVqXN8J11nDVOeP554h7P0FLp0CBEKaOay73KzkD5GpYkcDwkVlZhnmbj7CpCV7SDp5gcahZXm2SxTto4I0KG5FvsNUCWAybftkD1Nde8Zxs8NUmem2RnfZl6Ae3WTbHhCUGwg1O0JAxaL/OpVyoAHh4jIys/h+42HeWbKHw2cuEVOjPM91rcPdtfSHS5G42WGq7E64wXXBt3TuPmcP5QZC4gq4nAriaZs/yJ5LqNJY21moO0oDwk1cycjim7iDvPfLHpJTL9OmdkWe7VKH5jW0XYJTFHaYKrgenN4PJ3bYtpUJubqdhd917ceUumM0INxMWnomX6zdzwfL95Jy4Qqd6gbzbJcoGoboDyKny8qy3YuQ3QH3+DY4vhMCg213Lte+17Y4kw4BqmJCA8JNXbicwWdr9jEtNpGzl9K5r2EVxnaJIqpy6RsfrJRyCxoQbi41LZ2PVibxyaokLlzJoHd0NUbfG0VEpQCrS1NKWUwDQgFw6sIVPozdy+dr9pGeaejXLJRnOtcmtHwxXLRIKXVHaECoqxw/l8b7y/by1W8HMBgGtQxjRMfaVC7jZ3VpSqk7TANC5enImUu8+0sCM+MO4ukhPHZ3DYa1r0XFwBK2aJFS6pZpQKgCHUi5yKSlu5m98TB+3p4MbRPBn9rWpGwpF1uLQil1HQ0IVSgJx88xccke5m0+Smk/L55qW5PH74kg0FfbOyjlqjQg1E3ZfiSViUt2s3h7MuVLeTO8Qy0evSscfx83WotCKTehAaFuSfzBM0xYvJvY3ScIKu3LyI61GdiyOr5eGhRKuQoNCHVbfk86xfhFu/g96RTVyvoxqnMkfZuH4q1rUShV4mlAqNtmjGF1Qgr/XbSLTQfPUKNiKcbcG0mv6BA8dS0KpUqsggLCqb8Cikh3EdklIgki8mIezw8RkRMiEm//eNLhucEissf+MdiZdaobExHuiazE7D+35uPBMZTy8WLsN5voNimWeZuPkpXlGr9oKKVyOe0MQkQ8gd1AF+AQsA4YZIzZ7rDPECDGGDPymmMrAHFADGCA9UBzY8zp/N5PzyDurKwsw4Jtx5iweDcJx89Tv2oZnusaRae6wboWhVIliFVnEC2BBGNMojHmCjAD6F3IY7sBi40xp+yhsBjo7qQ61S3w8BB6NKrKwjHtmDggmgtXMnji8zgeeH8NK/ecwFWGLpVyZ84MiBDgoMPjQ/Zt1+orIptFZJaIVL+ZY0XkKRGJE5G4EydOFFXd6iZ4eggPNA1lybPteePBRhxPTePRj39nwLS1/J50yurylFK3werLUH4Cwo0xjbGdJXx+MwcbY6YZY2KMMTFBQUFOKVAVjrenBwNbhrHs+Q78q1cDkk5eoP+Hv/LYJ7+z6eAZq8tTSt0CZwbEYaC6w+NQ+7YcxpgUY8xl+8OPgOaFPVYVT75engxuHU7s8x35W4+6bDl0ht5TVvPk53HsOJpqdXlKqZvgzIBYB0SKSISI+AADgTmOO4hIVYeHvQD7mowsBLqKSHkRKQ90tW9TJYS/jydPtavFyhc68VyXKH5LSuG+d1Yy8qsNJBw/f+MXUEpZzmlNdowxGSIyEtsPdk/gE2PMNhEZB8QZY+YAo0SkF5ABnAKG2I89JSKvYgsZgHHGGB3QLoECfb14pnMkj90dzvSViXyyOon5W47Sp2kIYzpHEVZR16JQqrjSG+XUHZVy/jJTV+zlf7/uJzPL8FBMdZ7pVJtq5fytLk0pt6R3UqtiJzk1jSnLEvj69wMIwh9bhfHnjrUILq2LFil1J2lAqGLr0OmLvLs0gVkbDuHj6cFjrWswrF0tygf4WF2aUm5BA0IVe0knL/DOkt38uOkIAT5eDL0ngifbRlDGTxctUsqZNCBUibE7+RwTF+/m563HKOvvzVPtajKkdTgBumiRUk6hAaFKnK2HzzJh8W5+2XmcigE+DO9Qi0fuqoGft65FoVRR0oBQJdb6/aeZsHgXqxNSqFLGjxGdajMgpjo+XlY3AVDKNWhAqBJvzd6TTFi0m7j9pwkt78+ozpE82DQEL120SKnbYtl6EEoVlda1KjFz2N189ngLypfy4a+zNtN1Yiw/xh/WtSiUchINCFViiAgd6gQzZ2QbPny0Od6eHoyeEc9976xkwdZj2mJcqSKmAaFKHBGhW4Mq/Dy6LZMHNSU9M4thX6yn13urWbbruAaFUkVEA0KVWB4eQq/oaiwa247/9mvM6YtXePzTdfSb+itr9p60ujylSjydpFYu40pGFt/GHeTdX/aQnHqZ1rUq8lzXOjSvUd7q0pQqtvQqJuVW0tIz+fK3A3ywPIGT56/QsU4Qz3WtQ8OQslaXplSxowGh3NKFyxl8/us+PlyRyNlL6XRvUIWxXaKoU6W01aUpVWxoQCi3lpqWzscrk/h4VRIXrmTQK7oaY+6NIqJSgNWlKWU5DQilgNMXrvBhbCKfrUkiPdPQt1kIz3SKpHoFXbRIuS8NCKUcHD+XxgfL9/Ll2gMYDANbhDGyU20ql9G1KJT70YBQKg9HzlzivWUJfLvuIJ4ewqN31WBYh1pUCvS1ujSl7hgNCKUKcCDlIu8s3cMPGw/h5+3J423CeaptLcqW0rUolOvTgFCqEBKOn2fSkt3M3XyU0n5e/KltTR5vE05pXbRIuTANCKVuwo6jqUxYvJvF25MpX8qbYe1r8djd4fj76FoUyvVY1s1VRLqLyC4RSRCRFwvYr6+IGBGJsT8OF5FLIhJv/5jqzDqVclSvahmmPxbDjyPa0Ci0HP/5eSdt31rGZ6uTuJyRaXV5St0xTjuDEBFPYDfQBTgErAMGGWO2X7NfaWAe4AOMNMbEiUg4MNcY07Cw76dnEMpZfk86xfhFu/g96RTVyvrxTOdI+jUPxVvXolAuwKoziJZAgjEm0RhzBZgB9M5jv1eBN4E0J9ai1C1rGVGBb566iy+eaEVwGT9e+n4Lnd9ewfcbDpGpa1EoF+bMgAgBDjo8PmTflkNEmgHVjTHz8jg+QkQ2isgKEWnrxDqVuiER4Z7ISvzw59Z8MiSGQF8vnv12E90mxTJv81FdtEi5JC+r3lhEPIAJwJA8nj4KhBljUkSkOTBbRBoYY1KveY2ngKcAwsLCnFyxUrag6FS3Mh2iglmw7RgTF+9mxFcbqFe1DM91iaJzvWBExOoylSoSzjyDOAxUd3gcat+WrTTQEFguIvuAu4A5IhJjjLlsjEkBMMasB/YCUde+gTFmmjEmxhgTExQU5KQvQ6nreXgIPRpVZcGYdkwa0ISLVzJ48n9x9Hl/DSv3nNBFi5RLKFRAiEiA/Td+RCRKRHqJyI0uDl8HRIpIhIj4AAOBOdlPGmPOGmMqGWPCjTHhwFqgl32SOsg+yY2I1AQigcSb/uqUcjJPD6FP0xCWPNueN/s24uS5yzz68e8MmLaW35NOWV2eUrelsGcQsYCfiIQAi4BHgc8KOsAYkwGMBBYCO4BvjTHbRGSciPS6wfu1AzaLSDwwCxhmjNH/barY8vb0YECLMH75S3vG9W5A0skL9P/wVx79+DfiD56xujylbkmhLnMVkQ3GmGYi8gzgb4x5S0TijTFNnF9i4ehlrqo4uXQlky/W7ueDFXs5deEKvZtU41+9GlCulI/VpSl1laK4zFVE5G7gYWz3LADobaVK5cPfx5M/tatJ7F87MqpTbeZtPkq3SbEs33Xc6tKUKrTCBsQY4CXgB/swUU1gmfPKUso1BPp68WzXOswe0YYyft4M+XQdf/thCxcuZ1hdmlI3dNN3UtsnqwOvveTUajrEpIq7tPRMJizezfSViYSW9+fth5rQMqKC1WUpN3fbQ0wi8pWIlBGRAGArsF1Eni/KIpVydX7envytRz2+eepuBGHAtF/59/wdpKVrfydVPBV2iKm+/YyhD/AzEIHtSial1E1qGVGBn0e3ZVDLMKbFJtLrvVVsPXzW6rKUuk5hA8Lbft9DH2COMSYd0DuBlLpFAb5e/PuBRnz2eAvOXkqnz5TVvLNkD+mZWVaXplSOwgbEh8A+IACIFZEaQLGag1CqJOpQJ5iFY9rRo1FVJi7ZTd8P1pBw/JzVZSkF3Ea7bxHxst8MVyzoJLUq6eZtPsrfZ2/h4pVM/tq9Lo+3DsfDQ/s6KecqiknqsiIyQUTi7B9vYzubUEoVkZ6Nq7JwbDvuqV2JV+du548freXgqYtWl6XcWGGHmD4BzgH97R+pwKfOKkopdxVc2o+PBsfwVt/GbD2cyn3vrOSbdQe0+Z+yRGEDopYx5mX74j+Jxph/ATWdWZhS7kpE6N+iOj+PbkvDkDK88N0Wnvg8juOpuqaWurMKGxCXROSe7Aci0ga45JySlFIA1SuU4qsn7+Kf99dndcJJuk6KZe7mI1aXpdxIYQNiGDBFRPbZ1254D3jaaVUppQDbuhND74lg3qi21KhQipFfbeSZrzdy5uIVq0tTbqBQAWGM2WSMiQYaA42NMU2BTk6tTCmVo3ZwIN8Nb81zXaL4ectRuk6MZZk2/lNOdlMryhljUh16MD3rhHqUUvnw8vTgmc6RzB7RhnKlvHn803W89P1mzmvjP+Ukt7PkqF6grZQFGoaUZc7Ie3i6XU1mrDvIfe/E6up1yiluJyD0ujulLOLn7clLPerx7dO5jf9en7ddG/+pIlVgQIjIORFJzePjHFDtDtWolMpHi3Bb478/tgxj+sok/vDuKrYc0sZ/qmgUGBDGmNLGmDJ5fJQ2xnjdqSKVUvkL8PXidXvjv9S0dB54fzWTluzWxn/qtt3OEJNSqhjpUCeYRWPac3/jqkxaskcb/6nbpgGhlAspW8qbSQOb8v7DzTh46iI9Jq/io5WJZGXplKG6eRoQSrmgHo1sjf/aRVbitXk7GDRdG/+pm+fUgBCR7iKyS0QSROTFAvbrKyJGRGIctr1kP26XiHRzZp1KuaLg0n5MfyyGt/o1ZtuRVLpPimXG79r4TxWe0wJCRDyBKcB9QH1gkIjUz2O/0sBo4DeHbfWBgUADoDvwvv31lFI3QUToH1OdBWPa0ji0HC9+r43/VOE58wyiJZBg7/56BZgB9M5jv1eBNwHH79jewAxjzGVjTBKQYH89pdQtCC1fii+fbMXLf9DGf6rwnBkQIcBBh8eH7NtyiEgzoLoxZt7NHms//qnsRYxOnDhRNFUr5aI8PITH29gb/1UM0MZ/6oYsm6QWEQ9gAvDcrb6GMWaaMSbGGBMTFBRUdMUp5cJqBwfy3bC7r278t1Mb/6nrOTMgDgPVHR6H2rdlKw00BJbbW4jfBcyxT1Tf6Fil1G1wbPxXvpQPj3+mjf/U9ZwZEOuASBGJEBEfbJPOc7KfNMacNcZUMsaEG2PCgbVAL2NMnH2/gSLiKyIRQCTwuxNrVcotNQwpy5xn2vB0+9zGf78lplhdliomnBYQxpgMYCSwENgBfGuM2SYi40Sk1w2O3QZ8C2wHFgAjjDHahUwpJ/D18uSl++ox8+m78RBh4PS1vDZXG/8pEFe5JjomJsbExcVZXYZSJdqFyxn85+cdfLH2ALWDA5nQP5rGoeWsLks5kYisN8bE5PWc3kmtlMoR4OvFa30a8b+hLTmflsED769h4mJt/OeuNCCUUtdpFxXEwjHt6BVdjXeW7uHB99ewJ1kb/7kbDQilVJ7KlvJm4oAmfPBwMw6dvkjPd7Xxn7vRgFBKFei+RlVZNLY97SKDeG3eDgZq4z+3oQGhlLqhoNK+TH+sOf/t15gd9sZ/X2vjP5enAaGUKhQR4aGY6iwY247o6uV46fstDP1snTb+c2EaEEqpmxJSzp8vnmjFK3+oz5q9KXSdFMtPm7TxnyvSgFBK3TQPD2FImwjmj25LeMUAnvl6IyO/2sDpC9r4z5VoQCilblmtoEBmDbub57vVYeG2Y3SdpI3/XIkGhFLqtnh5ejCiY21mj2hDBXvjvxe/08Z/rkADQilVJBpUszX+G9a+Ft/GHaT7pFjWauO/Ek0DQilVZHy9PHnxvrrMHHY3nh7CoOlreVUb/5VYGhBKqSLXvEYFfh7dlkda1eDjVUnc/+4qNh86Y3VZ6iZpQCilnKKUjxev9mmojf9KMA0IpZRTaeO/kksDQinldNmN/6Y+0ozDZy7R891VTI9NJFMb/xVrGhBKqTume8OqLBzTjvZRQbw+fweDpq3lQIo2/iuuNCCUUndUUGlfpj3anPEPRbPjaCrd34nlq9+08V9xpAGhlLrjRIR+zUNZMLYdTcPK8bcftvD4Z+tI1sZ/xYoGhFLKMiHl/Pm/oa34V68GrE1MoevEWOZo479iQwNCKWUpDw9hcOtw5o9qS82gAEZ9vZER2vivWHBqQIhIdxHZJSIJIvJiHs8PE5EtIhIvIqtEpL59e7iIXLJvjxeRqc6sUyllvZpBgcx82tb4b5G98d8vO5OtLsutOS0gRMQTmALcB9QHBmUHgIOvjDGNjDFNgLeACQ7P7TXGNLF/DHNWnUqp4iO78d+PI+6hYoAPQz+L44VZmzmXlm51aW7JmWcQLYEEY0yiMeYKMAPo7biDMSbV4WEAoJcxKKWoX60MP45sw0DWKgYAABVrSURBVPAOtZi5/iD3vbNSG/9ZwJkBEQIcdHh8yL7tKiIyQkT2YjuDGOXwVISIbBSRFSLSNq83EJGnRCROROJOnDhRlLUrpSzm6+XJC91tjf+8tPGfJSyfpDbGTDHG1AJeAP5u33wUCDPGNAWeBb4SkTJ5HDvNGBNjjIkJCgq6c0Urpe6Y5jUqMH90Wx69y9b4r+fkldr47w5xZkAcBqo7PA61b8vPDKAPgDHmsjEmxf75emAvEOWkOpVSxVwpHy/G9W7I/z3RkguXM3ng/TVM0MZ/TufMgFgHRIpIhIj4AAOBOY47iEikw8OewB779iD7JDciUhOIBBKdWKtSqgRoGxnEwrHt6B1djclL9/DA+6vZrY3/nMZpAWGMyQBGAguBHcC3xphtIjJORHrZdxspIttEJB7bUNJg+/Z2wGb79lnAMGPMKWfVqpQqOcr6ezNhQBOmPtKco2fSuP/dVUyL3auN/5xAXKX/SUxMjImLi7O6DKXUHXTy/GX+9v0WFm1PpmV4BcY/FE1YxVJWl1WiiMh6Y0xMXs9ZPkmtlFK3qlKgLx8+2py3tfGfU2hAKKVKNBGhb/NQFo5tR7Ow8tr4rwhpQCilXEK1cv78b2hLxvXObfz3Y/xhPZu4DRoQSimX4eEhPHZ3buO/0TPiGfnVRk5p479bogGhlHI5VzX+236MrhNjWbpDG//dLA0IpZRLcmz8VynQhyc+18Z/N0sDQinl0rIb//3Z3viv+6SV/LpXG/8VhgaEUsrl+Xp58tfudZk5rDXenrbGf+N+0sZ/N6IBoZRyG81rlGf+6LYMvrsGn6y2Nf7bdFAb/+VHA0Ip5VZK+Xjxr94N+eKJVly8ksmDH6xhwqJd2vgvDxoQSim3dE9kJRaMaUfvJtWY/EsCfaasZtcxbfznSANCKeW2yvp7M6F/Ez58tDnHzqbxh3dX8eEKbfyXTQNCKeX2ujWowsKx7ehYN4j//LyTgdN+5UDKRavLspwGhFJKYWv8N/WR5kzoH83OY+fo/k4sX/62361bdWhAKKWUnYjwYLNQFo6xNf77fz9sZcin6zh21j0b/7n0ehDp6ekcOnSItDT3/MdVzufn50doaCje3t5Wl6KKWFaW4Yvf9vPv+Tvw8fTg1T4N6RVdDRGxurQiVdB6EC4dEElJSZQuXZqKFSu63D+qsp4xhpSUFM6dO0dERITV5SgnSTp5gee+jWfDgTP0aFSF1/o0okKAj9VlFRm3XTAoLS1Nw0E5jYhQsWJFPUN1cRGVApg5rDV/7V6HxduT3arxn0sHBKDhoJxKv7/cg6eH8OcOtZkzMrfx319nbXL5xn8uHxBKKVVU6lUtw5yR9zCiYy1mrT9E90krWbP3pNVlOY0GhBOlpKTQpEkTmjRpQpUqVQgJCcl5fOVKwQuYxMXFMWrUqBu+R+vWrYuk1uXLl3P//fcXyWsV9B4iwkcffZSzLT4+HhFh/PjxAPzzn/9kyZIlN/WaZcuWpUmTJtStW5e//OUvRV63Uo58vDx4vltdZg1vjY+XB3+c/hv/+mmbSzb+c2pAiEh3EdklIgki8mIezw8TkS0iEi8iq0SkvsNzL9mP2yUi3ZxZp7NUrFiR+Ph44uPjGTZsGGPHjs157OPjQ0ZGRr7HxsTEMHny5Bu+x5o1a4qyZKdr2LAh3377bc7jr7/+mujo6JzH48aN4957772p12zbti3x8fFs3LiRuXPnsnr16iKrV6n8NAsrz/xRbRnSOpxPV++jx+SVxLtY4z8vZ72wiHgCU4AuwCFgnYjMMcZsd9jtK2PMVPv+vYAJQHd7UAwEGgDVgCUiEmWMueWI/tdP29h+JPVWD89T/WplePkPDW7qmCFDhuDn58fGjRtp06YNAwcOZPTo0aSlpeHv78+nn35KnTp1WL58OePHj2fu3Lm88sorHDhwgMTERA4cOMCYMWNyzi4CAwM5f/48y5cv55VXXqFSpUps3bqV5s2b88UXXyAizJ8/n2effZaAgADatGlDYmIic+fOLVS9X3/9Nf/+978xxtCzZ0/efPNNMjMzeeKJJ4iLi0NEGDp0KGPHjmXy5MlMnToVLy8v6tevz4wZM657vRo1apCamkpycjLBwcEsWLCAHj16XPX3c//999OvXz/Cw8MZPHgwP/30E+np6cycOZO6devmW6u/vz9NmjTh8OHDV/3dAMyaNYu5c+fy2WefMWTIEMqUKUNcXBzHjh3jrbfeol+/foX+N1Qqm7+PJ6/0akCX+pV5fuYm+n6whhEdajGyUyQ+XiV/gMZpAQG0BBKMMYkAIjID6A3kBIQxxvEndgCQfc1tb2CGMeYykCQiCfbX+9WJ9d4xhw4dYs2aNXh6epKamsrKlSvx8vJiyZIl/O1vf+O777677pidO3eybNkyzp07R506dRg+fPh1195v3LiRbdu2Ua1aNdq0acPq1auJiYnh6aefJjY2loiICAYNGlToOo8cOcILL7zA+vXrKV++PF27dmX27NlUr16dw4cPs3XrVgDOnLH91vTGG2+QlJSEr69vzra89OvXj5kzZ9K0aVOaNWuGr69vvvtWqlSJDRs28P777zN+/Pirhqeudfr0afbs2UO7du1u+LUdPXqUVatWsXPnTnr16qUBoW5Lm9qVWDC2Hf+as53JvySwdOdxJvRvQp0qpa0u7bY4MyBCgIMOjw8Bra7dSURGAM8CPkAnh2PXXnNsSB7HPgU8BRAWFlZgMTf7m74zPfTQQ3h6egJw9uxZBg8ezJ49exAR0tPzviqiZ8+e+Pr64uvrS3BwMMnJyYSGhl61T8uWLXO2NWnShH379hEYGEjNmjVzrtMfNGgQ06ZNK1Sd69ato0OHDgQFBQHw8MMPExsbyz/+8Q8SExN55pln6NmzJ127dgWgcePGPPzww/Tp04c+ffrk+7r9+/dnwIAB7Ny5k0GDBhU4TPbggw8C0Lx5c77//vs891m5ciXR0dHs2bOHMWPGUKVKlRt+bX369MHDw4P69euTnOwelywq5yrj583b/aPp2qAy/++HLfzh3VU81zWKJ9vWxNOjZF7tZvk5kDFmijGmFvAC8PebPHaaMSbGGBOT/UOsJAgICMj5/B//+AcdO3Zk69at/PTTT/leU+/4W7anp2ee8xeF2acolC9fnk2bNtGhQwemTp3Kk08+CcC8efMYMWIEGzZsoEWLFvm+f5UqVfD29mbx4sV07ty5wPfK/poK+nratm3Lpk2b2LZtGx9//DHx8fHA1ZegXvv36vh35So3i6rioVuDKiwc045OdYNzGv/tT7lgdVm3xJkBcRio7vA41L4tPzOA7F87b/bYEuvs2bOEhNhOjj777LMif/06deqQmJjIvn37APjmm28KfWzLli1ZsWIFJ0+eJDMzk6+//pr27dtz8uRJsrKy6Nu3L6+99hobNmwgKyuLgwcP0rFjR958803Onj2bM/6fl3HjxvHmm2/mnEkVhYiICF588UXefPNNACpXrsyOHTvIysrihx9+KLL3UepGKgb68sEjzZg4wNb47753VvLF2pLX+M+ZQ0zrgEgRicD2w30g8EfHHUQk0hizx/6wJ5D9+RzgKxGZgG2SOhL43Ym1Wuavf/0rgwcP5rXXXqNnz55F/vr+/v68//77dO/enYCAAFq0aJHvvkuXLr1q2GrmzJm88cYbdOzYMWeSunfv3mzatInHH3+crCzbClz/+c9/yMzM5JFHHuHs2bMYYxg1ahTlypXL972K6vLcaw0bNozx48ezb98+3njjDe6//36CgoKIiYkpMLCUKmoiwgNNQ2kVUZEXvtvM32dvZdH2ZN7q25gqZf2sLq9QnNqLSUR6AJMAT+ATY8zrIjIOiDPGzBGRd4B7gXTgNDDSGLPNfuz/A4YCGcAYY8zPBb1XXr2YduzYQb169Yr6yypxzp8/T2BgIMYYRowYQWRkJGPHjrW6LJeh32fqRowxfLF2P/+evxNvT2Fc74b0blI8Gv+5bbM+/Y9rM3HiRD7//HOuXLlC06ZNmT59OqVKlbK6LJeh32eqsPadvMBzMzexfv/pYtP4TwNCKSfS7zN1MzKzDNNiE5m4eDdl/L1548FG3Fu/smX1uG03V6WUKm48PYThHWox55k2BJX25cn/xfH8zOLZ+E8DQimlLFC3Shl+HNGGkR1r892G4tn4TwNCKaUs4uPlwV+61eG74a3xtTf+e2XONi5dKR6N/zQglFLKYk3DyjPP3vjvszX76Plu8Wj8pwHhRB07dmThwoVXbZs0aRLDhw/P95gOHTqQPdneo0ePPHsavfLKKzntsfMze/Zstm/P7Yt4s22086NtwZVyjuzGf18+2Yq0K5n0/WANby/axZWMLMtq0oBwokGDBl3X0XTGjBmFbpg3f/78Am82K8i1AXErbbStpG3BlbvKbvz3QNMQ3v0lgT5TVrPr2DlLanGfgPj5Rfi0Z9F+/HzdEhdX6devH/PmzctZHGjfvn0cOXKEtm3bMnz4cGJiYmjQoAEvv/xynseHh4dz8qRt0ur1118nKiqKe+65h127duXsM336dFq0aEF0dDR9+/bl4sWLrFmzhjlz5vD888/TpEkT9u7dy5AhQ5g1axZgu2O6adOmNGrUiKFDh3L58uWc93v55Zdp1qwZjRo1YufOnYX+6/36669p1KgRDRs25IUXXgAgMzOTIUOG0LBhQxo1asTEiRMBmDx5MvXr16dx48YMHDgwz9erUaMGaWlpJCcnY4xhwYIF3HfffTnPO349N1t3Xm3Bs82aNYshQ4bkvMeoUaNo3bo1NWvWzHk/pZytjJ834x+KZvpjMRw/l8Yf3l3F1BV7ycy6s7cluE9AWKBChQq0bNmSn3+23QQ+Y8YM+vfvj4jw+uuvExcXx+bNm1mxYgWbN2/O93XWr1/PjBkziI+PZ/78+axbty7nuQcffJB169axadMm6tWrx8cff0zr1q3p1asX//3vf4mPj6dWrVo5+6elpTFkyBC++eYbtmzZQkZGBh988EHO89nttYcPH37DYaxs2W3Bf/nlF+Lj41m3bh2zZ88mPj4+py34li1bePzxxwFbW/CNGzeyefNmpk6dmu/rZrcFX7NmTaHbghem7ltpCz537lxefLHgXwiUKmpd6lfOafz3xs87GfDhnW3858xeTMXLfW9Y8rbZw0y9e/dmxowZfPzxxwB8++23TJs2jYyMDI4ePcr27dtp3Lhxnq+xcuVKHnjggZy7n3v16pXz3NatW/n73//OmTNnOH/+PN26Fbz43q5du4iIiCAqKgqAwYMHM2XKFMaMGQMUrr32tbQtuFLOk93478f4I/zzx610n7SSv/WsxyOtwpzeqkPPIJysd+/eLF26lA0bNnDx4kWaN29OUlIS48ePZ+nSpWzevJmePXvm2+b7RoYMGcJ7773Hli1bePnll2/5dbIVpr12YWlbcKWKhojQp2kIC8e2Iya8PP+YvZXHPvmdo2cvOfV9NSCcLDAwkI4dOzJ06NCcyenU1FQCAgIoW7YsycnJOUNQ+WnXrh2zZ8/m0qVLnDt3jp9++innuXPnzlG1alXS09P58ssvc7aXLl2ac+eun9iqU6cO+/btIyEhAYD/+7//o3379rf1NWpbcKXujKpl/fnf0Ja82qchcftO021iLLM3HnbaLy/uM8RkoUGDBvHAAw/kXNEUHR1N06ZNqVu3LtWrV6dNmzYFHt+sWTMGDBhAdHQ0wcHBV7XsfvXVV2nVqhVBQUG0atUqJxQGDhzIn/70JyZPnnzV5Kqfnx+ffvopDz30EBkZGbRo0YJhw4bd1NejbcGVso6I8OhdNWhbuxLPzdzEmG/iWbwjmXcHNsWjiFeu02Z9St0m/T5TVsnMMkxfmcj5tAz+0q3OLb1GQc369AxCKaVKKE8PYVj7Wjfe8RbpHIRSSqk8uXxAuMoQmiqe9PtLuTKXDgg/Pz9SUlL0P7FyCmMMKSkp+PmVjPWFlbpZLj0HERoayqFDhzhx4oTVpSgX5efnd9UVXUq5EpcOCG9vbyIiIqwuQymlSiSXHmJSSil16zQglFJK5UkDQimlVJ5c5k5qETkB7L+Nl6gEFK8Vw5Ur0e8v5Uy38/1VwxgTlNcTLhMQt0tE4vK73Vyp26XfX8qZnPX9pUNMSiml8qQBoZRSKk8aELmmWV2Acmn6/aWcySnfXzoHoZRSKk96BqGUUipPGhBKKaXy5PYBISKfiMhxEdlqdS3KtYhIdRFZJiLbRWSbiIy2uiblWkTET0R+F5FN9u+xfxXp67v7HISItAPOA/8zxjS0uh7lOkSkKlDVGLNBREoD64E+xpjtFpemXISICBBgjDkvIt7AKmC0MWZtUby+259BGGNigVNW16FcjzHmqDFmg/3zc8AOIMTaqpQrMTbn7Q+97R9F9lu/2weEUneCiIQDTYHfrK1EuRoR8RSReOA4sNgYU2TfYxoQSjmZiAQC3wFjjDGpVtejXIsxJtMY0wQIBVqKSJENlWtAKOVE9nHh74AvjTHfW12Pcl3GmDPAMqB7Ub2mBoRSTmKfQPwY2GGMmWB1Pcr1iEiQiJSzf+4PdAF2FtXru31AiMjXwK9AHRE5JCJPWF2TchltgEeBTiISb//oYXVRyqVUBZaJyGZgHbY5iLlF9eJuf5mrUkqpvLn9GYRSSqm8aUAopZTKkwaEUkqpPGlAKKWUypMGhFJKqTxpQCh1AyKS6XCZaryIvFiErx2unYRVceVldQFKlQCX7K0MlHIregah1C0SkX0i8paIbLH35K9t3x4uIr+IyGYRWSoiYfbtlUXkB3vv/k0i0tr+Up4iMt3ez3+R/Y5YRGSUfS2JzSIyw6IvU7kxDQilbsz/miGmAQ7PnTXGNALeAybZt70LfG6MaQx8CUy2b58MrDDGRAPNgG327ZHAFGNMA+AM0Ne+/UWgqf11hjnri1MqP3ontVI3ICLnjTGBeWzfB3QyxiTam/IdM8ZUFJGT2BYKSrdvP2qMqSQiJ4BQY8xlh9cIx9YeIdL++AXA2xjzmogswLaY1WxgtkPff6XuCD2DUOr2mHw+vxmXHT7PJHdusCcwBdvZxjoR0TlDdUdpQCh1ewY4/Pmr/fM1wED75w8DK+2fLwWGQ84iL2Xze1ER8QCqG2OWAS8AZYHrzmKUcib9jUSpG/O3r9iVbYExJvtS1/L2TpqXgUH2bc8An4rI88AJ4HH79tHANHvH4ExsYXE0n/f0BL6wh4gAk+39/pW6Y3QOQqlbZJ+DiDHGnLS6FqWcQYeYlFJK5UnPIJRSSuVJzyCUUkrlSQNCKaVUnjQglFJK5UkDQimlVJ40IJRSSuXp/wOvU2WwVW+nUwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["\n","plt.figure()\n","plt.plot(epoch_list,training_loss_max, label=\"Training Loss Max Run\")\n","plt.plot(epoch_list,val_loss_max, label=\"Validation Loss Max Run\")\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.xticks(epoch_list)\n","plt.legend()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"3fH_e7Wt_kNP","executionInfo":{"status":"ok","timestamp":1644697857925,"user_tz":0,"elapsed":18,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"3f7ad097-84e3-4b02-d818-f1aaca46f226"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Distilbert Experiment HateTwit Baseline .ipynb","provenance":[{"file_id":"1A8y-Rv0ooUg6fzJ2bnYBJxBSaOEr3z9z","timestamp":1643754143701},{"file_id":"1-rZqxPTOtm21puGsZKK_FiKXeyCg7py7","timestamp":1643745856080},{"file_id":"15wylWRQJ1vxlP58OhBHUnY5fdagThMvJ","timestamp":1643406846637},{"file_id":"1B35hajBJY3fRQV7LSjqoqQ3xjdcyCzE3","timestamp":1642365829686},{"file_id":"1b0lCW2Cj6AULiE-Axh2OeZwURHR6pfcD","timestamp":1642333651961},{"file_id":"1RAjFaq-k9CLJQP5eO668UXLc0q-wjuve","timestamp":1642280213414},{"file_id":"1LzZr7GRN1SwVrNyjVX5t5PpCvio8w_kE","timestamp":1642109182548},{"file_id":"1t-qzEyxZtGn_Cnlfg2WtN-0dlgUmxfzx","timestamp":1641764210714},{"file_id":"14bEU8hCGPF8cVUA_BonJQA6Brv89DKUm","timestamp":1641252935713},{"file_id":"18Il3CpGf89tF1Z10iYX8OdfeHxxAX1Ui","timestamp":1639243141142},{"file_id":"1SHCgoRQVGtl9OiWEJGK3JgKkuxxSPy_5","timestamp":1639231968300},{"file_id":"1D-3yvF0nGnaWEZGxQj21R6fsGnyv5a5g","timestamp":1637526185003},{"file_id":"1glXr2JglKPUpN_3AGyk3GjfCtZSDNfsZ","timestamp":1637408594851},{"file_id":"1rc5hX8PBIv7GKvlxLQ35Vwf2jxLsv9f4","timestamp":1634501666668}],"background_execution":"on","mount_file_id":"1STrl8D_SltHJ1NdJG0TjnfyyiceDn_Gi","authorship_tag":"ABX9TyMVpJfgFKLXDtg2E788uiqG"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}