{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":26641,"status":"ok","timestamp":1644777706877,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"},"user_tz":0},"id":"F-o6bXOJ18j4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f1351bf3-b2ca-49bf-ba4a-7ca03442ba48"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 3.5 MB 7.0 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 61.3 MB/s \n","\u001b[K     |████████████████████████████████| 6.8 MB 51.7 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 68.3 MB/s \n","\u001b[K     |████████████████████████████████| 67 kB 4.8 MB/s \n","\u001b[K     |████████████████████████████████| 311 kB 8.1 MB/s \n","\u001b[K     |████████████████████████████████| 133 kB 39.8 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 15.1 MB/s \n","\u001b[K     |████████████████████████████████| 243 kB 7.2 MB/s \n","\u001b[K     |████████████████████████████████| 144 kB 49.2 MB/s \n","\u001b[K     |████████████████████████████████| 94 kB 3.1 MB/s \n","\u001b[K     |████████████████████████████████| 271 kB 39.9 MB/s \n","\u001b[?25h"]}],"source":["!pip install -qq transformers\n","!pip install -qq datasets"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Rz6wNlu92ge_","executionInfo":{"status":"ok","timestamp":1644777718708,"user_tz":0,"elapsed":11837,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["import transformers\n","import datasets\n","from transformers import AutoTokenizer,AutoModelForQuestionAnswering, AutoModelForSequenceClassification,AdamW, get_linear_schedule_with_warmup,Trainer, TrainingArguments\n","from transformers import DataCollator, DataCollatorForLanguageModeling,default_data_collator\n","from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n","import torch\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from pylab import rcParams\n","import matplotlib.pyplot as plt\n","from matplotlib import rc\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, classification_report\n","from collections import defaultdict\n","import random\n","from textwrap import wrap\n","from datetime import datetime\n","from datasets import load_from_disk\n","from datasets import load_dataset\n","from datasets import Dataset\n","from sklearn.metrics import accuracy_score,classification_report, confusion_matrix\n","from sklearn.metrics import precision_recall_fscore_support"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"T7IFr4-3TKaA","executionInfo":{"status":"ok","timestamp":1644767152563,"user_tz":0,"elapsed":11,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["# the model we gonna train, base uncased BERT\n","# check text classification models here: https://huggingface.co/models?filter=text-classification\n","MODEL_NAME = \"distilbert-base-uncased\"\n","# max sequence length for each document/sentence sample\n","BATCH_SIZE = 64\n","EPOCHS = 4\n","LEARNING_RATE= 8.584684132528283e-05\n","WEIGHT_DECAY = 0.10919253165395515\n","WARMUP_STEPS = 50\n","RANDOM_SEED=32\n","\n","\n","\n","\n","QA_OUTPUT_PATH= \"/content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad\"\n","\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"YoKXcvyo_X47","executionInfo":{"status":"ok","timestamp":1644767152564,"user_tz":0,"elapsed":11,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["def set_seed(seed):\n","    \"\"\"Set all seeds to make results reproducible (deterministic mode).\n","       When seed is None, disables deterministic mode.\n","    :param seed: an integer to your choosing\n","    \"\"\"\n","    if seed is not None:\n","        torch.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","        np.random.seed(seed)\n","        random.seed(seed)\n","\n","def compute_metrics(pred):\n","  labels = pred.label_ids\n","  preds = pred.predictions.argmax(-1)\n","  # calculate accuracy using sklearn's function\n","  acc = accuracy_score(labels, preds)\n","  precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n","  acc = accuracy_score(labels, preds)\n","  confusion_matrix = classification_report(labels, preds, digits=4,output_dict=True)\n","  return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall,\n","        'hate_f1': confusion_matrix[\"0\"][\"f1-score\"],\n","        'hate_recall': confusion_matrix[\"0\"][\"recall\"],\n","        'hate_precision': confusion_matrix[\"0\"][\"precision\"],\n","        'offensive_f1': confusion_matrix[\"1\"][\"f1-score\"],\n","        'offensive_recall': confusion_matrix[\"1\"][\"recall\"],\n","        'offensive_precision': confusion_matrix[\"1\"][\"precision\"],\n","        'normal_f1': confusion_matrix[\"2\"][\"f1-score\"],\n","        'normal_recall': confusion_matrix[\"2\"][\"recall\"],\n","        'normal_precision': confusion_matrix[\"2\"][\"precision\"],    \n","  }\n","\n","\n","def seq_model_init(modelname_or_path):\n","  temp_model =  AutoModelForSequenceClassification.from_pretrained(modelname_or_path,num_labels=3).to(device)\n","  return temp_model\n","\n","\n","def timestamp():\n","    dateTimeObj = datetime.now()\n","    timestampStr = dateTimeObj.strftime(\"%d-%b-%Y (%H:%M:%S.%f)\")\n","    print(timestampStr)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"lqKiS7jbkC4x","executionInfo":{"status":"ok","timestamp":1644767152565,"user_tz":0,"elapsed":10,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["set_seed(RANDOM_SEED)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"jo4n81tx6lbr","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1644770442267,"user_tz":0,"elapsed":3211270,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"632e201c-0e93-41f0-899f-d30b1b1b76fe"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad were not used when initializing DistilBertForSequenceClassification: ['qa_outputs.bias', 'qa_outputs.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2332\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2332' max='2332' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2332/2332 05:06, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.669700</td>\n","      <td>0.540339</td>\n","      <td>0.779352</td>\n","      <td>0.727934</td>\n","      <td>0.735986</td>\n","      <td>0.721026</td>\n","      <td>0.706436</td>\n","      <td>0.679074</td>\n","      <td>0.736096</td>\n","      <td>0.860355</td>\n","      <td>0.878193</td>\n","      <td>0.843228</td>\n","      <td>0.617010</td>\n","      <td>0.605809</td>\n","      <td>0.628633</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.493400</td>\n","      <td>0.496043</td>\n","      <td>0.797381</td>\n","      <td>0.743964</td>\n","      <td>0.763380</td>\n","      <td>0.740435</td>\n","      <td>0.756656</td>\n","      <td>0.814889</td>\n","      <td>0.706190</td>\n","      <td>0.869989</td>\n","      <td>0.891892</td>\n","      <td>0.849136</td>\n","      <td>0.605247</td>\n","      <td>0.514523</td>\n","      <td>0.734815</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.364700</td>\n","      <td>0.540804</td>\n","      <td>0.807255</td>\n","      <td>0.766131</td>\n","      <td>0.765314</td>\n","      <td>0.769599</td>\n","      <td>0.777936</td>\n","      <td>0.822938</td>\n","      <td>0.737601</td>\n","      <td>0.873397</td>\n","      <td>0.869678</td>\n","      <td>0.877147</td>\n","      <td>0.647059</td>\n","      <td>0.616183</td>\n","      <td>0.681193</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.251000</td>\n","      <td>0.642853</td>\n","      <td>0.804894</td>\n","      <td>0.764948</td>\n","      <td>0.761572</td>\n","      <td>0.769597</td>\n","      <td>0.784993</td>\n","      <td>0.820926</td>\n","      <td>0.752074</td>\n","      <td>0.871124</td>\n","      <td>0.863384</td>\n","      <td>0.879005</td>\n","      <td>0.638727</td>\n","      <td>0.624481</td>\n","      <td>0.653637</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/1/checkpoint-583\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/1/checkpoint-583/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/1/checkpoint-583/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/1/checkpoint-1166\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/1/checkpoint-1166/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/1/checkpoint-1166/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/1/checkpoint-1749\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/1/checkpoint-1749/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/1/checkpoint-1749/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/1/checkpoint-2332\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/1/checkpoint-2332/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/1/checkpoint-2332/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_task/results/1/checkpoint-1166 (score: 0.4960433840751648).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_1\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_1/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_1/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 64\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [73/73 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/config.json\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForQuestionAnswering\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad were not used when initializing DistilBertForSequenceClassification: ['qa_outputs.bias', 'qa_outputs.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2332\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2332' max='2332' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2332/2332 05:06, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.652800</td>\n","      <td>0.552738</td>\n","      <td>0.772913</td>\n","      <td>0.706633</td>\n","      <td>0.747951</td>\n","      <td>0.687188</td>\n","      <td>0.714583</td>\n","      <td>0.690141</td>\n","      <td>0.740821</td>\n","      <td>0.851935</td>\n","      <td>0.917068</td>\n","      <td>0.795440</td>\n","      <td>0.553380</td>\n","      <td>0.454357</td>\n","      <td>0.707593</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.494400</td>\n","      <td>0.521265</td>\n","      <td>0.795879</td>\n","      <td>0.746498</td>\n","      <td>0.757306</td>\n","      <td>0.755060</td>\n","      <td>0.748151</td>\n","      <td>0.865191</td>\n","      <td>0.659004</td>\n","      <td>0.871354</td>\n","      <td>0.862643</td>\n","      <td>0.880242</td>\n","      <td>0.619988</td>\n","      <td>0.537344</td>\n","      <td>0.732673</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.360500</td>\n","      <td>0.535443</td>\n","      <td>0.806182</td>\n","      <td>0.768316</td>\n","      <td>0.764642</td>\n","      <td>0.772283</td>\n","      <td>0.788566</td>\n","      <td>0.804829</td>\n","      <td>0.772947</td>\n","      <td>0.871354</td>\n","      <td>0.862643</td>\n","      <td>0.880242</td>\n","      <td>0.645028</td>\n","      <td>0.649378</td>\n","      <td>0.640737</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.242500</td>\n","      <td>0.622315</td>\n","      <td>0.809187</td>\n","      <td>0.768819</td>\n","      <td>0.764425</td>\n","      <td>0.775001</td>\n","      <td>0.794090</td>\n","      <td>0.838028</td>\n","      <td>0.754529</td>\n","      <td>0.876148</td>\n","      <td>0.865605</td>\n","      <td>0.886950</td>\n","      <td>0.636219</td>\n","      <td>0.621369</td>\n","      <td>0.651795</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/2/checkpoint-583\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/2/checkpoint-583/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/2/checkpoint-583/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/2/checkpoint-1166\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/2/checkpoint-1166/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/2/checkpoint-1166/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/2/checkpoint-1749\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/2/checkpoint-1749/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/2/checkpoint-1749/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/2/checkpoint-2332\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/2/checkpoint-2332/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/2/checkpoint-2332/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_task/results/2/checkpoint-1166 (score: 0.5212645530700684).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_2\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_2/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_2/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 64\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [73/73 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/config.json\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForQuestionAnswering\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad were not used when initializing DistilBertForSequenceClassification: ['qa_outputs.bias', 'qa_outputs.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2332\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2332' max='2332' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2332/2332 05:06, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.655700</td>\n","      <td>0.550199</td>\n","      <td>0.773771</td>\n","      <td>0.715833</td>\n","      <td>0.735566</td>\n","      <td>0.705708</td>\n","      <td>0.698318</td>\n","      <td>0.710262</td>\n","      <td>0.686770</td>\n","      <td>0.854649</td>\n","      <td>0.888190</td>\n","      <td>0.823550</td>\n","      <td>0.594530</td>\n","      <td>0.518672</td>\n","      <td>0.696379</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.480700</td>\n","      <td>0.519811</td>\n","      <td>0.794806</td>\n","      <td>0.734991</td>\n","      <td>0.764251</td>\n","      <td>0.728280</td>\n","      <td>0.768501</td>\n","      <td>0.814889</td>\n","      <td>0.727110</td>\n","      <td>0.867945</td>\n","      <td>0.905220</td>\n","      <td>0.833617</td>\n","      <td>0.568528</td>\n","      <td>0.464730</td>\n","      <td>0.732026</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.351700</td>\n","      <td>0.549562</td>\n","      <td>0.807040</td>\n","      <td>0.766435</td>\n","      <td>0.766717</td>\n","      <td>0.766360</td>\n","      <td>0.792640</td>\n","      <td>0.801811</td>\n","      <td>0.783677</td>\n","      <td>0.873083</td>\n","      <td>0.874861</td>\n","      <td>0.871313</td>\n","      <td>0.633580</td>\n","      <td>0.622407</td>\n","      <td>0.645161</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.231100</td>\n","      <td>0.666835</td>\n","      <td>0.804464</td>\n","      <td>0.766715</td>\n","      <td>0.761318</td>\n","      <td>0.772748</td>\n","      <td>0.792176</td>\n","      <td>0.814889</td>\n","      <td>0.770695</td>\n","      <td>0.870628</td>\n","      <td>0.857090</td>\n","      <td>0.884601</td>\n","      <td>0.637340</td>\n","      <td>0.646266</td>\n","      <td>0.628658</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/3/checkpoint-583\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/3/checkpoint-583/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/3/checkpoint-583/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/3/checkpoint-1166\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/3/checkpoint-1166/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/3/checkpoint-1166/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/3/checkpoint-1749\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/3/checkpoint-1749/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/3/checkpoint-1749/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/3/checkpoint-2332\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/3/checkpoint-2332/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/3/checkpoint-2332/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_task/results/3/checkpoint-1166 (score: 0.5198111534118652).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_3\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_3/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_3/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 64\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [73/73 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/config.json\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForQuestionAnswering\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad were not used when initializing DistilBertForSequenceClassification: ['qa_outputs.bias', 'qa_outputs.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2332\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2332' max='2332' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2332/2332 05:06, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.660900</td>\n","      <td>0.552437</td>\n","      <td>0.773342</td>\n","      <td>0.706868</td>\n","      <td>0.756376</td>\n","      <td>0.689527</td>\n","      <td>0.723618</td>\n","      <td>0.724346</td>\n","      <td>0.722892</td>\n","      <td>0.849131</td>\n","      <td>0.913736</td>\n","      <td>0.793059</td>\n","      <td>0.547855</td>\n","      <td>0.430498</td>\n","      <td>0.753176</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.480200</td>\n","      <td>0.516062</td>\n","      <td>0.795235</td>\n","      <td>0.754446</td>\n","      <td>0.753198</td>\n","      <td>0.763202</td>\n","      <td>0.776011</td>\n","      <td>0.859155</td>\n","      <td>0.707539</td>\n","      <td>0.859396</td>\n","      <td>0.847464</td>\n","      <td>0.871668</td>\n","      <td>0.627933</td>\n","      <td>0.582988</td>\n","      <td>0.680387</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.346400</td>\n","      <td>0.526239</td>\n","      <td>0.809187</td>\n","      <td>0.764836</td>\n","      <td>0.769958</td>\n","      <td>0.765706</td>\n","      <td>0.804924</td>\n","      <td>0.855131</td>\n","      <td>0.760286</td>\n","      <td>0.872707</td>\n","      <td>0.880785</td>\n","      <td>0.864776</td>\n","      <td>0.616876</td>\n","      <td>0.561203</td>\n","      <td>0.684810</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.234700</td>\n","      <td>0.667931</td>\n","      <td>0.805108</td>\n","      <td>0.765341</td>\n","      <td>0.763014</td>\n","      <td>0.768494</td>\n","      <td>0.804475</td>\n","      <td>0.831992</td>\n","      <td>0.778719</td>\n","      <td>0.869468</td>\n","      <td>0.865605</td>\n","      <td>0.873366</td>\n","      <td>0.622081</td>\n","      <td>0.607884</td>\n","      <td>0.636957</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/4/checkpoint-583\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/4/checkpoint-583/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/4/checkpoint-583/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/4/checkpoint-1166\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/4/checkpoint-1166/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/4/checkpoint-1166/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/4/checkpoint-1749\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/4/checkpoint-1749/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/4/checkpoint-1749/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/4/checkpoint-2332\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/4/checkpoint-2332/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/4/checkpoint-2332/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_task/results/4/checkpoint-1166 (score: 0.5160619020462036).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_4\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_4/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_4/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 64\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [73/73 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/config.json\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForQuestionAnswering\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad were not used when initializing DistilBertForSequenceClassification: ['qa_outputs.bias', 'qa_outputs.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2332\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2332' max='2332' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2332/2332 05:05, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.651100</td>\n","      <td>0.545049</td>\n","      <td>0.776991</td>\n","      <td>0.719815</td>\n","      <td>0.744356</td>\n","      <td>0.707295</td>\n","      <td>0.708229</td>\n","      <td>0.714286</td>\n","      <td>0.702275</td>\n","      <td>0.854111</td>\n","      <td>0.894113</td>\n","      <td>0.817536</td>\n","      <td>0.597105</td>\n","      <td>0.513485</td>\n","      <td>0.713256</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.477900</td>\n","      <td>0.492314</td>\n","      <td>0.798669</td>\n","      <td>0.757496</td>\n","      <td>0.752923</td>\n","      <td>0.763610</td>\n","      <td>0.755131</td>\n","      <td>0.795775</td>\n","      <td>0.718438</td>\n","      <td>0.869647</td>\n","      <td>0.857090</td>\n","      <td>0.882577</td>\n","      <td>0.647709</td>\n","      <td>0.637967</td>\n","      <td>0.657754</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.350600</td>\n","      <td>0.523007</td>\n","      <td>0.814552</td>\n","      <td>0.776192</td>\n","      <td>0.770871</td>\n","      <td>0.782436</td>\n","      <td>0.794004</td>\n","      <td>0.825956</td>\n","      <td>0.764432</td>\n","      <td>0.880706</td>\n","      <td>0.867827</td>\n","      <td>0.893974</td>\n","      <td>0.653866</td>\n","      <td>0.653527</td>\n","      <td>0.654206</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.224800</td>\n","      <td>0.644025</td>\n","      <td>0.807469</td>\n","      <td>0.764613</td>\n","      <td>0.762699</td>\n","      <td>0.767711</td>\n","      <td>0.792453</td>\n","      <td>0.823944</td>\n","      <td>0.763281</td>\n","      <td>0.876789</td>\n","      <td>0.873380</td>\n","      <td>0.880224</td>\n","      <td>0.624599</td>\n","      <td>0.605809</td>\n","      <td>0.644592</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/5/checkpoint-583\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/5/checkpoint-583/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/5/checkpoint-583/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/5/checkpoint-1166\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/5/checkpoint-1166/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/5/checkpoint-1166/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/5/checkpoint-1749\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/5/checkpoint-1749/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/5/checkpoint-1749/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/5/checkpoint-2332\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/5/checkpoint-2332/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/5/checkpoint-2332/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_task/results/5/checkpoint-1166 (score: 0.49231410026550293).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_5\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_5/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_5/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 64\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [73/73 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/config.json\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForQuestionAnswering\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad were not used when initializing DistilBertForSequenceClassification: ['qa_outputs.bias', 'qa_outputs.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2332\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2332' max='2332' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2332/2332 05:05, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.658400</td>\n","      <td>0.543349</td>\n","      <td>0.782786</td>\n","      <td>0.734582</td>\n","      <td>0.739579</td>\n","      <td>0.733676</td>\n","      <td>0.726925</td>\n","      <td>0.764588</td>\n","      <td>0.692799</td>\n","      <td>0.857720</td>\n","      <td>0.864865</td>\n","      <td>0.850692</td>\n","      <td>0.619101</td>\n","      <td>0.571577</td>\n","      <td>0.675245</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.483900</td>\n","      <td>0.510265</td>\n","      <td>0.795664</td>\n","      <td>0.753122</td>\n","      <td>0.750752</td>\n","      <td>0.760013</td>\n","      <td>0.761242</td>\n","      <td>0.825956</td>\n","      <td>0.705933</td>\n","      <td>0.865392</td>\n","      <td>0.854498</td>\n","      <td>0.876567</td>\n","      <td>0.632731</td>\n","      <td>0.599585</td>\n","      <td>0.669757</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.357400</td>\n","      <td>0.549946</td>\n","      <td>0.808328</td>\n","      <td>0.763730</td>\n","      <td>0.771388</td>\n","      <td>0.763093</td>\n","      <td>0.796209</td>\n","      <td>0.845070</td>\n","      <td>0.752688</td>\n","      <td>0.871711</td>\n","      <td>0.883006</td>\n","      <td>0.860700</td>\n","      <td>0.623272</td>\n","      <td>0.561203</td>\n","      <td>0.700777</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.236200</td>\n","      <td>0.656167</td>\n","      <td>0.801030</td>\n","      <td>0.761986</td>\n","      <td>0.757712</td>\n","      <td>0.766920</td>\n","      <td>0.794747</td>\n","      <td>0.821932</td>\n","      <td>0.769303</td>\n","      <td>0.866929</td>\n","      <td>0.857460</td>\n","      <td>0.876609</td>\n","      <td>0.624283</td>\n","      <td>0.621369</td>\n","      <td>0.627225</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/6/checkpoint-583\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/6/checkpoint-583/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/6/checkpoint-583/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/6/checkpoint-1166\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/6/checkpoint-1166/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/6/checkpoint-1166/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/6/checkpoint-1749\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/6/checkpoint-1749/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/6/checkpoint-1749/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/6/checkpoint-2332\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/6/checkpoint-2332/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/6/checkpoint-2332/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_task/results/6/checkpoint-1166 (score: 0.5102648735046387).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_6\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_6/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_6/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 64\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [73/73 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/config.json\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForQuestionAnswering\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad were not used when initializing DistilBertForSequenceClassification: ['qa_outputs.bias', 'qa_outputs.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2332\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2332' max='2332' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2332/2332 05:06, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.658700</td>\n","      <td>0.538534</td>\n","      <td>0.786220</td>\n","      <td>0.735913</td>\n","      <td>0.745305</td>\n","      <td>0.732496</td>\n","      <td>0.734262</td>\n","      <td>0.768612</td>\n","      <td>0.702852</td>\n","      <td>0.860833</td>\n","      <td>0.875972</td>\n","      <td>0.846209</td>\n","      <td>0.612644</td>\n","      <td>0.552905</td>\n","      <td>0.686856</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.474100</td>\n","      <td>0.494381</td>\n","      <td>0.805323</td>\n","      <td>0.752635</td>\n","      <td>0.783322</td>\n","      <td>0.743031</td>\n","      <td>0.771142</td>\n","      <td>0.811871</td>\n","      <td>0.734304</td>\n","      <td>0.871959</td>\n","      <td>0.908923</td>\n","      <td>0.837884</td>\n","      <td>0.614806</td>\n","      <td>0.508299</td>\n","      <td>0.777778</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.344000</td>\n","      <td>0.554329</td>\n","      <td>0.808328</td>\n","      <td>0.764424</td>\n","      <td>0.766410</td>\n","      <td>0.767572</td>\n","      <td>0.785547</td>\n","      <td>0.842052</td>\n","      <td>0.736148</td>\n","      <td>0.875440</td>\n","      <td>0.875602</td>\n","      <td>0.875278</td>\n","      <td>0.632287</td>\n","      <td>0.585062</td>\n","      <td>0.687805</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.209400</td>\n","      <td>0.660640</td>\n","      <td>0.808972</td>\n","      <td>0.768862</td>\n","      <td>0.766302</td>\n","      <td>0.772216</td>\n","      <td>0.788144</td>\n","      <td>0.815895</td>\n","      <td>0.762218</td>\n","      <td>0.875396</td>\n","      <td>0.870048</td>\n","      <td>0.880810</td>\n","      <td>0.643046</td>\n","      <td>0.630705</td>\n","      <td>0.655879</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/7/checkpoint-583\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/7/checkpoint-583/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/7/checkpoint-583/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/7/checkpoint-1166\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/7/checkpoint-1166/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/7/checkpoint-1166/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/7/checkpoint-1749\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/7/checkpoint-1749/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/7/checkpoint-1749/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/7/checkpoint-2332\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/7/checkpoint-2332/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/7/checkpoint-2332/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_task/results/7/checkpoint-1166 (score: 0.49438104033470154).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_7\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_7/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_7/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 64\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [73/73 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/config.json\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForQuestionAnswering\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad were not used when initializing DistilBertForSequenceClassification: ['qa_outputs.bias', 'qa_outputs.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2332\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2332' max='2332' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2332/2332 05:01, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.654600</td>\n","      <td>0.555022</td>\n","      <td>0.784288</td>\n","      <td>0.735363</td>\n","      <td>0.740940</td>\n","      <td>0.734446</td>\n","      <td>0.734129</td>\n","      <td>0.773642</td>\n","      <td>0.698456</td>\n","      <td>0.859186</td>\n","      <td>0.867456</td>\n","      <td>0.851072</td>\n","      <td>0.612776</td>\n","      <td>0.562241</td>\n","      <td>0.673292</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.476900</td>\n","      <td>0.513554</td>\n","      <td>0.794806</td>\n","      <td>0.753464</td>\n","      <td>0.758568</td>\n","      <td>0.749191</td>\n","      <td>0.756136</td>\n","      <td>0.728370</td>\n","      <td>0.786102</td>\n","      <td>0.863270</td>\n","      <td>0.871899</td>\n","      <td>0.854809</td>\n","      <td>0.640986</td>\n","      <td>0.647303</td>\n","      <td>0.634791</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.339100</td>\n","      <td>0.566037</td>\n","      <td>0.807040</td>\n","      <td>0.762140</td>\n","      <td>0.767684</td>\n","      <td>0.762002</td>\n","      <td>0.791052</td>\n","      <td>0.836016</td>\n","      <td>0.750678</td>\n","      <td>0.872641</td>\n","      <td>0.881525</td>\n","      <td>0.863933</td>\n","      <td>0.622727</td>\n","      <td>0.568465</td>\n","      <td>0.688442</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.221100</td>\n","      <td>0.689058</td>\n","      <td>0.808972</td>\n","      <td>0.771492</td>\n","      <td>0.768270</td>\n","      <td>0.774937</td>\n","      <td>0.796443</td>\n","      <td>0.810865</td>\n","      <td>0.782524</td>\n","      <td>0.873040</td>\n","      <td>0.865605</td>\n","      <td>0.880603</td>\n","      <td>0.644995</td>\n","      <td>0.648340</td>\n","      <td>0.641684</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/8/checkpoint-583\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/8/checkpoint-583/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/8/checkpoint-583/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/8/checkpoint-1166\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/8/checkpoint-1166/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/8/checkpoint-1166/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/8/checkpoint-1749\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/8/checkpoint-1749/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/8/checkpoint-1749/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/8/checkpoint-2332\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/8/checkpoint-2332/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/8/checkpoint-2332/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_task/results/8/checkpoint-1166 (score: 0.5135542750358582).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_8\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_8/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_8/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 64\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [73/73 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/config.json\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForQuestionAnswering\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad were not used when initializing DistilBertForSequenceClassification: ['qa_outputs.bias', 'qa_outputs.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2332\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2332' max='2332' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2332/2332 05:01, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.644000</td>\n","      <td>0.552100</td>\n","      <td>0.766259</td>\n","      <td>0.715114</td>\n","      <td>0.727958</td>\n","      <td>0.705173</td>\n","      <td>0.682801</td>\n","      <td>0.667002</td>\n","      <td>0.699367</td>\n","      <td>0.842539</td>\n","      <td>0.869678</td>\n","      <td>0.817043</td>\n","      <td>0.620000</td>\n","      <td>0.578838</td>\n","      <td>0.667464</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.467600</td>\n","      <td>0.502205</td>\n","      <td>0.798025</td>\n","      <td>0.750132</td>\n","      <td>0.761325</td>\n","      <td>0.750158</td>\n","      <td>0.771375</td>\n","      <td>0.835010</td>\n","      <td>0.716753</td>\n","      <td>0.865546</td>\n","      <td>0.877083</td>\n","      <td>0.854309</td>\n","      <td>0.613475</td>\n","      <td>0.538382</td>\n","      <td>0.712912</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.331800</td>\n","      <td>0.566286</td>\n","      <td>0.804679</td>\n","      <td>0.765938</td>\n","      <td>0.764516</td>\n","      <td>0.767524</td>\n","      <td>0.803368</td>\n","      <td>0.815895</td>\n","      <td>0.791220</td>\n","      <td>0.868597</td>\n","      <td>0.866346</td>\n","      <td>0.870860</td>\n","      <td>0.625850</td>\n","      <td>0.620332</td>\n","      <td>0.631468</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.212800</td>\n","      <td>0.690503</td>\n","      <td>0.802962</td>\n","      <td>0.766851</td>\n","      <td>0.762247</td>\n","      <td>0.771884</td>\n","      <td>0.799605</td>\n","      <td>0.814889</td>\n","      <td>0.784884</td>\n","      <td>0.866204</td>\n","      <td>0.854498</td>\n","      <td>0.878234</td>\n","      <td>0.634743</td>\n","      <td>0.646266</td>\n","      <td>0.623624</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/9/checkpoint-583\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/9/checkpoint-583/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/9/checkpoint-583/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/9/checkpoint-1166\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/9/checkpoint-1166/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/9/checkpoint-1166/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/9/checkpoint-1749\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/9/checkpoint-1749/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/9/checkpoint-1749/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/9/checkpoint-2332\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/9/checkpoint-2332/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/9/checkpoint-2332/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_task/results/9/checkpoint-1166 (score: 0.5022048354148865).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_9\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_9/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_9/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 64\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [73/73 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/config.json\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForQuestionAnswering\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad were not used when initializing DistilBertForSequenceClassification: ['qa_outputs.bias', 'qa_outputs.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/Dissertation/disbert_hate_ml/results/best_model_squad and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2332\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2332' max='2332' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2332/2332 05:03, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.659400</td>\n","      <td>0.541565</td>\n","      <td>0.779566</td>\n","      <td>0.720245</td>\n","      <td>0.740460</td>\n","      <td>0.710822</td>\n","      <td>0.714848</td>\n","      <td>0.731388</td>\n","      <td>0.699038</td>\n","      <td>0.860755</td>\n","      <td>0.894854</td>\n","      <td>0.829160</td>\n","      <td>0.585132</td>\n","      <td>0.506224</td>\n","      <td>0.693182</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.481800</td>\n","      <td>0.503446</td>\n","      <td>0.794806</td>\n","      <td>0.751064</td>\n","      <td>0.753163</td>\n","      <td>0.749503</td>\n","      <td>0.753105</td>\n","      <td>0.762575</td>\n","      <td>0.743867</td>\n","      <td>0.865183</td>\n","      <td>0.870789</td>\n","      <td>0.859649</td>\n","      <td>0.634904</td>\n","      <td>0.615145</td>\n","      <td>0.655973</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.357200</td>\n","      <td>0.561501</td>\n","      <td>0.795235</td>\n","      <td>0.750122</td>\n","      <td>0.749454</td>\n","      <td>0.755256</td>\n","      <td>0.773259</td>\n","      <td>0.831992</td>\n","      <td>0.722271</td>\n","      <td>0.865811</td>\n","      <td>0.861163</td>\n","      <td>0.870509</td>\n","      <td>0.611296</td>\n","      <td>0.572614</td>\n","      <td>0.655582</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.239500</td>\n","      <td>0.649979</td>\n","      <td>0.804464</td>\n","      <td>0.763620</td>\n","      <td>0.764819</td>\n","      <td>0.763006</td>\n","      <td>0.797625</td>\n","      <td>0.810865</td>\n","      <td>0.784810</td>\n","      <td>0.869037</td>\n","      <td>0.873380</td>\n","      <td>0.864736</td>\n","      <td>0.624197</td>\n","      <td>0.604772</td>\n","      <td>0.644912</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/10/checkpoint-583\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/10/checkpoint-583/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/10/checkpoint-583/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/10/checkpoint-1166\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/10/checkpoint-1166/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/10/checkpoint-1166/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/10/checkpoint-1749\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/10/checkpoint-1749/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/10/checkpoint-1749/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/results/10/checkpoint-2332\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/10/checkpoint-2332/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/results/10/checkpoint-2332/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_task/results/10/checkpoint-1166 (score: 0.5034459233283997).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_10\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_10/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_10/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 64\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [73/73 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}],"source":["result_list = []\n","for i in range(1,11):\n","\n","  training_args = TrainingArguments(\n","    output_dir='/content/drive/MyDrive/Dissertation/disbert_hate_task/results/'+str(i),          # output directory\n","    num_train_epochs=EPOCHS,              # total number of training epochs\n","    save_strategy =\"epoch\" ,\n","    per_device_train_batch_size=BATCH_SIZE,  # batch size per device during training\n","    per_device_eval_batch_size=BATCH_SIZE,   # batch size for evaluation\n","    weight_decay= WEIGHT_DECAY,               # strength of weight decay\n","    learning_rate= LEARNING_RATE, \n","    warmup_steps = WARMUP_STEPS,\n","    logging_dir='./disbert_hate_task/logs',     # directory for storing logs\n","    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n","    evaluation_strategy=\"epoch\",\n","  )\n","\n","  hatetwit_dataset_dfs = load_from_disk('/content/drive/MyDrive/Dissertation/datasets/hatetwit_'+str(i))\n","  train_dataset = hatetwit_dataset_dfs [\"train\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","  eval_dataset = hatetwit_dataset_dfs [\"validation\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","  test_dataset = hatetwit_dataset_dfs [\"test\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","  seq_model = seq_model_init(QA_OUTPUT_PATH)\n","\n","  trainer = Trainer(\n","      model=seq_model,                         # the instantiated Transformers model to be trained\n","      args=training_args,                  # training arguments, defined above\n","      train_dataset= train_dataset,         # training dataset\n","      eval_dataset=eval_dataset,          # evaluation dataset\n","      compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n","  )\n","  trainer.train()\n","  trainer.save_model('/content/drive/MyDrive/Dissertation/disbert_hate_task/models/model_'+str(i))\n","  results = trainer.evaluate(test_dataset)\n","  results[\"model_run\"] = i\n","  result_list.append(results)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"khwJ-nkJrtka","executionInfo":{"status":"ok","timestamp":1644771101412,"user_tz":0,"elapsed":1489,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["results_df = pd.DataFrame(result_list)\n","results_df.to_csv('/content/drive/MyDrive/Dissertation/results/distilbert_task.csv')"]},{"cell_type":"code","source":["results_df = results_df.sort_values(by=['eval_f1'])\n","#Print min values\n","results_df.head(1)"],"metadata":{"id":"PON0aGtf78Aw","colab":{"base_uri":"https://localhost:8080/","height":145},"executionInfo":{"status":"ok","timestamp":1644771104982,"user_tz":0,"elapsed":343,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"e6cb1e81-526e-4cd6-b57a-7355b9a6550a"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-bb651c39-8af9-4bec-b54f-1c027e8029f6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eval_loss</th>\n","      <th>eval_accuracy</th>\n","      <th>eval_f1</th>\n","      <th>eval_precision</th>\n","      <th>eval_recall</th>\n","      <th>eval_hate_f1</th>\n","      <th>eval_hate_recall</th>\n","      <th>eval_hate_precision</th>\n","      <th>eval_offensive_f1</th>\n","      <th>eval_offensive_recall</th>\n","      <th>eval_offensive_precision</th>\n","      <th>eval_normal_f1</th>\n","      <th>eval_normal_recall</th>\n","      <th>eval_normal_precision</th>\n","      <th>eval_runtime</th>\n","      <th>eval_samples_per_second</th>\n","      <th>eval_steps_per_second</th>\n","      <th>epoch</th>\n","      <th>model_run</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4</th>\n","      <td>0.529357</td>\n","      <td>0.785316</td>\n","      <td>0.742649</td>\n","      <td>0.737345</td>\n","      <td>0.749163</td>\n","      <td>0.754445</td>\n","      <td>0.790534</td>\n","      <td>0.721507</td>\n","      <td>0.85924</td>\n","      <td>0.845556</td>\n","      <td>0.873374</td>\n","      <td>0.614263</td>\n","      <td>0.611399</td>\n","      <td>0.617155</td>\n","      <td>3.1729</td>\n","      <td>1468.063</td>\n","      <td>23.007</td>\n","      <td>4.0</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb651c39-8af9-4bec-b54f-1c027e8029f6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bb651c39-8af9-4bec-b54f-1c027e8029f6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bb651c39-8af9-4bec-b54f-1c027e8029f6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   eval_loss  eval_accuracy   eval_f1  ...  eval_steps_per_second  epoch  model_run\n","4   0.529357       0.785316  0.742649  ...                 23.007    4.0          5\n","\n","[1 rows x 19 columns]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["#Print max values \n","results_df.tail(1)"],"metadata":{"id":"KXAQOU-_79fl","colab":{"base_uri":"https://localhost:8080/","height":145},"executionInfo":{"status":"ok","timestamp":1644771108011,"user_tz":0,"elapsed":335,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"ef236009-d783-4f64-99bf-2fe0e48a3f4e"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-d83f684f-dbd7-4383-a471-6626c87338e7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eval_loss</th>\n","      <th>eval_accuracy</th>\n","      <th>eval_f1</th>\n","      <th>eval_precision</th>\n","      <th>eval_recall</th>\n","      <th>eval_hate_f1</th>\n","      <th>eval_hate_recall</th>\n","      <th>eval_hate_precision</th>\n","      <th>eval_offensive_f1</th>\n","      <th>eval_offensive_recall</th>\n","      <th>eval_offensive_precision</th>\n","      <th>eval_normal_f1</th>\n","      <th>eval_normal_recall</th>\n","      <th>eval_normal_precision</th>\n","      <th>eval_runtime</th>\n","      <th>eval_samples_per_second</th>\n","      <th>eval_steps_per_second</th>\n","      <th>epoch</th>\n","      <th>model_run</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>0.506378</td>\n","      <td>0.805496</td>\n","      <td>0.764829</td>\n","      <td>0.764612</td>\n","      <td>0.773048</td>\n","      <td>0.766652</td>\n","      <td>0.851964</td>\n","      <td>0.69687</td>\n","      <td>0.871968</td>\n","      <td>0.858889</td>\n","      <td>0.885452</td>\n","      <td>0.655866</td>\n","      <td>0.60829</td>\n","      <td>0.711515</td>\n","      <td>3.1773</td>\n","      <td>1466.031</td>\n","      <td>22.976</td>\n","      <td>4.0</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d83f684f-dbd7-4383-a471-6626c87338e7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d83f684f-dbd7-4383-a471-6626c87338e7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d83f684f-dbd7-4383-a471-6626c87338e7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   eval_loss  eval_accuracy   eval_f1  ...  eval_steps_per_second  epoch  model_run\n","3   0.506378       0.805496  0.764829  ...                 22.976    4.0          4\n","\n","[1 rows x 19 columns]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["#Print median f1\n","results_df[\"eval_f1\"].median()"],"metadata":{"id":"ZQlZh0nM7_EN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644771110170,"user_tz":0,"elapsed":376,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"ba3616c4-4cc5-4ef3-92fc-5c5f661fa268"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7456612144989003"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["#Print average values\n","results_df.mean()"],"metadata":{"id":"eeoLBsH_8Ac1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644771111705,"user_tz":0,"elapsed":3,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"18e7b5bc-f517-4399-dcf9-395596fa764d"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["eval_loss                      0.510480\n","eval_accuracy                  0.796780\n","eval_f1                        0.748721\n","eval_precision                 0.759284\n","eval_recall                    0.749382\n","eval_hate_f1                   0.761477\n","eval_hate_recall               0.813797\n","eval_hate_precision            0.717901\n","eval_offensive_f1              0.867881\n","eval_offensive_recall          0.875593\n","eval_offensive_precision       0.861053\n","eval_normal_f1                 0.616806\n","eval_normal_recall             0.558756\n","eval_normal_precision          0.698897\n","eval_runtime                   3.173450\n","eval_samples_per_second     1467.947100\n","eval_steps_per_second         23.005600\n","epoch                          4.000000\n","model_run                      5.500000\n","dtype: float64"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["results_df.std()"],"metadata":{"id":"zaHeUgYd8CNR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644771113924,"user_tz":0,"elapsed":319,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"2b6ba286-c1f2-49a6-bb0e-3fa59b3964cb"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["eval_loss                    0.011077\n","eval_accuracy                0.006815\n","eval_f1                      0.007371\n","eval_precision               0.013542\n","eval_recall                  0.011175\n","eval_hate_f1                 0.007950\n","eval_hate_recall             0.038525\n","eval_hate_precision          0.032722\n","eval_offensive_f1            0.006199\n","eval_offensive_recall        0.023427\n","eval_offensive_precision     0.016646\n","eval_normal_f1               0.019583\n","eval_normal_recall           0.055521\n","eval_normal_precision        0.055624\n","eval_runtime                 0.033442\n","eval_samples_per_second     15.209067\n","eval_steps_per_second        0.238198\n","epoch                        0.000000\n","model_run                    3.027650\n","dtype: float64"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["#Data below manually copied from 4 (Max) and 5th (Min) runs\n","training_loss_min = [0.6511,0.477900,0.350600,0.224800]\n","training_loss_max = [0.660900,0.4802,0.3464,0.23470]\n","val_loss_min = [0.545049,0.492314,0.523007,0.644025]\n","val_loss_max = [0.552437,0.516062,0.526239,0.667931]\n","epoch_list=[1,2,3,4]\n","\n","plt.figure()\n","plt.plot(epoch_list,training_loss_min, label=\"Training Loss Min Run\")\n","plt.plot(epoch_list,val_loss_min, label=\"Validation Loss Min Run\")\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.xticks(epoch_list)\n","plt.legend()\n","plt.show()"],"metadata":{"id":"WyTBvDCz8D6K","colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"status":"ok","timestamp":1644777719367,"user_tz":0,"elapsed":665,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"af8174f5-5bcc-4343-8a23-0eae3bb95a45"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["plt.figure()\n","plt.plot(epoch_list,training_loss_max, label=\"Training Loss Max Run\")\n","plt.plot(epoch_list,val_loss_max, label=\"Validation Loss Max Run\")\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.xticks(epoch_list)\n","plt.legend()\n","plt.show()"],"metadata":{"id":"0o1V0zbH8GR9","colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"status":"ok","timestamp":1644777719854,"user_tz":0,"elapsed":506,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"465bd145-7aff-4c5a-8211-ebd0f56ef149"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Distilbert Experiment HateTwit Intermediate Task Transfer.ipynb","provenance":[{"file_id":"11zAh-a_KPmflomNvD1V-XdXzenQf9Q16","timestamp":1644756430702},{"file_id":"1a2My2hhUmHWnDPSOkajnyi9ZeBYHGBAE","timestamp":1644482917164},{"file_id":"1P3VgwZUmhtAsU0t-TfIzNCI19KZV3I_q","timestamp":1643491583972},{"file_id":"1-rZqxPTOtm21puGsZKK_FiKXeyCg7py7","timestamp":1643483337240},{"file_id":"15wylWRQJ1vxlP58OhBHUnY5fdagThMvJ","timestamp":1643406846637},{"file_id":"1B35hajBJY3fRQV7LSjqoqQ3xjdcyCzE3","timestamp":1642365829686},{"file_id":"1b0lCW2Cj6AULiE-Axh2OeZwURHR6pfcD","timestamp":1642333651961},{"file_id":"1RAjFaq-k9CLJQP5eO668UXLc0q-wjuve","timestamp":1642280213414},{"file_id":"1LzZr7GRN1SwVrNyjVX5t5PpCvio8w_kE","timestamp":1642109182548},{"file_id":"1t-qzEyxZtGn_Cnlfg2WtN-0dlgUmxfzx","timestamp":1641764210714},{"file_id":"14bEU8hCGPF8cVUA_BonJQA6Brv89DKUm","timestamp":1641252935713},{"file_id":"18Il3CpGf89tF1Z10iYX8OdfeHxxAX1Ui","timestamp":1639243141142},{"file_id":"1SHCgoRQVGtl9OiWEJGK3JgKkuxxSPy_5","timestamp":1639231968300},{"file_id":"1D-3yvF0nGnaWEZGxQj21R6fsGnyv5a5g","timestamp":1637526185003},{"file_id":"1glXr2JglKPUpN_3AGyk3GjfCtZSDNfsZ","timestamp":1637408594851},{"file_id":"1rc5hX8PBIv7GKvlxLQ35Vwf2jxLsv9f4","timestamp":1634501666668}],"mount_file_id":"15soPSdetAURkujymKYMFo54SUBNktW8f","authorship_tag":"ABX9TyNT2esFjrMkf6K9qus4BLr1"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}