{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":19310,"status":"ok","timestamp":1644968727295,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"},"user_tz":0},"id":"F-o6bXOJ18j4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8cf0f1b7-d317-4203-c935-1698cac1e30a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 3.5 MB 5.3 MB/s \n","\u001b[K     |████████████████████████████████| 67 kB 3.5 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 63.4 MB/s \n","\u001b[K     |████████████████████████████████| 6.8 MB 71.3 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 77.0 MB/s \n","\u001b[K     |████████████████████████████████| 1.2 MB 5.3 MB/s \n","\u001b[K     |████████████████████████████████| 311 kB 5.3 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 77.0 MB/s \n","\u001b[K     |████████████████████████████████| 133 kB 83.7 MB/s \n","\u001b[K     |████████████████████████████████| 243 kB 85.7 MB/s \n","\u001b[K     |████████████████████████████████| 144 kB 80.4 MB/s \n","\u001b[K     |████████████████████████████████| 271 kB 81.1 MB/s \n","\u001b[K     |████████████████████████████████| 94 kB 3.6 MB/s \n","\u001b[?25h"]}],"source":["!pip install -qq transformers\n","!pip install -qq sentencepiece\n","!pip install -qq datasets\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":9232,"status":"ok","timestamp":1644968736518,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"},"user_tz":0},"id":"Rz6wNlu92ge_"},"outputs":[],"source":["import transformers\n","import datasets\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup,Trainer, TrainingArguments\n","from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n","import torch\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from pylab import rcParams\n","import matplotlib.pyplot as plt\n","from matplotlib import rc\n","from sklearn.metrics import confusion_matrix, classification_report\n","from collections import defaultdict\n","import random\n","from textwrap import wrap\n","from datetime import datetime\n","from datasets import load_from_disk\n","from datasets import Dataset\n","from sklearn.metrics import accuracy_score,classification_report, confusion_matrix\n","from sklearn.metrics import precision_recall_fscore_support"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pOQkqPGp2ZTN"},"outputs":[],"source":["from torch import nn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T7IFr4-3TKaA"},"outputs":[],"source":["# the model we gonna train, base uncased BERT\n","# check text classification models here: https://huggingface.co/models?filter=text-classification\n","MODEL_NAME = \"distilbert-base-uncased\"\n","# max sequence length for each document/sentence sample\n","BATCH_SIZE = 16\n","EPOCHS = 3\n","LEARNING_RATE= 6.58e-5\n","#LEARNING_RATE= 3.5e-6\n","WEIGHT_DECAY = 0.129\n","WARMUP_STEPS = 164\n","RANDOM_SEED=22\n","\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YoKXcvyo_X47"},"outputs":[],"source":["def set_seed(seed):\n","    \"\"\"Set all seeds to make results reproducible (deterministic mode).\n","       When seed is None, disables deterministic mode.\n","    :param seed: an integer to your choosing\n","    \"\"\"\n","    if seed is not None:\n","        torch.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","        np.random.seed(seed)\n","        random.seed(seed)\n","\n","def compute_metrics(pred):\n","  labels = pred.label_ids\n","  preds = pred.predictions.argmax(-1)\n","  # calculate accuracy using sklearn's function\n","  acc = accuracy_score(labels, preds)\n","  precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n","  acc = accuracy_score(labels, preds)\n","  confusion_matrix = classification_report(labels, preds, digits=4,output_dict=True)\n","  return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall,\n","        'hate_f1': confusion_matrix[\"0\"][\"f1-score\"],\n","        'hate_recall': confusion_matrix[\"0\"][\"recall\"],\n","        'hate_precision': confusion_matrix[\"0\"][\"precision\"],\n","        'offensive_f1': confusion_matrix[\"1\"][\"f1-score\"],\n","        'offensive_recall': confusion_matrix[\"1\"][\"recall\"],\n","        'offensive_precision': confusion_matrix[\"1\"][\"precision\"],\n","        'normal_f1': confusion_matrix[\"2\"][\"f1-score\"],\n","        'normal_recall': confusion_matrix[\"2\"][\"recall\"],\n","        'normal_precision': confusion_matrix[\"2\"][\"precision\"],    \n","  }\n","\n","\n","def model_init():\n","  temp_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME,num_labels=3).to(device)\n","  return temp_model\n","\n","# Code modified from Stabilizer library to handle DistilBERT architecture\n","#https://github.com/flowerpot-ai/stabilizer\n","\n","\n","def get_optimizer_parameters_with_llrd(model, peak_lr, multiplicative_factor):\n","    num_encoder_layers = len(model.distilbert.transformer.layer)\n","    # Task specific layer gets the peak_lr\n","    tsl_parameters = [\n","        {\n","            \"params\": [param for name, param in model.named_parameters() if 'distilbert' not in name],\n","            \"param_names\": [name for name, param in model.named_parameters() if 'distilbert' not in name],\n","            \"lr\": peak_lr,\n","            \"name\": \"tsl\",\n","        }\n","    ]\n","\n","    # Starting from the last encoder layer each encoder layers get a lr defined by\n","    # current_layer_lr = prev_layer_lr * multiplicative_factor\n","    # the last encoder layer lr = peak_lr * multiplicative_factor\n","    encoder_parameters = [\n","        {\n","            \"params\": [param for name, param in model.named_parameters() if f\"distilbert.transformer.layer.{layer_num}\" in name],\n","            \"param_names\": [name for name, param in model.named_parameters() if f\"distilbert.transformer.layer.{layer_num}\" in name],\n","            \"lr\": peak_lr * (multiplicative_factor ** (num_encoder_layers - layer_num)),\n","            \"name\": f\"layer_{layer_num}\",\n","        }\n","        for layer_num, layer in enumerate(model.distilbert.transformer.layer)\n","    ]\n","\n","    # Embedding layer gets embedding layer lr = first encoder layer lr * multiplicative_factor\n","    embedding_parameters = [\n","        {\n","            \"params\": [param for name, param in model.named_parameters() if 'embeddings' in name],\n","            \"param_names\": [name for name, param in model.named_parameters() if 'embeddings' in name],\n","            \"lr\": peak_lr * (multiplicative_factor ** (num_encoder_layers + 1)),\n","            \"name\": \"embedding\",\n","        }\n","    ]\n","    return tsl_parameters + encoder_parameters + embedding_parameters\n","\n","def timestamp():\n","    dateTimeObj = datetime.now()\n","    timestampStr = dateTimeObj.strftime(\"%d-%b-%Y (%H:%M:%S.%f)\")\n","    print(timestampStr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lqKiS7jbkC4x"},"outputs":[],"source":["set_seed(RANDOM_SEED)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"TlWMqxBs5b5P","executionInfo":{"status":"ok","timestamp":1644879709672,"user_tz":0,"elapsed":3399399,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"c7f2ed63-b258-4a2f-e058-37dfc90434d3"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:28, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.562900</td>\n","      <td>0.530089</td>\n","      <td>0.782142</td>\n","      <td>0.737673</td>\n","      <td>0.735157</td>\n","      <td>0.746929</td>\n","      <td>0.720289</td>\n","      <td>0.801811</td>\n","      <td>0.653815</td>\n","      <td>0.859360</td>\n","      <td>0.840429</td>\n","      <td>0.879163</td>\n","      <td>0.633370</td>\n","      <td>0.598548</td>\n","      <td>0.672494</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.427000</td>\n","      <td>0.478901</td>\n","      <td>0.811548</td>\n","      <td>0.764638</td>\n","      <td>0.772563</td>\n","      <td>0.759949</td>\n","      <td>0.773242</td>\n","      <td>0.790744</td>\n","      <td>0.756497</td>\n","      <td>0.881658</td>\n","      <td>0.897816</td>\n","      <td>0.866071</td>\n","      <td>0.639013</td>\n","      <td>0.591286</td>\n","      <td>0.695122</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.278900</td>\n","      <td>0.551580</td>\n","      <td>0.809830</td>\n","      <td>0.768845</td>\n","      <td>0.765866</td>\n","      <td>0.773092</td>\n","      <td>0.786712</td>\n","      <td>0.821932</td>\n","      <td>0.754386</td>\n","      <td>0.877612</td>\n","      <td>0.870789</td>\n","      <td>0.884543</td>\n","      <td>0.642212</td>\n","      <td>0.626556</td>\n","      <td>0.658670</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/1/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/1/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/1/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/1/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/1/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/1/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/1/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/1/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/1/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/1/checkpoint-4660 (score: 0.4789011478424072).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_1\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_1/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_1/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:29, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.562700</td>\n","      <td>0.529708</td>\n","      <td>0.793089</td>\n","      <td>0.744394</td>\n","      <td>0.751636</td>\n","      <td>0.743245</td>\n","      <td>0.731315</td>\n","      <td>0.777666</td>\n","      <td>0.690179</td>\n","      <td>0.868305</td>\n","      <td>0.876342</td>\n","      <td>0.860414</td>\n","      <td>0.633562</td>\n","      <td>0.575726</td>\n","      <td>0.704315</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.427400</td>\n","      <td>0.515588</td>\n","      <td>0.807469</td>\n","      <td>0.767980</td>\n","      <td>0.762275</td>\n","      <td>0.781602</td>\n","      <td>0.781908</td>\n","      <td>0.878270</td>\n","      <td>0.704600</td>\n","      <td>0.874238</td>\n","      <td>0.849315</td>\n","      <td>0.900667</td>\n","      <td>0.647795</td>\n","      <td>0.617220</td>\n","      <td>0.681558</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.259500</td>\n","      <td>0.561834</td>\n","      <td>0.816484</td>\n","      <td>0.779233</td>\n","      <td>0.775799</td>\n","      <td>0.783495</td>\n","      <td>0.801164</td>\n","      <td>0.830986</td>\n","      <td>0.773408</td>\n","      <td>0.878641</td>\n","      <td>0.871159</td>\n","      <td>0.886252</td>\n","      <td>0.657895</td>\n","      <td>0.648340</td>\n","      <td>0.667735</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/2/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/2/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/2/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/2/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/2/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/2/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/2/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/2/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/2/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/2/checkpoint-4660 (score: 0.5155879855155945).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_2\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_2/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_2/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:32, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.556200</td>\n","      <td>0.550140</td>\n","      <td>0.776991</td>\n","      <td>0.722388</td>\n","      <td>0.736599</td>\n","      <td>0.713914</td>\n","      <td>0.711443</td>\n","      <td>0.719316</td>\n","      <td>0.703740</td>\n","      <td>0.855605</td>\n","      <td>0.883006</td>\n","      <td>0.829854</td>\n","      <td>0.600115</td>\n","      <td>0.539419</td>\n","      <td>0.676203</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.423300</td>\n","      <td>0.506001</td>\n","      <td>0.803177</td>\n","      <td>0.753334</td>\n","      <td>0.769038</td>\n","      <td>0.746592</td>\n","      <td>0.771470</td>\n","      <td>0.799799</td>\n","      <td>0.745080</td>\n","      <td>0.871786</td>\n","      <td>0.897445</td>\n","      <td>0.847552</td>\n","      <td>0.616745</td>\n","      <td>0.542531</td>\n","      <td>0.714481</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.266000</td>\n","      <td>0.586377</td>\n","      <td>0.804679</td>\n","      <td>0.763226</td>\n","      <td>0.765290</td>\n","      <td>0.761347</td>\n","      <td>0.788945</td>\n","      <td>0.789738</td>\n","      <td>0.788153</td>\n","      <td>0.871436</td>\n","      <td>0.877083</td>\n","      <td>0.865863</td>\n","      <td>0.629297</td>\n","      <td>0.617220</td>\n","      <td>0.641855</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/3/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/3/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/3/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/3/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/3/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/3/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/3/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/3/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/3/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/3/checkpoint-4660 (score: 0.5060012936592102).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_3\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_3/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_3/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:31, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.565000</td>\n","      <td>0.545790</td>\n","      <td>0.781927</td>\n","      <td>0.728146</td>\n","      <td>0.751377</td>\n","      <td>0.724864</td>\n","      <td>0.726437</td>\n","      <td>0.794769</td>\n","      <td>0.668925</td>\n","      <td>0.856265</td>\n","      <td>0.876712</td>\n","      <td>0.836749</td>\n","      <td>0.601737</td>\n","      <td>0.503112</td>\n","      <td>0.748457</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.424100</td>\n","      <td>0.527110</td>\n","      <td>0.789011</td>\n","      <td>0.751565</td>\n","      <td>0.742404</td>\n","      <td>0.767712</td>\n","      <td>0.759425</td>\n","      <td>0.851107</td>\n","      <td>0.685575</td>\n","      <td>0.856703</td>\n","      <td>0.823399</td>\n","      <td>0.892814</td>\n","      <td>0.638567</td>\n","      <td>0.628631</td>\n","      <td>0.648822</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.277500</td>\n","      <td>0.568358</td>\n","      <td>0.806396</td>\n","      <td>0.764175</td>\n","      <td>0.764762</td>\n","      <td>0.766979</td>\n","      <td>0.788224</td>\n","      <td>0.835010</td>\n","      <td>0.746403</td>\n","      <td>0.871852</td>\n","      <td>0.871529</td>\n","      <td>0.872175</td>\n","      <td>0.632450</td>\n","      <td>0.594398</td>\n","      <td>0.675708</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/4/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/4/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/4/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/4/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/4/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/4/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/4/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/4/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/4/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/4/checkpoint-4660 (score: 0.52711021900177).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_4\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_4/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_4/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:04]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:29, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.550500</td>\n","      <td>0.531634</td>\n","      <td>0.783645</td>\n","      <td>0.730830</td>\n","      <td>0.750730</td>\n","      <td>0.718309</td>\n","      <td>0.712259</td>\n","      <td>0.707243</td>\n","      <td>0.717347</td>\n","      <td>0.857854</td>\n","      <td>0.893743</td>\n","      <td>0.824735</td>\n","      <td>0.622378</td>\n","      <td>0.553942</td>\n","      <td>0.710106</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.418400</td>\n","      <td>0.486576</td>\n","      <td>0.810260</td>\n","      <td>0.767282</td>\n","      <td>0.772743</td>\n","      <td>0.762923</td>\n","      <td>0.771772</td>\n","      <td>0.775654</td>\n","      <td>0.767928</td>\n","      <td>0.877167</td>\n","      <td>0.889670</td>\n","      <td>0.865011</td>\n","      <td>0.652906</td>\n","      <td>0.623444</td>\n","      <td>0.685291</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.265100</td>\n","      <td>0.567558</td>\n","      <td>0.812406</td>\n","      <td>0.769892</td>\n","      <td>0.771513</td>\n","      <td>0.769351</td>\n","      <td>0.791360</td>\n","      <td>0.810865</td>\n","      <td>0.772771</td>\n","      <td>0.879396</td>\n","      <td>0.884117</td>\n","      <td>0.874725</td>\n","      <td>0.638919</td>\n","      <td>0.613071</td>\n","      <td>0.667043</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/5/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/5/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/5/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/5/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/5/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/5/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/5/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/5/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/5/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/5/checkpoint-4660 (score: 0.48657578229904175).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_5\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_5/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_5/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:30, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.564100</td>\n","      <td>0.526468</td>\n","      <td>0.782786</td>\n","      <td>0.738570</td>\n","      <td>0.743688</td>\n","      <td>0.734070</td>\n","      <td>0.728690</td>\n","      <td>0.705231</td>\n","      <td>0.753763</td>\n","      <td>0.854948</td>\n","      <td>0.865235</td>\n","      <td>0.844902</td>\n","      <td>0.632071</td>\n","      <td>0.631743</td>\n","      <td>0.632399</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.416400</td>\n","      <td>0.492574</td>\n","      <td>0.806611</td>\n","      <td>0.767511</td>\n","      <td>0.766816</td>\n","      <td>0.769643</td>\n","      <td>0.794388</td>\n","      <td>0.825956</td>\n","      <td>0.765144</td>\n","      <td>0.868792</td>\n","      <td>0.867827</td>\n","      <td>0.869759</td>\n","      <td>0.639353</td>\n","      <td>0.615145</td>\n","      <td>0.665544</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.249600</td>\n","      <td>0.588790</td>\n","      <td>0.810474</td>\n","      <td>0.772104</td>\n","      <td>0.767682</td>\n","      <td>0.778156</td>\n","      <td>0.798853</td>\n","      <td>0.841046</td>\n","      <td>0.760692</td>\n","      <td>0.874110</td>\n","      <td>0.863754</td>\n","      <td>0.884717</td>\n","      <td>0.643349</td>\n","      <td>0.629668</td>\n","      <td>0.657638</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/6/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/6/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/6/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/6/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/6/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/6/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/6/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/6/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/6/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/6/checkpoint-4660 (score: 0.49257364869117737).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_6\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_6/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_6/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:04]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:26, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.560100</td>\n","      <td>0.528842</td>\n","      <td>0.789654</td>\n","      <td>0.744095</td>\n","      <td>0.749822</td>\n","      <td>0.741566</td>\n","      <td>0.743689</td>\n","      <td>0.770624</td>\n","      <td>0.718574</td>\n","      <td>0.859546</td>\n","      <td>0.870048</td>\n","      <td>0.849295</td>\n","      <td>0.629050</td>\n","      <td>0.584025</td>\n","      <td>0.681598</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.426500</td>\n","      <td>0.488321</td>\n","      <td>0.806825</td>\n","      <td>0.764032</td>\n","      <td>0.770578</td>\n","      <td>0.760486</td>\n","      <td>0.776908</td>\n","      <td>0.798793</td>\n","      <td>0.756190</td>\n","      <td>0.871215</td>\n","      <td>0.884117</td>\n","      <td>0.858684</td>\n","      <td>0.643973</td>\n","      <td>0.598548</td>\n","      <td>0.696860</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.268100</td>\n","      <td>0.573359</td>\n","      <td>0.811977</td>\n","      <td>0.773104</td>\n","      <td>0.772005</td>\n","      <td>0.774653</td>\n","      <td>0.793120</td>\n","      <td>0.811871</td>\n","      <td>0.775216</td>\n","      <td>0.875742</td>\n","      <td>0.874121</td>\n","      <td>0.877369</td>\n","      <td>0.650449</td>\n","      <td>0.637967</td>\n","      <td>0.663430</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/7/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/7/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/7/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/7/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/7/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/7/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/7/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/7/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/7/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/7/checkpoint-4660 (score: 0.48832064867019653).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_7\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_7/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_7/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:28, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.561400</td>\n","      <td>0.550100</td>\n","      <td>0.783001</td>\n","      <td>0.735305</td>\n","      <td>0.740803</td>\n","      <td>0.732740</td>\n","      <td>0.735151</td>\n","      <td>0.759557</td>\n","      <td>0.712264</td>\n","      <td>0.856151</td>\n","      <td>0.867086</td>\n","      <td>0.845487</td>\n","      <td>0.614612</td>\n","      <td>0.571577</td>\n","      <td>0.664656</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.430700</td>\n","      <td>0.526517</td>\n","      <td>0.792445</td>\n","      <td>0.745575</td>\n","      <td>0.752692</td>\n","      <td>0.739289</td>\n","      <td>0.754892</td>\n","      <td>0.737425</td>\n","      <td>0.773207</td>\n","      <td>0.865710</td>\n","      <td>0.881896</td>\n","      <td>0.850107</td>\n","      <td>0.616124</td>\n","      <td>0.598548</td>\n","      <td>0.634763</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.275900</td>\n","      <td>0.593492</td>\n","      <td>0.805752</td>\n","      <td>0.765202</td>\n","      <td>0.763921</td>\n","      <td>0.766912</td>\n","      <td>0.787224</td>\n","      <td>0.805835</td>\n","      <td>0.769452</td>\n","      <td>0.872356</td>\n","      <td>0.870418</td>\n","      <td>0.874303</td>\n","      <td>0.636027</td>\n","      <td>0.624481</td>\n","      <td>0.648009</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/8/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/8/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/8/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/8/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/8/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/8/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/8/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/8/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/8/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/8/checkpoint-4660 (score: 0.5265170931816101).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_8\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_8/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_8/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:04]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:29, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.566900</td>\n","      <td>0.551633</td>\n","      <td>0.783430</td>\n","      <td>0.730578</td>\n","      <td>0.752952</td>\n","      <td>0.715323</td>\n","      <td>0.707292</td>\n","      <td>0.683099</td>\n","      <td>0.733261</td>\n","      <td>0.856992</td>\n","      <td>0.898556</td>\n","      <td>0.819102</td>\n","      <td>0.627451</td>\n","      <td>0.564315</td>\n","      <td>0.706494</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.436200</td>\n","      <td>0.509417</td>\n","      <td>0.805108</td>\n","      <td>0.761952</td>\n","      <td>0.767719</td>\n","      <td>0.761152</td>\n","      <td>0.767619</td>\n","      <td>0.810865</td>\n","      <td>0.728752</td>\n","      <td>0.870778</td>\n","      <td>0.878193</td>\n","      <td>0.863487</td>\n","      <td>0.647458</td>\n","      <td>0.594398</td>\n","      <td>0.710918</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.279100</td>\n","      <td>0.590794</td>\n","      <td>0.803177</td>\n","      <td>0.764428</td>\n","      <td>0.762631</td>\n","      <td>0.766306</td>\n","      <td>0.782565</td>\n","      <td>0.785714</td>\n","      <td>0.779441</td>\n","      <td>0.869695</td>\n","      <td>0.864865</td>\n","      <td>0.874579</td>\n","      <td>0.641026</td>\n","      <td>0.648340</td>\n","      <td>0.633874</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/9/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/9/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/9/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/9/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/9/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/9/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/9/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/9/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/9/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/9/checkpoint-4660 (score: 0.5094171762466431).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_9\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_9/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_9/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:04]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.16.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6990\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6990' max='6990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6990/6990 05:51, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.567300</td>\n","      <td>0.530137</td>\n","      <td>0.789225</td>\n","      <td>0.732465</td>\n","      <td>0.757529</td>\n","      <td>0.717484</td>\n","      <td>0.723361</td>\n","      <td>0.710262</td>\n","      <td>0.736952</td>\n","      <td>0.865493</td>\n","      <td>0.910033</td>\n","      <td>0.825109</td>\n","      <td>0.608541</td>\n","      <td>0.532158</td>\n","      <td>0.710526</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.442600</td>\n","      <td>0.505552</td>\n","      <td>0.804250</td>\n","      <td>0.756708</td>\n","      <td>0.766264</td>\n","      <td>0.750243</td>\n","      <td>0.756219</td>\n","      <td>0.764588</td>\n","      <td>0.748031</td>\n","      <td>0.875249</td>\n","      <td>0.894854</td>\n","      <td>0.856485</td>\n","      <td>0.638655</td>\n","      <td>0.591286</td>\n","      <td>0.694275</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.277200</td>\n","      <td>0.563636</td>\n","      <td>0.808328</td>\n","      <td>0.766561</td>\n","      <td>0.767950</td>\n","      <td>0.765360</td>\n","      <td>0.772000</td>\n","      <td>0.776660</td>\n","      <td>0.767396</td>\n","      <td>0.876520</td>\n","      <td>0.880415</td>\n","      <td>0.872661</td>\n","      <td>0.651163</td>\n","      <td>0.639004</td>\n","      <td>0.663793</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/10/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/10/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/10/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/10/checkpoint-4660\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/10/checkpoint-4660/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/10/checkpoint-4660/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/10/checkpoint-6990\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/10/checkpoint-6990/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/10/checkpoint-6990/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/10/checkpoint-4660 (score: 0.5055522918701172).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_10\n","Configuration saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_10/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_10/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [292/292 00:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}],"source":["result_list = []\n","for i in range(1,11):\n","\n","  training_args = TrainingArguments(\n","    output_dir='/content/drive/MyDrive/Dissertation/disbert_hate_llrd/results/'+str(i),          # output directory\n","    num_train_epochs=EPOCHS,              # total number of training epochs\n","    save_strategy =\"epoch\" ,\n","    per_device_train_batch_size=BATCH_SIZE,  # batch size per device during training\n","    per_device_eval_batch_size=BATCH_SIZE,   # batch size for evaluation\n","    weight_decay= WEIGHT_DECAY,               # strength of weight decay\n","    learning_rate= LEARNING_RATE, \n","    warmup_steps = WARMUP_STEPS,\n","    logging_dir='./disbert_hate_llrd/logs',     # directory for storing logs\n","    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n","    evaluation_strategy=\"epoch\",\n","  )\n","\n","  hatetwit_dataset_dfs = load_from_disk('/content/drive/MyDrive/Dissertation/datasets/hatetwit_'+str(i))\n","  train_dataset = hatetwit_dataset_dfs [\"train\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","  eval_dataset = hatetwit_dataset_dfs [\"validation\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","  test_dataset = hatetwit_dataset_dfs [\"test\"].remove_columns([\"input_ids_bert\",\"attention_mask_bert\",\"token_type_ids_bert\"])\n","  model = model_init()\n","  parameters = get_optimizer_parameters_with_llrd(model, LEARNING_RATE, 0.95)\n","  trainer = Trainer(\n","      model=model,                         # the instantiated Transformers model to be trained\n","      args=training_args,                  # training arguments, defined above\n","      train_dataset= train_dataset,         # training dataset\n","      eval_dataset=eval_dataset,          # evaluation dataset\n","      compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n","  )\n","  trainer.create_optimizer()\n","  trainer.optimizer = AdamW(parameters, lr=LEARNING_RATE,weight_decay=WEIGHT_DECAY)\n","  trainer.train()\n","  trainer.save_model('/content/drive/MyDrive/Dissertation/disbert_hate_llrd/models/model_'+str(i))\n","  results = trainer.evaluate(test_dataset)\n","  results[\"model_run\"] = i\n","  result_list.append(results)"]},{"cell_type":"code","source":["timestamp()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5AJjJD3gLwuz","executionInfo":{"status":"ok","timestamp":1644879709673,"user_tz":0,"elapsed":12,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"7d3ec5c7-814d-47be-8314-9c138cd88630"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["14-Feb-2022 (23:01:49.164785)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uGVY-cSu593H"},"outputs":[],"source":["results_df = pd.DataFrame(result_list)\n","results_df.to_csv('/content/drive/MyDrive/Dissertation/results/distilbert_llrd.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"id":"GskO2Y_U6USH","executionInfo":{"status":"ok","timestamp":1644879710269,"user_tz":0,"elapsed":37,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"b455b05d-7ec8-4312-8c7d-19a867a59ded"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-d54e6eaa-f44c-4a6a-be39-6f80c7cb28c8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eval_loss</th>\n","      <th>eval_accuracy</th>\n","      <th>eval_f1</th>\n","      <th>eval_precision</th>\n","      <th>eval_recall</th>\n","      <th>eval_hate_f1</th>\n","      <th>eval_hate_recall</th>\n","      <th>eval_hate_precision</th>\n","      <th>eval_offensive_f1</th>\n","      <th>eval_offensive_recall</th>\n","      <th>eval_offensive_precision</th>\n","      <th>eval_normal_f1</th>\n","      <th>eval_normal_recall</th>\n","      <th>eval_normal_precision</th>\n","      <th>eval_runtime</th>\n","      <th>eval_samples_per_second</th>\n","      <th>eval_steps_per_second</th>\n","      <th>epoch</th>\n","      <th>model_run</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5</th>\n","      <td>0.50151</td>\n","      <td>0.800773</td>\n","      <td>0.753821</td>\n","      <td>0.758464</td>\n","      <td>0.751334</td>\n","      <td>0.777778</td>\n","      <td>0.796576</td>\n","      <td>0.759846</td>\n","      <td>0.87187</td>\n","      <td>0.883333</td>\n","      <td>0.8607</td>\n","      <td>0.611817</td>\n","      <td>0.574093</td>\n","      <td>0.654846</td>\n","      <td>4.5414</td>\n","      <td>1025.672</td>\n","      <td>64.297</td>\n","      <td>3.0</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d54e6eaa-f44c-4a6a-be39-6f80c7cb28c8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d54e6eaa-f44c-4a6a-be39-6f80c7cb28c8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d54e6eaa-f44c-4a6a-be39-6f80c7cb28c8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   eval_loss  eval_accuracy   eval_f1  ...  eval_steps_per_second  epoch  model_run\n","5    0.50151       0.800773  0.753821  ...                 64.297    3.0          6\n","\n","[1 rows x 19 columns]"]},"metadata":{},"execution_count":10}],"source":["#Sort rows to determine the mix, max and median \n","results_df = results_df.sort_values(by=['eval_f1'])\n","#Print min values\n","results_df.head(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"id":"6ekob4bg6X7y","executionInfo":{"status":"ok","timestamp":1644879710270,"user_tz":0,"elapsed":34,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"dc94d640-7080-4604-a89f-d300bb227262"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-4db2e80d-c0ed-408c-a396-1e24e10c602e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eval_loss</th>\n","      <th>eval_accuracy</th>\n","      <th>eval_f1</th>\n","      <th>eval_precision</th>\n","      <th>eval_recall</th>\n","      <th>eval_hate_f1</th>\n","      <th>eval_hate_recall</th>\n","      <th>eval_hate_precision</th>\n","      <th>eval_offensive_f1</th>\n","      <th>eval_offensive_recall</th>\n","      <th>eval_offensive_precision</th>\n","      <th>eval_normal_f1</th>\n","      <th>eval_normal_recall</th>\n","      <th>eval_normal_precision</th>\n","      <th>eval_runtime</th>\n","      <th>eval_samples_per_second</th>\n","      <th>eval_steps_per_second</th>\n","      <th>epoch</th>\n","      <th>model_run</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.519406</td>\n","      <td>0.805067</td>\n","      <td>0.766486</td>\n","      <td>0.761343</td>\n","      <td>0.778609</td>\n","      <td>0.782098</td>\n","      <td>0.871098</td>\n","      <td>0.709598</td>\n","      <td>0.869565</td>\n","      <td>0.848148</td>\n","      <td>0.892092</td>\n","      <td>0.647795</td>\n","      <td>0.61658</td>\n","      <td>0.682339</td>\n","      <td>3.9435</td>\n","      <td>1181.179</td>\n","      <td>74.046</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4db2e80d-c0ed-408c-a396-1e24e10c602e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4db2e80d-c0ed-408c-a396-1e24e10c602e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4db2e80d-c0ed-408c-a396-1e24e10c602e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   eval_loss  eval_accuracy   eval_f1  ...  eval_steps_per_second  epoch  model_run\n","1   0.519406       0.805067  0.766486  ...                 74.046    3.0          2\n","\n","[1 rows x 19 columns]"]},"metadata":{},"execution_count":11}],"source":["#Print max values \n","results_df.tail(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GnlGqulr6jjJ","executionInfo":{"status":"ok","timestamp":1644879710270,"user_tz":0,"elapsed":33,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"05f702bc-0068-4f20-fea1-69a5be0fd8c2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7596179455147313"]},"metadata":{},"execution_count":12}],"source":["#Print median f1\n","results_df[\"eval_f1\"].median()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bcF2Dhgf6ldi","executionInfo":{"status":"ok","timestamp":1644879710271,"user_tz":0,"elapsed":25,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"04882074-7f0b-4041-976d-b1b4a6e3129a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["eval_loss                      0.508580\n","eval_accuracy                  0.803306\n","eval_f1                        0.759532\n","eval_precision                 0.763414\n","eval_recall                    0.759900\n","eval_hate_f1                   0.774456\n","eval_hate_recall               0.809668\n","eval_hate_precision            0.744097\n","eval_offensive_f1              0.871012\n","eval_offensive_recall          0.875630\n","eval_offensive_precision       0.867226\n","eval_normal_f1                 0.633129\n","eval_normal_recall             0.594404\n","eval_normal_precision          0.678919\n","eval_runtime                   4.277420\n","eval_samples_per_second     1097.497400\n","eval_steps_per_second         68.799800\n","epoch                          3.000000\n","model_run                      5.500000\n","dtype: float64"]},"metadata":{},"execution_count":13}],"source":["#Print average values\n","results_df.mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wAgbASEh6nsb","executionInfo":{"status":"ok","timestamp":1644879710271,"user_tz":0,"elapsed":23,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"a87978ba-1494-4d1d-a538-68645d5888e3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["eval_loss                     0.008435\n","eval_accuracy                 0.003864\n","eval_f1                       0.004274\n","eval_precision                0.006943\n","eval_recall                   0.010613\n","eval_hate_f1                  0.007287\n","eval_hate_recall              0.033044\n","eval_hate_precision           0.028622\n","eval_offensive_f1             0.003675\n","eval_offensive_recall         0.021946\n","eval_offensive_precision      0.017515\n","eval_normal_f1                0.014692\n","eval_normal_recall            0.030047\n","eval_normal_precision         0.022331\n","eval_runtime                  0.399662\n","eval_samples_per_second     101.472003\n","eval_steps_per_second         6.361026\n","epoch                         0.000000\n","model_run                     3.027650\n","dtype: float64"]},"metadata":{},"execution_count":14}],"source":["results_df.std()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"UKVEXp3A6pW1","executionInfo":{"status":"ok","timestamp":1644968736533,"user_tz":0,"elapsed":22,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"4a853633-3f2c-409f-cdc7-849a20a0257a"},"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["training_loss_min = [0.55,0.4184,0.265]\n","training_loss_max = [0.5629,0.4270,0.2789]\n","val_loss_min = [0.5316,0.486,0.567]\n","val_loss_max = [0.5300,0.478901,0.551580]\n","epoch_list=[1,2,3]\n","\n","plt.figure()\n","plt.plot(epoch_list,training_loss_min, label=\"Training Loss Min Run\")\n","plt.plot(epoch_list,val_loss_min, label=\"Validation Loss Min Run\")\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.xticks(epoch_list)\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"4_mveuvX6rdY","executionInfo":{"status":"ok","timestamp":1644968736878,"user_tz":0,"elapsed":12,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"fcca90cd-6650-4e03-ec9e-ae42641c908f"},"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["plt.figure()\n","plt.plot(epoch_list,training_loss_max, label=\"Training Loss Max Run\")\n","plt.plot(epoch_list,val_loss_max, label=\"Validation Loss Max Run\")\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.xticks(epoch_list)\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","source":["6.58e-5\n","eval_loss                      0.508580\n","eval_accuracy                  0.803306\n","eval_f1                        0.759532\n","eval_precision                 0.763414\n","eval_recall                    0.759900\n","eval_hate_f1                   0.774456\n","eval_hate_recall               0.809668\n","eval_hate_precision            0.744097\n","eval_offensive_f1              0.871012\n","eval_offensive_recall          0.875630\n","eval_offensive_precision       0.867226\n","eval_normal_f1                 0.633129\n","eval_normal_recall             0.594404\n","eval_normal_precision          0.678919\n","eval_runtime                   4.292950\n","eval_samples_per_second     1091.155200\n","eval_steps_per_second         68.402300\n","epoch                          3.000000\n","model_run                      5.500000\n","dtype: float64"],"metadata":{"id":"bTj5vzHD-xq3"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644879710686,"user_tz":0,"elapsed":16,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"529a1da1-6414-44d1-b34b-50d984035bf6","id":"LCfFD1So-yEn"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["eval_loss                      0.508580\n","eval_accuracy                  0.803306\n","eval_f1                        0.759532\n","eval_precision                 0.763414\n","eval_recall                    0.759900\n","eval_hate_f1                   0.774456\n","eval_hate_recall               0.809668\n","eval_hate_precision            0.744097\n","eval_offensive_f1              0.871012\n","eval_offensive_recall          0.875630\n","eval_offensive_precision       0.867226\n","eval_normal_f1                 0.633129\n","eval_normal_recall             0.594404\n","eval_normal_precision          0.678919\n","eval_runtime                   4.277420\n","eval_samples_per_second     1097.497400\n","eval_steps_per_second         68.799800\n","epoch                          3.000000\n","model_run                      5.500000\n","dtype: float64"]},"metadata":{},"execution_count":17}],"source":["#Print average values\n","results_df.mean()"]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Distilbert Experiment  HateTwit LLRD Results.ipynb","provenance":[{"file_id":"16nhJIX25usU3-INiry6hlKgeD9v2SqdP","timestamp":1644756721306},{"file_id":"1-rZqxPTOtm21puGsZKK_FiKXeyCg7py7","timestamp":1644163561234},{"file_id":"15wylWRQJ1vxlP58OhBHUnY5fdagThMvJ","timestamp":1643406846637},{"file_id":"1B35hajBJY3fRQV7LSjqoqQ3xjdcyCzE3","timestamp":1642365829686},{"file_id":"1b0lCW2Cj6AULiE-Axh2OeZwURHR6pfcD","timestamp":1642333651961},{"file_id":"1RAjFaq-k9CLJQP5eO668UXLc0q-wjuve","timestamp":1642280213414},{"file_id":"1LzZr7GRN1SwVrNyjVX5t5PpCvio8w_kE","timestamp":1642109182548},{"file_id":"1t-qzEyxZtGn_Cnlfg2WtN-0dlgUmxfzx","timestamp":1641764210714},{"file_id":"14bEU8hCGPF8cVUA_BonJQA6Brv89DKUm","timestamp":1641252935713},{"file_id":"18Il3CpGf89tF1Z10iYX8OdfeHxxAX1Ui","timestamp":1639243141142},{"file_id":"1SHCgoRQVGtl9OiWEJGK3JgKkuxxSPy_5","timestamp":1639231968300},{"file_id":"1D-3yvF0nGnaWEZGxQj21R6fsGnyv5a5g","timestamp":1637526185003},{"file_id":"1glXr2JglKPUpN_3AGyk3GjfCtZSDNfsZ","timestamp":1637408594851},{"file_id":"1rc5hX8PBIv7GKvlxLQ35Vwf2jxLsv9f4","timestamp":1634501666668}],"mount_file_id":"1mIc-wIhR0AZs-81UARd03TJJNrvmHGX4","authorship_tag":"ABX9TyN28opmb2NIUhjN6s+tEKwI"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}