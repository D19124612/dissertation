{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":6096,"status":"ok","timestamp":1644969919546,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"},"user_tz":0},"id":"F-o6bXOJ18j4"},"outputs":[],"source":["!pip install -qq transformers\n","!pip install -qq datasets"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Rz6wNlu92ge_","executionInfo":{"status":"ok","timestamp":1644969926551,"user_tz":0,"elapsed":7012,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["import transformers\n","import datasets\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification,Trainer, TrainingArguments\n","from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n","import torch\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from pylab import rcParams\n","import matplotlib.pyplot as plt\n","from matplotlib import rc\n","from sklearn.metrics import confusion_matrix, classification_report\n","from collections import defaultdict\n","import random\n","from textwrap import wrap\n","from datetime import datetime\n","from datasets import load_from_disk\n","from datasets import Dataset\n","from sklearn.metrics import accuracy_score,classification_report, confusion_matrix\n","from sklearn.metrics import precision_recall_fscore_support"]},{"cell_type":"code","source":["# the model we gonna train, base uncased BERT\n","MODEL_NAME = \"bert-base-uncased\" \n","# max sequence length for each document/sentence sample\n","MAX_LENGTH = 64\n","BATCH_SIZE = 32\n","EPOCHS = 3\n","LEARNING_RATE= 1e-5\n","RANDOM_SEED=2\n","\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"],"metadata":{"id":"hLv2iDcSqccp","executionInfo":{"status":"ok","timestamp":1644969926552,"user_tz":0,"elapsed":7,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"BI8Q2LQR4LmJ","executionInfo":{"status":"ok","timestamp":1644969926553,"user_tz":0,"elapsed":7,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"outputs":[],"source":["def set_seed(seed):\n","    \"\"\"Set all seeds to make results reproducible (deterministic mode).\n","       When seed is None, disables deterministic mode.\n","    :param seed: an integer to your choosing\n","    \"\"\"\n","    if seed is not None:\n","        torch.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","        np.random.seed(seed)\n","        random.seed(seed)\n","\n","def compute_metrics(pred):\n","  labels = pred.label_ids\n","  preds = pred.predictions.argmax(-1)\n","  # calculate accuracy using sklearn's function\n","  acc = accuracy_score(labels, preds)\n","  precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n","  acc = accuracy_score(labels, preds)\n","  confusion_matrix = classification_report(labels, preds, digits=4,output_dict=True)\n","  return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall,\n","        'hate_f1': confusion_matrix[\"0\"][\"f1-score\"],\n","        'hate_recall': confusion_matrix[\"0\"][\"recall\"],\n","        'hate_precision': confusion_matrix[\"0\"][\"precision\"],\n","        'offensive_f1': confusion_matrix[\"1\"][\"f1-score\"],\n","        'offensive_recall': confusion_matrix[\"1\"][\"recall\"],\n","        'offensive_precision': confusion_matrix[\"1\"][\"precision\"],\n","        'normal_f1': confusion_matrix[\"2\"][\"f1-score\"],\n","        'normal_recall': confusion_matrix[\"2\"][\"recall\"],\n","        'normal_precision': confusion_matrix[\"2\"][\"precision\"],    \n","  }\n","\n","\n","def model_init():\n","  temp_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME,num_labels=3).to(device)\n","  return temp_model\n","\n","# Code modified from Stabilizer library to handle DistilBERT architecture\n","#https://github.com/flowerpot-ai/stabilizer\n","\n","\n","\n","\n","def timestamp():\n","    dateTimeObj = datetime.now()\n","    timestampStr = dateTimeObj.strftime(\"%d-%b-%Y (%H:%M:%S.%f)\")\n","    print(timestampStr)"]},{"cell_type":"code","source":["set_seed(2)"],"metadata":{"id":"_87D6sh12Ilk","executionInfo":{"status":"ok","timestamp":1644969926553,"user_tz":0,"elapsed":7,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6759,"status":"ok","timestamp":1644969933306,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"},"user_tz":0},"id":"AMEUIo294iAd"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"]},{"cell_type":"code","source":["timestamp()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gm-HN_XEwkA8","executionInfo":{"status":"ok","timestamp":1644969933307,"user_tz":0,"elapsed":12,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"a91c39e5-c9d2-4f93-a4da-9edea19b8427"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["16-Feb-2022 (00:05:32.807737)\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"id":"PLMUUequ6kV6","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1644975492775,"user_tz":0,"elapsed":5559473,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"04efeee1-3dc0-421d-cdcc-2ce111531f82"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3495\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3495/3495 08:41, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.607200</td>\n","      <td>0.560791</td>\n","      <td>0.773557</td>\n","      <td>0.730820</td>\n","      <td>0.726028</td>\n","      <td>0.736744</td>\n","      <td>0.716619</td>\n","      <td>0.750503</td>\n","      <td>0.685662</td>\n","      <td>0.848758</td>\n","      <td>0.835246</td>\n","      <td>0.862715</td>\n","      <td>0.627083</td>\n","      <td>0.624481</td>\n","      <td>0.629707</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.520700</td>\n","      <td>0.520584</td>\n","      <td>0.788367</td>\n","      <td>0.741296</td>\n","      <td>0.746164</td>\n","      <td>0.741315</td>\n","      <td>0.743237</td>\n","      <td>0.787726</td>\n","      <td>0.703504</td>\n","      <td>0.860662</td>\n","      <td>0.866716</td>\n","      <td>0.854691</td>\n","      <td>0.619989</td>\n","      <td>0.569502</td>\n","      <td>0.680297</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.463100</td>\n","      <td>0.516819</td>\n","      <td>0.795235</td>\n","      <td>0.750414</td>\n","      <td>0.751433</td>\n","      <td>0.754162</td>\n","      <td>0.751402</td>\n","      <td>0.808853</td>\n","      <td>0.701571</td>\n","      <td>0.866914</td>\n","      <td>0.863384</td>\n","      <td>0.870474</td>\n","      <td>0.632925</td>\n","      <td>0.590249</td>\n","      <td>0.682254</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/1/checkpoint-1165\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/1/checkpoint-1165/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/1/checkpoint-1165/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/1/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/1/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/1/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/1/checkpoint-3495\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/1/checkpoint-3495/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/1/checkpoint-3495/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/bert/results/1/checkpoint-3495 (score: 0.5168185830116272).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/models/model_1\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/models/model_1/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/models/model_1/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence, attention_mask_bert, token_type_ids_bert, input_ids_bert.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [146/146 00:05]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3495\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3495/3495 08:36, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.599600</td>\n","      <td>0.553356</td>\n","      <td>0.776132</td>\n","      <td>0.719509</td>\n","      <td>0.739003</td>\n","      <td>0.705641</td>\n","      <td>0.705512</td>\n","      <td>0.676056</td>\n","      <td>0.737651</td>\n","      <td>0.855626</td>\n","      <td>0.895224</td>\n","      <td>0.819383</td>\n","      <td>0.597388</td>\n","      <td>0.545643</td>\n","      <td>0.659975</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.521000</td>\n","      <td>0.527916</td>\n","      <td>0.786006</td>\n","      <td>0.737240</td>\n","      <td>0.740965</td>\n","      <td>0.739884</td>\n","      <td>0.734884</td>\n","      <td>0.794769</td>\n","      <td>0.683391</td>\n","      <td>0.862324</td>\n","      <td>0.862643</td>\n","      <td>0.862005</td>\n","      <td>0.614512</td>\n","      <td>0.562241</td>\n","      <td>0.677500</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.457600</td>\n","      <td>0.517896</td>\n","      <td>0.787723</td>\n","      <td>0.740926</td>\n","      <td>0.742239</td>\n","      <td>0.742182</td>\n","      <td>0.738506</td>\n","      <td>0.775654</td>\n","      <td>0.704753</td>\n","      <td>0.862636</td>\n","      <td>0.863754</td>\n","      <td>0.861521</td>\n","      <td>0.621636</td>\n","      <td>0.587137</td>\n","      <td>0.660443</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/2/checkpoint-1165\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/2/checkpoint-1165/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/2/checkpoint-1165/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/2/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/2/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/2/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/2/checkpoint-3495\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/2/checkpoint-3495/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/2/checkpoint-3495/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/bert/results/2/checkpoint-3495 (score: 0.5178959369659424).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/models/model_2\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/models/model_2/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/models/model_2/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence, attention_mask_bert, token_type_ids_bert, input_ids_bert.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [146/146 00:05]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3495\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3495/3495 08:45, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.598700</td>\n","      <td>0.575654</td>\n","      <td>0.762395</td>\n","      <td>0.711223</td>\n","      <td>0.714413</td>\n","      <td>0.710108</td>\n","      <td>0.703307</td>\n","      <td>0.727364</td>\n","      <td>0.680791</td>\n","      <td>0.843033</td>\n","      <td>0.850056</td>\n","      <td>0.836125</td>\n","      <td>0.587328</td>\n","      <td>0.552905</td>\n","      <td>0.626322</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.512200</td>\n","      <td>0.555892</td>\n","      <td>0.774200</td>\n","      <td>0.711596</td>\n","      <td>0.737323</td>\n","      <td>0.710554</td>\n","      <td>0.728102</td>\n","      <td>0.802817</td>\n","      <td>0.666110</td>\n","      <td>0.855446</td>\n","      <td>0.879674</td>\n","      <td>0.832516</td>\n","      <td>0.551241</td>\n","      <td>0.449170</td>\n","      <td>0.713344</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.452400</td>\n","      <td>0.547150</td>\n","      <td>0.784503</td>\n","      <td>0.735937</td>\n","      <td>0.740609</td>\n","      <td>0.734983</td>\n","      <td>0.742308</td>\n","      <td>0.776660</td>\n","      <td>0.710866</td>\n","      <td>0.858662</td>\n","      <td>0.867086</td>\n","      <td>0.850399</td>\n","      <td>0.606842</td>\n","      <td>0.561203</td>\n","      <td>0.660562</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/3/checkpoint-1165\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/3/checkpoint-1165/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/3/checkpoint-1165/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/3/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/3/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/3/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/3/checkpoint-3495\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/3/checkpoint-3495/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/3/checkpoint-3495/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/bert/results/3/checkpoint-3495 (score: 0.5471498370170593).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/models/model_3\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/models/model_3/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/models/model_3/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence, attention_mask_bert, token_type_ids_bert, input_ids_bert.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [146/146 00:05]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3495\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3495/3495 08:35, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.608000</td>\n","      <td>0.579239</td>\n","      <td>0.767761</td>\n","      <td>0.706370</td>\n","      <td>0.734351</td>\n","      <td>0.693952</td>\n","      <td>0.709453</td>\n","      <td>0.717304</td>\n","      <td>0.701772</td>\n","      <td>0.846695</td>\n","      <td>0.891522</td>\n","      <td>0.806160</td>\n","      <td>0.562963</td>\n","      <td>0.473029</td>\n","      <td>0.695122</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.519500</td>\n","      <td>0.587072</td>\n","      <td>0.757459</td>\n","      <td>0.717007</td>\n","      <td>0.709512</td>\n","      <td>0.735992</td>\n","      <td>0.714224</td>\n","      <td>0.830986</td>\n","      <td>0.626232</td>\n","      <td>0.832620</td>\n","      <td>0.791929</td>\n","      <td>0.877719</td>\n","      <td>0.604178</td>\n","      <td>0.585062</td>\n","      <td>0.624585</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.454700</td>\n","      <td>0.548608</td>\n","      <td>0.780640</td>\n","      <td>0.733055</td>\n","      <td>0.737790</td>\n","      <td>0.733154</td>\n","      <td>0.737892</td>\n","      <td>0.781690</td>\n","      <td>0.698741</td>\n","      <td>0.853363</td>\n","      <td>0.859682</td>\n","      <td>0.847136</td>\n","      <td>0.607910</td>\n","      <td>0.558091</td>\n","      <td>0.667494</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/4/checkpoint-1165\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/4/checkpoint-1165/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/4/checkpoint-1165/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/4/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/4/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/4/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/4/checkpoint-3495\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/4/checkpoint-3495/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/4/checkpoint-3495/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/bert/results/4/checkpoint-3495 (score: 0.5486082434654236).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/models/model_4\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/models/model_4/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/models/model_4/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence, attention_mask_bert, token_type_ids_bert, input_ids_bert.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [146/146 00:05]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3495\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3495/3495 08:44, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.596900</td>\n","      <td>0.554762</td>\n","      <td>0.776561</td>\n","      <td>0.728339</td>\n","      <td>0.732131</td>\n","      <td>0.725209</td>\n","      <td>0.718077</td>\n","      <td>0.721328</td>\n","      <td>0.714855</td>\n","      <td>0.853377</td>\n","      <td>0.863014</td>\n","      <td>0.843954</td>\n","      <td>0.613563</td>\n","      <td>0.591286</td>\n","      <td>0.637584</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.517000</td>\n","      <td>0.526863</td>\n","      <td>0.784718</td>\n","      <td>0.740120</td>\n","      <td>0.740115</td>\n","      <td>0.745287</td>\n","      <td>0.739574</td>\n","      <td>0.802817</td>\n","      <td>0.685567</td>\n","      <td>0.857036</td>\n","      <td>0.850056</td>\n","      <td>0.864132</td>\n","      <td>0.623751</td>\n","      <td>0.582988</td>\n","      <td>0.670644</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.462200</td>\n","      <td>0.523563</td>\n","      <td>0.789011</td>\n","      <td>0.742359</td>\n","      <td>0.745438</td>\n","      <td>0.744895</td>\n","      <td>0.742991</td>\n","      <td>0.799799</td>\n","      <td>0.693717</td>\n","      <td>0.862114</td>\n","      <td>0.862273</td>\n","      <td>0.861954</td>\n","      <td>0.621972</td>\n","      <td>0.572614</td>\n","      <td>0.680641</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/5/checkpoint-1165\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/5/checkpoint-1165/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/5/checkpoint-1165/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/5/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/5/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/5/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/5/checkpoint-3495\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/5/checkpoint-3495/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/5/checkpoint-3495/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/bert/results/5/checkpoint-3495 (score: 0.5235632061958313).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/models/model_5\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/models/model_5/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/models/model_5/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence, attention_mask_bert, token_type_ids_bert, input_ids_bert.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [146/146 00:05]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3495\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3495/3495 08:47, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.605200</td>\n","      <td>0.555847</td>\n","      <td>0.770766</td>\n","      <td>0.720922</td>\n","      <td>0.726167</td>\n","      <td>0.717812</td>\n","      <td>0.710565</td>\n","      <td>0.727364</td>\n","      <td>0.694524</td>\n","      <td>0.848219</td>\n","      <td>0.859682</td>\n","      <td>0.837058</td>\n","      <td>0.603982</td>\n","      <td>0.566390</td>\n","      <td>0.646919</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.521400</td>\n","      <td>0.534285</td>\n","      <td>0.779566</td>\n","      <td>0.731602</td>\n","      <td>0.735105</td>\n","      <td>0.732621</td>\n","      <td>0.727187</td>\n","      <td>0.773642</td>\n","      <td>0.685995</td>\n","      <td>0.854824</td>\n","      <td>0.857830</td>\n","      <td>0.851838</td>\n","      <td>0.612795</td>\n","      <td>0.566390</td>\n","      <td>0.667482</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.453900</td>\n","      <td>0.528043</td>\n","      <td>0.784932</td>\n","      <td>0.738882</td>\n","      <td>0.739916</td>\n","      <td>0.742370</td>\n","      <td>0.740984</td>\n","      <td>0.795775</td>\n","      <td>0.693252</td>\n","      <td>0.858310</td>\n","      <td>0.855609</td>\n","      <td>0.861028</td>\n","      <td>0.617353</td>\n","      <td>0.575726</td>\n","      <td>0.665468</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/6/checkpoint-1165\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/6/checkpoint-1165/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/6/checkpoint-1165/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/6/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/6/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/6/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/6/checkpoint-3495\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/6/checkpoint-3495/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/6/checkpoint-3495/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/bert/results/6/checkpoint-3495 (score: 0.5280429124832153).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/models/model_6\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/models/model_6/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/models/model_6/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence, attention_mask_bert, token_type_ids_bert, input_ids_bert.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [146/146 00:05]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3495\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3495/3495 08:52, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.607600</td>\n","      <td>0.567196</td>\n","      <td>0.770122</td>\n","      <td>0.724400</td>\n","      <td>0.723855</td>\n","      <td>0.725141</td>\n","      <td>0.724121</td>\n","      <td>0.735412</td>\n","      <td>0.713171</td>\n","      <td>0.846239</td>\n","      <td>0.845613</td>\n","      <td>0.846867</td>\n","      <td>0.602841</td>\n","      <td>0.594398</td>\n","      <td>0.611526</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.518300</td>\n","      <td>0.537031</td>\n","      <td>0.781713</td>\n","      <td>0.732854</td>\n","      <td>0.738051</td>\n","      <td>0.736380</td>\n","      <td>0.738631</td>\n","      <td>0.808853</td>\n","      <td>0.679628</td>\n","      <td>0.856244</td>\n","      <td>0.856720</td>\n","      <td>0.855769</td>\n","      <td>0.603687</td>\n","      <td>0.543568</td>\n","      <td>0.678756</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.468000</td>\n","      <td>0.534948</td>\n","      <td>0.784932</td>\n","      <td>0.739856</td>\n","      <td>0.739425</td>\n","      <td>0.743492</td>\n","      <td>0.746692</td>\n","      <td>0.794769</td>\n","      <td>0.704100</td>\n","      <td>0.857408</td>\n","      <td>0.853758</td>\n","      <td>0.861090</td>\n","      <td>0.615469</td>\n","      <td>0.581950</td>\n","      <td>0.653085</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/7/checkpoint-1165\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/7/checkpoint-1165/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/7/checkpoint-1165/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/7/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/7/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/7/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/7/checkpoint-3495\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/7/checkpoint-3495/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/7/checkpoint-3495/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/bert/results/7/checkpoint-3495 (score: 0.5349481105804443).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/models/model_7\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/models/model_7/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/models/model_7/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence, attention_mask_bert, token_type_ids_bert, input_ids_bert.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [146/146 00:05]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3495\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3495/3495 08:38, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.601800</td>\n","      <td>0.585181</td>\n","      <td>0.758103</td>\n","      <td>0.713602</td>\n","      <td>0.706465</td>\n","      <td>0.724536</td>\n","      <td>0.706968</td>\n","      <td>0.770624</td>\n","      <td>0.653026</td>\n","      <td>0.838451</td>\n","      <td>0.813773</td>\n","      <td>0.864673</td>\n","      <td>0.595388</td>\n","      <td>0.589212</td>\n","      <td>0.601695</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.517300</td>\n","      <td>0.539925</td>\n","      <td>0.781927</td>\n","      <td>0.736426</td>\n","      <td>0.736778</td>\n","      <td>0.736293</td>\n","      <td>0.734228</td>\n","      <td>0.743461</td>\n","      <td>0.725221</td>\n","      <td>0.856984</td>\n","      <td>0.858571</td>\n","      <td>0.855404</td>\n","      <td>0.618067</td>\n","      <td>0.606846</td>\n","      <td>0.629709</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.458600</td>\n","      <td>0.543635</td>\n","      <td>0.781927</td>\n","      <td>0.736523</td>\n","      <td>0.736336</td>\n","      <td>0.740006</td>\n","      <td>0.744802</td>\n","      <td>0.792757</td>\n","      <td>0.702317</td>\n","      <td>0.854542</td>\n","      <td>0.851536</td>\n","      <td>0.857569</td>\n","      <td>0.610225</td>\n","      <td>0.575726</td>\n","      <td>0.649123</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/8/checkpoint-1165\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/8/checkpoint-1165/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/8/checkpoint-1165/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/8/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/8/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/8/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/8/checkpoint-3495\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/8/checkpoint-3495/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/8/checkpoint-3495/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/bert/results/8/checkpoint-2330 (score: 0.5399251580238342).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/models/model_8\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/models/model_8/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/models/model_8/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence, attention_mask_bert, token_type_ids_bert, input_ids_bert.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [146/146 00:05]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3495\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3495/3495 08:49, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.602700</td>\n","      <td>0.575228</td>\n","      <td>0.765400</td>\n","      <td>0.711267</td>\n","      <td>0.726456</td>\n","      <td>0.700009</td>\n","      <td>0.686335</td>\n","      <td>0.667002</td>\n","      <td>0.706823</td>\n","      <td>0.844096</td>\n","      <td>0.875972</td>\n","      <td>0.814458</td>\n","      <td>0.603371</td>\n","      <td>0.557054</td>\n","      <td>0.658088</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.515800</td>\n","      <td>0.540109</td>\n","      <td>0.782142</td>\n","      <td>0.733457</td>\n","      <td>0.741240</td>\n","      <td>0.730648</td>\n","      <td>0.730159</td>\n","      <td>0.763581</td>\n","      <td>0.699539</td>\n","      <td>0.855527</td>\n","      <td>0.868197</td>\n","      <td>0.843222</td>\n","      <td>0.614684</td>\n","      <td>0.560166</td>\n","      <td>0.680958</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.446000</td>\n","      <td>0.544680</td>\n","      <td>0.787293</td>\n","      <td>0.744247</td>\n","      <td>0.744398</td>\n","      <td>0.745885</td>\n","      <td>0.747592</td>\n","      <td>0.780684</td>\n","      <td>0.717190</td>\n","      <td>0.856825</td>\n","      <td>0.856350</td>\n","      <td>0.857302</td>\n","      <td>0.628323</td>\n","      <td>0.600622</td>\n","      <td>0.658703</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/9/checkpoint-1165\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/9/checkpoint-1165/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/9/checkpoint-1165/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/9/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/9/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/9/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/9/checkpoint-3495\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/9/checkpoint-3495/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/9/checkpoint-3495/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/bert/results/9/checkpoint-2330 (score: 0.5401089787483215).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/models/model_9\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/models/model_9/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/models/model_9/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence, attention_mask_bert, token_type_ids_bert, input_ids_bert.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [146/146 00:05]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 37265\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3495\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3495/3495 08:47, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Hate F1</th>\n","      <th>Hate Recall</th>\n","      <th>Hate Precision</th>\n","      <th>Offensive F1</th>\n","      <th>Offensive Recall</th>\n","      <th>Offensive Precision</th>\n","      <th>Normal F1</th>\n","      <th>Normal Recall</th>\n","      <th>Normal Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.605800</td>\n","      <td>0.555729</td>\n","      <td>0.779137</td>\n","      <td>0.730440</td>\n","      <td>0.732797</td>\n","      <td>0.729456</td>\n","      <td>0.712610</td>\n","      <td>0.733400</td>\n","      <td>0.692966</td>\n","      <td>0.857721</td>\n","      <td>0.862643</td>\n","      <td>0.852855</td>\n","      <td>0.620990</td>\n","      <td>0.592324</td>\n","      <td>0.652571</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.512500</td>\n","      <td>0.523541</td>\n","      <td>0.790084</td>\n","      <td>0.739669</td>\n","      <td>0.746424</td>\n","      <td>0.736219</td>\n","      <td>0.729400</td>\n","      <td>0.752515</td>\n","      <td>0.707663</td>\n","      <td>0.867408</td>\n","      <td>0.880415</td>\n","      <td>0.854781</td>\n","      <td>0.622197</td>\n","      <td>0.575726</td>\n","      <td>0.676829</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.459800</td>\n","      <td>0.527571</td>\n","      <td>0.793733</td>\n","      <td>0.744209</td>\n","      <td>0.752075</td>\n","      <td>0.741867</td>\n","      <td>0.736138</td>\n","      <td>0.774648</td>\n","      <td>0.701275</td>\n","      <td>0.868993</td>\n","      <td>0.880415</td>\n","      <td>0.857864</td>\n","      <td>0.627496</td>\n","      <td>0.570539</td>\n","      <td>0.697085</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/10/checkpoint-1165\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/10/checkpoint-1165/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/10/checkpoint-1165/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/10/checkpoint-2330\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/10/checkpoint-2330/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/10/checkpoint-2330/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: token_type_ids_mask, sentence, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 4659\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/results/10/checkpoint-3495\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/results/10/checkpoint-3495/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/results/10/checkpoint-3495/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Dissertation/bert/results/10/checkpoint-2330 (score: 0.5235409140586853).\n","Saving model checkpoint to /content/drive/MyDrive/Dissertation/bert/models/model_10\n","Configuration saved in /content/drive/MyDrive/Dissertation/bert/models/model_10/config.json\n","Model weights saved in /content/drive/MyDrive/Dissertation/bert/models/model_10/pytorch_model.bin\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence, attention_mask_bert, token_type_ids_bert, input_ids_bert.\n","***** Running Evaluation *****\n","  Num examples = 4658\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [146/146 00:05]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}],"source":["result_list = []\n","for i in range(1,11):\n","  training_args = TrainingArguments(\n","    output_dir='/content/drive/MyDrive/Dissertation/bert/results/'+str(i),          # output directory\n","    num_train_epochs=EPOCHS,              # total number of training epochs\n","    save_strategy =\"epoch\" ,\n","    per_device_train_batch_size=BATCH_SIZE,  # batch size per device during training\n","    per_device_eval_batch_size=BATCH_SIZE,   # batch size for evaluation\n","    learning_rate=LEARNING_RATE, \n","    logging_dir='./bert/logs/'+str(i),     # directory for storing logs\n","    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n","    evaluation_strategy=\"epoch\",     # evaluate each `logging_steps`\n","  )\n","\n","  hatetwit_dataset_dfs = load_from_disk('/content/drive/MyDrive/Dissertation/datasets/hatetwit_'+str(i))\n","  train_dataset = hatetwit_dataset_dfs [\"train\"].remove_columns([\"input_ids\",\"attention_mask\"])\n","  train_dataset = train_dataset.rename_column(\"input_ids_bert\",\"input_ids\")\n","  train_dataset = train_dataset.rename_column(\"attention_mask_bert\",\"attention_mask\")\n","  train_dataset = train_dataset.rename_column(\"token_type_ids_bert\",\"token_type_ids_mask\")\n","  eval_dataset = hatetwit_dataset_dfs [\"validation\"].remove_columns([\"input_ids\",\"attention_mask\"])\n","  eval_dataset = eval_dataset.rename_column(\"input_ids_bert\",\"input_ids\")\n","  eval_dataset = eval_dataset.rename_column(\"attention_mask_bert\",\"attention_mask\")\n","  eval_dataset = eval_dataset.rename_column(\"token_type_ids_bert\",\"token_type_ids_mask\")\n","  test_dataset = hatetwit_dataset_dfs [\"test\"].remove_columns([\"input_ids\",\"attention_mask\"])\n","  test_dataset = test_dataset.rename_column(\"input_ids_bert\",\"input_ids\")\n","  test_dataset = test_dataset.rename_column(\"attention_mask_bert\",\"attention_mask\")\n","  test_dataset = test_dataset.rename_column(\"token_type_ids_bert\",\"token_type_ids_mask\")\n","  model = model_init()\n","  trainer = Trainer(\n","      model=model,                         # the instantiated Transformers model to be trained\n","      args=training_args,                  # training arguments, defined above\n","      train_dataset= train_dataset,         # training dataset\n","      eval_dataset=eval_dataset,          # evaluation dataset\n","      compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n","  )\n","  trainer.train()\n","  trainer.save_model('/content/drive/MyDrive/Dissertation/bert/models/model_'+str(i))\n","  results = trainer.evaluate(hatetwit_dataset_dfs [\"test\"])\n","  results[\"model_run\"] = i\n","  result_list.append(results)"]},{"cell_type":"code","source":[""],"metadata":{"id":"1R_h0r9nsfAY","executionInfo":{"status":"ok","timestamp":1644975492776,"user_tz":0,"elapsed":25,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["timestamp()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BM22uoltwiK6","executionInfo":{"status":"ok","timestamp":1644975492776,"user_tz":0,"elapsed":6,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"382db572-0d6d-4aeb-e5c8-daabef770202"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["16-Feb-2022 (01:38:12.460922)\n"]}]},{"cell_type":"code","source":["results_df = pd.DataFrame(result_list)\n","results_df.to_csv('/content/drive/MyDrive/Dissertation/results/bert_baselines.csv')\n"],"metadata":{"id":"N1NyJwvv7nck","executionInfo":{"status":"ok","timestamp":1644975493244,"user_tz":0,"elapsed":472,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#Sort rows to determine the mix, max and median \n","results_df = results_df.sort_values(by=['eval_f1'])\n"],"metadata":{"id":"IbBd-VMMyCDP","executionInfo":{"status":"ok","timestamp":1644975493796,"user_tz":0,"elapsed":554,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#Print min values \n","results_df.head(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"id":"dmqlHGLvymGC","executionInfo":{"status":"ok","timestamp":1644975493797,"user_tz":0,"elapsed":33,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"1e89035b-b634-4886-960c-bab64d46012b"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-e8ecd0ff-afea-473c-976f-913e559630be\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eval_loss</th>\n","      <th>eval_accuracy</th>\n","      <th>eval_f1</th>\n","      <th>eval_precision</th>\n","      <th>eval_recall</th>\n","      <th>eval_hate_f1</th>\n","      <th>eval_hate_recall</th>\n","      <th>eval_hate_precision</th>\n","      <th>eval_offensive_f1</th>\n","      <th>eval_offensive_recall</th>\n","      <th>eval_offensive_precision</th>\n","      <th>eval_normal_f1</th>\n","      <th>eval_normal_recall</th>\n","      <th>eval_normal_precision</th>\n","      <th>eval_runtime</th>\n","      <th>eval_samples_per_second</th>\n","      <th>eval_steps_per_second</th>\n","      <th>epoch</th>\n","      <th>model_run</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.534123</td>\n","      <td>0.781237</td>\n","      <td>0.732864</td>\n","      <td>0.735147</td>\n","      <td>0.734031</td>\n","      <td>0.740811</td>\n","      <td>0.78147</td>\n","      <td>0.704174</td>\n","      <td>0.856669</td>\n","      <td>0.86</td>\n","      <td>0.853363</td>\n","      <td>0.601111</td>\n","      <td>0.560622</td>\n","      <td>0.647904</td>\n","      <td>6.6495</td>\n","      <td>700.499</td>\n","      <td>21.956</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8ecd0ff-afea-473c-976f-913e559630be')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e8ecd0ff-afea-473c-976f-913e559630be button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e8ecd0ff-afea-473c-976f-913e559630be');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   eval_loss  eval_accuracy   eval_f1  ...  eval_steps_per_second  epoch  model_run\n","1   0.534123       0.781237  0.732864  ...                 21.956    3.0          2\n","\n","[1 rows x 19 columns]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["#Print max values \n","results_df.tail(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"id":"i0OsqgEzyvGn","executionInfo":{"status":"ok","timestamp":1644975493797,"user_tz":0,"elapsed":30,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"a84484ec-dc01-413b-e82b-8a4ccb6828d0"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-8498afcd-7df8-427e-8979-0d0d6e4cf481\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eval_loss</th>\n","      <th>eval_accuracy</th>\n","      <th>eval_f1</th>\n","      <th>eval_precision</th>\n","      <th>eval_recall</th>\n","      <th>eval_hate_f1</th>\n","      <th>eval_hate_recall</th>\n","      <th>eval_hate_precision</th>\n","      <th>eval_offensive_f1</th>\n","      <th>eval_offensive_recall</th>\n","      <th>eval_offensive_precision</th>\n","      <th>eval_normal_f1</th>\n","      <th>eval_normal_recall</th>\n","      <th>eval_normal_precision</th>\n","      <th>eval_runtime</th>\n","      <th>eval_samples_per_second</th>\n","      <th>eval_steps_per_second</th>\n","      <th>epoch</th>\n","      <th>model_run</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>0.53366</td>\n","      <td>0.796264</td>\n","      <td>0.748941</td>\n","      <td>0.757816</td>\n","      <td>0.74821</td>\n","      <td>0.751527</td>\n","      <td>0.805639</td>\n","      <td>0.704225</td>\n","      <td>0.866825</td>\n","      <td>0.876296</td>\n","      <td>0.857557</td>\n","      <td>0.628472</td>\n","      <td>0.562694</td>\n","      <td>0.711664</td>\n","      <td>6.2582</td>\n","      <td>744.306</td>\n","      <td>23.329</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8498afcd-7df8-427e-8979-0d0d6e4cf481')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8498afcd-7df8-427e-8979-0d0d6e4cf481 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8498afcd-7df8-427e-8979-0d0d6e4cf481');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   eval_loss  eval_accuracy   eval_f1  ...  eval_steps_per_second  epoch  model_run\n","3    0.53366       0.796264  0.748941  ...                 23.329    3.0          4\n","\n","[1 rows x 19 columns]"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["#Print median f1\n","results_df[\"eval_f1\"].median()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u-SU_m3qzwuV","executionInfo":{"status":"ok","timestamp":1644975493798,"user_tz":0,"elapsed":29,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"45e34b89-3fe4-4388-9ac8-5c59760bfc36"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.739697657732783"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["#Print average values\n","results_df.mean()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GB7q4QKDyx7Y","executionInfo":{"status":"ok","timestamp":1644975493798,"user_tz":0,"elapsed":26,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"cf474111-072e-4662-daab-c2766dc976a8"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["eval_loss                     0.534259\n","eval_accuracy                 0.787720\n","eval_f1                       0.740537\n","eval_precision                0.744674\n","eval_recall                   0.740911\n","eval_hate_f1                  0.743993\n","eval_hate_recall              0.786103\n","eval_hate_precision           0.706472\n","eval_offensive_f1             0.860770\n","eval_offensive_recall         0.865852\n","eval_offensive_precision      0.855807\n","eval_normal_f1                0.616849\n","eval_normal_recall            0.570777\n","eval_normal_precision         0.671744\n","eval_runtime                  6.090190\n","eval_samples_per_second     767.173500\n","eval_steps_per_second        24.046100\n","epoch                         3.000000\n","model_run                     5.500000\n","dtype: float64"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["results_df.std()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"whggzZ1TdRU2","executionInfo":{"status":"ok","timestamp":1644975493798,"user_tz":0,"elapsed":23,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"e02d3045-9571-460f-9d3b-f9250816a1a0"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["eval_loss                    0.011483\n","eval_accuracy                0.005688\n","eval_f1                      0.005878\n","eval_precision               0.007528\n","eval_recall                  0.005517\n","eval_hate_f1                 0.005697\n","eval_hate_recall             0.014494\n","eval_hate_precision          0.012071\n","eval_offensive_f1            0.005826\n","eval_offensive_recall        0.009405\n","eval_offensive_precision     0.006139\n","eval_normal_f1               0.011002\n","eval_normal_recall           0.016615\n","eval_normal_precision        0.020409\n","eval_runtime                 0.360022\n","eval_samples_per_second     43.944597\n","eval_steps_per_second        1.377354\n","epoch                        0.000000\n","model_run                    3.027650\n","dtype: float64"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["training_loss_min = [0.6056,0.51370,0.4534]\n","training_loss_max = [0.608,0.5195,0.4547]\n","val_loss_min = [0.5524,0.519667,0.510353]\n","val_loss_max = [0.5792,0.5870,0.5486]\n","epoch_list=[1,2,3]\n","\n","plt.figure()\n","plt.plot(epoch_list,training_loss_min, label=\"Training Loss Min Run\")\n","plt.plot(epoch_list,val_loss_min, label=\"Validation Loss Min Run\")\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.xticks(epoch_list)\n","plt.legend()\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"rzGc0sf0shQV","executionInfo":{"status":"ok","timestamp":1644975493799,"user_tz":0,"elapsed":22,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"1f7f3f79-bcf9-40b3-d7b4-ccb5fe956bca"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["\n","plt.figure()\n","plt.plot(epoch_list,training_loss_max, label=\"Training Loss Max Run\")\n","plt.plot(epoch_list,val_loss_max, label=\"Validation Loss Max Run\")\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.xticks(epoch_list)\n","plt.legend()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"amlBhY_k1Z88","executionInfo":{"status":"ok","timestamp":1644975495197,"user_tz":0,"elapsed":1418,"user":{"displayName":"Aidan McGowran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14843729866646891917"}},"outputId":"90030de4-8552-40d1-9652-7a03888a147a"},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":[""],"metadata":{"id":"SgT9sCMftskm"}}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"BERT Baseline Experiment Hatetwit.ipynb","provenance":[{"file_id":"1RAjFaq-k9CLJQP5eO668UXLc0q-wjuve","timestamp":1644664697589},{"file_id":"1LzZr7GRN1SwVrNyjVX5t5PpCvio8w_kE","timestamp":1642109182548},{"file_id":"1t-qzEyxZtGn_Cnlfg2WtN-0dlgUmxfzx","timestamp":1641764210714},{"file_id":"14bEU8hCGPF8cVUA_BonJQA6Brv89DKUm","timestamp":1641252935713},{"file_id":"18Il3CpGf89tF1Z10iYX8OdfeHxxAX1Ui","timestamp":1639243141142},{"file_id":"1SHCgoRQVGtl9OiWEJGK3JgKkuxxSPy_5","timestamp":1639231968300},{"file_id":"1D-3yvF0nGnaWEZGxQj21R6fsGnyv5a5g","timestamp":1637526185003},{"file_id":"1glXr2JglKPUpN_3AGyk3GjfCtZSDNfsZ","timestamp":1637408594851},{"file_id":"1rc5hX8PBIv7GKvlxLQ35Vwf2jxLsv9f4","timestamp":1634501666668}],"mount_file_id":"1tZKcKBRCOjrR6uuM0O334HPdW2Ae2fmk","authorship_tag":"ABX9TyPxOu0CgnsF7r8rWdWucxBn"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}